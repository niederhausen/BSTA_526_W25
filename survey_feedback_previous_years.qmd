---
title: "Survey Feedback from Previous Years"
editor: visual
---

# 2024

## Week 1 

### Muddiest points

#### Class logistics

-   Will there be presentation slides in future classes, or is everything embedded into the quarto/html files for all lectures?
    -   *The material will primarily be in quarto/html files and not slides.*
-   Specifics of what topics will be covered exactly. \* *I don't have a list of all the specific functions we will be covering, but you are welcome to peruse the [BSTA 504 webpage from Winter 2023](https://sph-r-programming-2023.netlify.app/) to get more details on topics we will be covering. We will be closely following the same class materials.*
-   Identifying which section of the code we were discussing during the lecture
    -   *Thanks for letting me know. I will try to be clearer in the future, and also jump around less. Please let me know in class if you're not sure where we are at.*
-   The material covered towards the end of the class felt a bit difficult to keep up with. I wish we would have been told to read the materials from Week 1 (or at least skim them) ahead of Day 1, because I quickly lost track of the conversation when shortcuts were used super quickly, for example, or when we jumped from chunks of code to another topic without reflecting on them. I still had 70% of the material down and I wrote great notes during the discussion (which I later filled in with the script that was on the class website), but I think it the beginner/intermediate programming lingo that was used to explain ideas here confused me at times. Thus, I struggled to keep up with discussions around packages / best coding practices, especially when they were not mentioned directly on the script (where I could follow along!).
    -   *Thanks for the feedback. In future years, we will reach out to students before the term to let them know about the readings to prepare for class. Please let us know if there is lingo we are using that you are not familiar with. Learning R and coding is a whole new language!*

#### RStudio

-   I have trouble thinking through where things are automatically downloaded, saved, and running from. I can attend office hours for this!
    -   *Office hours are always a great idea. I do recommend paying close attention to where files are being saved when downloading and preferably specifying their location instead using the default location. Having organized files will make working on complex analyses much easier.*
-   How to read the course material in R. While it made sense in real time it may be difficult when going back over the material.
    -   *Getting used to reading code and navigating the rendered html files takes a while, and is a part of learning R. Figuring out how to take notes for yourself that works for you is also a learning curve. I recommend taking notes in the qmd files as we go through them in class. After class you can summarize and transfer key points to other file formats that you are more used to using. I personally have a folder in my Google drive filled with documents on different R programming topics. It started with one file, and then eventually expanded to multiple files on different topics in an attempt to organize my notes better. Whenever I learn something new (such as an R function or handy R package) that I want to keep for future reference, I add to them with links to relevant webpages and/or filenames and locations of where I used them.*

#### Code

-   What does the pacman package do? I have it installed but I'm not sure what it is actually used for.
    -   *I didn't go into `pacman` in Day 1. The `p_load()` function from the `pacman` package (usually run as `pacman::p_load()`) lets you load many packages at once without separately using the `library()` function for each individually.*
    -   *An added bonus is that by default it will install packages you don't already have, unless you specify `install = FALSE`.*
    -   *Another option is to set `update = TRUE` so that it will automatically update packages. I do not use this option though since sometimes updating packages causes conflicts with other packages or older code.*
    -   *You can read more about the different options in the [documentation](https://www.rdocumentation.org/packages/pacman/versions/0.5.1/topics/p_load). This [Medium article](https://medium.com/r-tutorials/an-alternative-to-loading-packages-in-r-using-pacman-p-load-6037903a301a) also has some tips on using `pacman`.*
-   The part on when to load in packages once they've already been loaded in - like for example would it be good to put that as a step in our homework 1 .qmd at the top? Or not necessary since they're already loaded in to R Studio from the work we did in class yesterday? What would happen if we try to load them in and they were already loaded in, would the .qmd file not render and show an error?
    -   *I always load my packages at the very top of the .qmd files, usually in the first code chunk (with the setup label). If you still have a previous R session open, then yes you don't need to load the packages again to run code within RStudio. However, when a file is rendered it starts with an empty workspace, which is why our qmd file must include code that loads the packages (either using `library()` or `pacman::p_load()`. We don't have to load packages at the beginning of the file, just before we have code that depends on the packages being used.*
-   I didn't understand the part where we talked about num, char, logical combinations (line 503).
    -   *The content of the objects `char_logical`, `num_char`, `num_logical`, and `tricky` were designed specifically to be confusing and thus make us aware of how R will decide to assign the data type when a vector is a mix of data types. Some key takeaways are below. Let me know if you sitll have questions about this.*
        -   *Numbers and logical/boolean (`TRUE`, `FALSE`) do not have double quotes around them, but character strings do. If you add double quotes to a number or logical, then R will treat it as a character string.*
        -   *If a vector is a mix of numbers and character strings, then the data type of the vector is character.*
        -   *If a vector is a mix of numbers and logical, then the data type of the vector is numeric and the logical value is converted to a numeric value (`TRUE`=1, `FALSE`=0).*
        -   *If a vector is a mix of character strings and logical, then the data type of the vector is character and the logical value is converted to a character string and no longer operates as a logical (i.e. no longer equal to 1 or 0).*
-   Lines 614-619, confused what the ratio means there. Could you go over the correct code (or options of the correct code) for challenge 5?
    -   *The code `1:4` or `6:9` creates sequences of integers starting with the first specified digit and ending at the last specified digit. For example, `1:4` is the vector with the digits 1 2 3 4. You can also create decreasing sequences by making the first number the bigger one. For example, `9:7` is the vector 9 8 7.*
    -   *Challenge 5:*
        -   `more_heights_complete <- na.omit(more_heights)`
        -   `median(more_heights_complete)`
        -   *You could also get the median of `more_heights` without first removing the missing values with `median(more_heights, na.rm = TRUE)`.*
-   how to count the TRUE values in a logical vector
    -   `TRUE` is equal to 1 in R (and `FALSE` is equal to 0), and the function `sum()` adds up the values in a vector. Thus, `sum(TRUE, FALSE, TRUE)` is equal to 2. Similarly, `sum(TRUE, FALSE, 5)` is equal to 6.
    -   The way I used it in class though is by counting how many values in the vector `z` (which was 7 9 11 13) are equal to 9. To do that I used the code `sum(z == 9)`. Breaking that down, the code inside the parentheses `z == 9` is equal to `FALSE TRUE FALSE FALSE` since the `==` means "equals to" in R.
    -   You can read up more on boolean and logical operators at the [R-bloggers post](https://www.r-bloggers.com/2021/09/r-booleans-comparison-and-logical-operators/).

### Clearest Points

*Thank you for the feedback!*

#### Class logistics

-   Syllabus/course structure
-   The syllabus review.
-   Overall expectations and course flow
-   Introduction to the class (first half of the class); conversation around syllabus; and the Quarto introduction

#### Quarto

-   How to create and edit a Quarto document in RStudio.
-   The differences between quarto and markdown
-   rmarkdown is no more, quarto it is!

#### Coding

-   Having code missing and fixing it in front of the class was helpful in troubleshooting.
-   Just running through all the commands was very clear and easy to follow
-   Basic R set up for quarto and introduction to R objects, vectors, etc.
-   Introduction, functions, and explanations was the clearest for me.
-   Classification of the objects in logical, character, and numeric
-   Not necessarily a point, but I really liked when we were encouraged to use the shortcut keys for various commands on R and other little things like switching code between console vs inline , I have used R before for a class briefly but I never knew all these ways by which I can save time and be efficient while writing a code.

## Week 2

### Muddiest points

-   When discussing untidy data, the difference between long data and wide data was unclear.
    -   *We'll be discussing the difference between long and wide data in more detail later in the course when we convert a dataset between the two. For now, you can take a look at an [example I created for our BERD R workshops](https://jminnier-berd-r-courses.netlify.app/02-data-wrangling-tidyverse/02_data_wrangling_slides_part2.html#27). The wide data in that example are not "tidy" since each cell contains two pieces of information: both the SBP and the visit number. In contrast, the long data have a separate column indicating which visit number the data in a given row are from.*
-   for the "summary()" function, is there a way to summarize all but one variable in a dataset?
    -   *Yes! I sometimes restrict a dataset to a couple of variables for which I want to see the summary. I usually use the `select()` function for this, which we will be covering later in the course. For now, you can take a look at some [select() examples from the BERD R workshops](https://jminnier-berd-r-courses.netlify.app/02-data-wrangling-tidyverse/02_data_wrangling_slides_part1.html#29) (see slides 29-32).*
-   Differences between a tibble and a data.frame
    -   *I'm not surprised to see this show up as a muddiest point! Depending on your level of experience with R, at this point in the class some of the differences are difficult to explain since we haven't done much coding yet. The [tibble vignette](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html) lists some of the differences though if you are interested. For our purposes, they are almost the same thing. When some differences come up later in the course, I will point them out.*

### Clearest Points

*Thanks for the feedback!*

-   I enjoyed going through the code and viewing the functions. I haven't really used `skimr` before and that was nice to see.
    -   *I like using `skmir`, but have recently been using `get_summary_stats()` from the `rstatix` package when teaching. It is only for numeric variables though. See a [`get_summary_stats()` example from my BSTA 511 class](https://niederhausen.github.io/BSTA_511_F23/slides/Day03_bsta511.html#/get_summary_stats-from-rstatix-package).*
-   Loading data.
-   How to load data into R was clearest.
    -   *Good to know that loading data was clear. This part can be tricky sometimes!*
-   ggplot
    -   *Hopefully this will still be clear when we cover more advanced options in `ggplot`!*

## Week 3

### Muddiest points

#### here package

The here package takes a bit to explaining, but, compared to the old way of doing things, it is a real life saver. The issue in the past had to do with relative file paths, especially with `.qmd` files that are saved in sub-folders. The `.qmd` file recognizes where it is saved as the root file path, which is okay with a one-off `.qmd` file. But when working in projects (recommended) and striving for reproducible R code (highly recommended), the `here` package save a lot of headache.

For further reading: + [Why should I use the here package when I'm already using projects?](https://malco.io/articles/2018-11-05-why-should-i-use-the-here-package-when-i-m-already-using-projects) by Malcolm Barrett. + [how to use the `here` package](http://jenrichmond.rbind.io/post/how-to-use-the-here-package/) by Jenny Richmond. + [here package vignette](https://here.r-lib.org/articles/here.html) + [Using here with rmarkdown](https://cran.r-project.org/web/packages/here/vignettes/rmarkdown.html)

Project-oriented workflows are recommended. Here package solves some old headaches. It gets easier with practice.

##### Question about using here

> ... how \[here\] can be used in certain instances where one may not remember if they switched to a new qmd file? In that case, would you suggest to use the "here" command each time you work on a project where there's a chance that you'll switch between qmd files and would like to use the same data file throughout? Is there any other way to better use this function or tips on how you deal with it?

There is a difference between working interactively in RStudio where data are loaded to the Environment. In this case, loading a data set once means that it can be used in any other code while working in the environment.

Issues will com up when you go to render a `.qmd` that doesn't have the data loaded within that `.qmd`. It won't look to the environment for the data; it looks to the filepath that you specify in the `.qmd`. Best practice is to *write the code* to load the data in each `.qmd` or `.R` script so that R knows where to look for the data that you want it to operate on / analyze.

#### The ! function. It seems like sometimes we use ! and sometimes we use -. Are they interchangeable, or each with different types of functions?

-   `!` -- the exclamation point can be read as "not" it is primarily used in logical statements
-   `-` -- the minus sign can be used in more instances
    -   to do actual arithmetic (i.e. subtraction)
    -   to indicate a negative number
    -   with `dplyr::select()` to remove or not select a column, or exclusion

```{r}

# Subtraction
5 - 3

# Negation
x <- 10
-x

# Selection/exclusion
library(dplyr)
select(starwars, -height) |> dplyr::glimpse()

```

#### Using the fill command

We didn't cover it in the lecture notes, but then it appeared in the example. I suggest to read/work through the [fill vignette](https://tidyr.tidyverse.org/reference/fill.html); the examples there are good ones to show what the function does. Then look back a the `smoke_messy` data set in Part 3 and think about why this command would be useful to clean up the data and for *fill*ing in missing values.

#### Loading data into R

It gets easier and hopefully you get to see more example in the notes and practice with the homework. [This tutorial](http://www.sthda.com/english/wiki/importing-data-into-r) is pretty good. So is the [readxl vignette](https://readxl.tidyverse.org/) and the [readr vignette](https://readr.tidyverse.org/).

#### Reasonable width, height, and dpi values when using ggsave

This takes some trial and error and depends on the purpose. For draft figures, dpi = 70 might be okay, but a journal might require dpi above 300 for publication. In Quarto, rendering an html, the figure defaults are 7x5 inches ([Link](https://quarto.org/docs/computations/execution-options.html)). We talked about in class how you can use the plot panes to size your figures by trial and error.

#### The `tidyselect` section

There were pretty good resources in the notes

-   See some more examples in [this slide](https://jminnier-berd-r-courses.netlify.app/02-data-wrangling-tidyverse/02_data_wrangling_slides_part1.html#32)

-   For more info and learning about tidyselect, please run this code in your console:

```{r}
#| eval: false
# install remotes package
install.packages("remotes")
# use remotes to install this package from github
remotes::install_github("laderast/tidyowl")

# load tidyowl package
library(tidyowl)

# interactive tutorial
tidyowl::learn_tidyselect()
```

[Here is also a link](https://dplyr.tidyverse.org/reference/dplyr_tidy_select.html) with a list of the selectors and links to each one. For example, there is a link to [`starts_with`](https://tidyselect.r-lib.org/reference/starts_with.html) and a bunch of examples.


## Week 4



```{r}
#| label: setup

# Load packages
pacman::p_load(tidyverse, 
               readxl, 
               janitor,
               here)
```

```{r}
#| label: load the data

# Load data
smoke_complete <- readxl::read_excel(here("data", "smoke_complete.xlsx"), 
                                     sheet = 1, 
                                     na = "NA")
                                     
# dplyr::glimpse(smoke_complete)
```


### Keyboard shortcut for the pipe (`%>%` or `|>`)

In office hours, someone didn't know about this fact and wanted to make sure everyone knows about it.

::: {.callout-tip}

#### Important keyboard shortcut

In RStudio the keyboard shortcut for the pipe operator `%>%` (or native pipe `|>`) is `Ctrl + Shift + M` (Windows) or `Cmd + Shift + M` (Mac).

Note: `Ctrl + Shift + M` also works on a Mac.

:::


### The difference between NA value and 0

#### NA (Not Available)

+ `NA` is a special value in R that represents missing or undefined data.
+ `0` is a numeric value representing the number zero. It is a valid and well-defined numerical value in R. 
+ It's important to handle `NA` values appropriately in data analysis and to consider their impact on calculations, as operations involving `NA` may result in `NA`.

```{r}
NA + 5  # The result is NA

0 + 5  # The results is 5


x <- c(1, 2, NA, 4)

sum(x)  # The result is NA

# Using the argument na.rm = TRUE, means to ignore the NAs
sum(x, na.rm = TRUE) # The results is 7


x <- c(1, 2, 0, 4)

sum(x) # The result is 7


```


### `across()` and it's usage

The biggest advantage that across brings is the ability to perform the same data manipulation task to multiple columns.

Below the values in three columns are all set to the mean value using the `mean()`. I had to write out the function and the variable names three times.  

```{r}
smoke_complete |> 
  mutate(days_to_death = mean(days_to_death, na.rm = TRUE), 
         days_to_birth = mean(days_to_birth, na.rm = TRUE), 
         days_to_last_follow_up = mean(days_to_last_follow_up, na.rm = TRUE)) |> 
  dplyr::glimpse()
```

The same thing is accomplished using `across()` but we only have to call the `mean()` function once.

```{r}
smoke_complete |> 
  mutate(dplyr::across(.cols = c(days_to_death, 
                                 days_to_birth, 
                                 days_to_last_follow_up), 
                       .fns = ~ mean(.x, na.rm = TRUE))) |> 
  dplyr::glimpse()


```


#### Links to check out

+ [`across()` vignette](https://dplyr.tidyverse.org/reference/across.html)
+ [Why I love dplyr's across](https://willhipson.netlify.app/post/dplyr_across/dplyr_across/)


### `~` and `.x`

We've seen the `~` and `.x` used with `dplyr::across()`. We will see them again later when we get to the package `purrr`.

In the tidyverse, `~` and `.x` are used to create what they call *lambda* functions which are part of the `purrr` syntax. We have not talked about functions yet, but `purrr` package and the `dplyr::across()` function allow you to specify functions to apply in a few different ways:

1. **A named function, e.g. `mean`.**

```{r}
smoke_complete |> 
  mutate(dplyr::across(.cols = c(days_to_death, 
                                 days_to_birth, 
                                 days_to_last_follow_up), 
                       .fns = mean)) |> 
  dplyr::glimpse()

```

::: {.callout-note}
Above, just using the function name, we are not able to provide the additional argument `na.rm = TRUE` to the `mean()` function, so the columns are now all `NA` values because there were missing (`NA`) values in those columns.
:::

2. **An anonymous function, e.g. `\(x) x + 1` or `function(x) x + 1`.**

This has not been covered yet. R lets you specify your own functions and there are two basic ways to do it.

```{r}
smoke_complete |> 
  mutate(dplyr::across(.cols = c(days_to_death, 
                                 days_to_birth, 
                                 days_to_last_follow_up), 
                       .fns = \(x) mean(x, na.rm = TRUE))) |> 
  dplyr::glimpse()
```

or 

```{r}
smoke_complete |> 
  mutate(dplyr::across(.cols = c(days_to_death, 
                                 days_to_birth, 
                                 days_to_last_follow_up), 
                       .fns = function(x) mean(x, na.rm = TRUE))) |> 
  dplyr::glimpse()
```

::: {.callout-note}
Now we are able to use the additional argument `na.rm = TRUE` and the columns are now the means of the valid values in those columns.
:::

3. **A purrr-style lambda function, e.g. `~ mean(.x, na.rm = TRUE)`**

We use `~` to indicate that we are supplying a lambda function and we use `.x` as a placeholder for the argument within our lambda function to indicate where to use the variable. 

```{r}
smoke_complete |> 
  mutate(dplyr::across(.cols = c(days_to_death, 
                                 days_to_birth, 
                                 days_to_last_follow_up), 
                       .fns = ~ mean(.x, na.rm = TRUE))) |> 
  dplyr::glimpse()
```


#### Links to check out

Some of these are `purrr` focused which we have not covered yet. Others use `dplyr::across()` withing the `dplyr::summarize()` function which we will be covering soon

+ [Meaning of tilde and dot notation in dplyr](https://stackoverflow.com/questions/68249625/meaning-of-tilde-and-dot-notation-in-dplyr)
+ [What is the meaning of '~' and '.' inside the function map? ](https://stackoverflow.com/questions/70665707/what-is-the-meaning-of-and-inside-the-function-map)
+ [`across()` vignette](https://dplyr.tidyverse.org/reference/across.html)
+ [Why I love dplyr's across](https://willhipson.netlify.app/post/dplyr_across/dplyr_across/)


### Exceptions where we have seen the `~` used

In class, we have seen three instances where the `~` is used that is not for a lambda function.

#### `case_when`

```{r}
smoke_complete |> 
  mutate(cigarettes_category = case_when(
      cigarettes_per_day < 6 ~ "0-5", 
      cigarettes_per_day >= 6 ~ "6+"
    )) |> 
  mutate(cigarettes_category = factor(cigarettes_category)) |> 
  janitor::tabyl(cigarettes_category)
```

#### `facet_wrap`

```{r}
ggplot(data = smoke_complete, 
       aes(x = age_at_diagnosis, 
           y = cigarettes_per_day)) + 
  geom_point() + 
  facet_wrap(~ disease)
```

Per the [`facet_wrap` vignettte](https://ggplot2.tidyverse.org/reference/facet_wrap.html):

> For compatibility with the classic interface, can also be a formula or character vector. Use either a one sided formula, `~a + b`, or a character vector, `c("a", "b")`.

Here it is being used to specify a formula.

Though per the vignette, the `vars()` function is preferred syntax:

```{r}
ggplot(data = smoke_complete, 
       aes(x = age_at_diagnosis, 
           y = cigarettes_per_day)) + 
  geom_point() + 
  facet_wrap(ggplot2::vars(disease))
```

#### `facet_grid`

```{r}
ggplot(data = smoke_complete, 
       aes(x = age_at_diagnosis, 
           y = cigarettes_per_day)) + 
  geom_point() + 
  facet_grid(disease ~ vital_status)
```

Per the [`facet_grid` vignettte](https://ggplot2.tidyverse.org/reference/facet_grid.html):

> For compatibility with the classic interface, rows can also be a formula with the rows (of the tabular display) on the LHS and the columns (of the tabular display) on the RHS; the dot in the formula is used to indicate there should be no faceting on this dimension (either row or column).

Again, it is being used to specify a formula.

Though per the vignette, the `ggplot2::vars()` function with the arguments `rows` and `cols` seems to be preferred:

```{r}
ggplot(data = smoke_complete, 
       aes(x = age_at_diagnosis, 
           y = cigarettes_per_day)) + 
  geom_point() + 
  facet_grid(rows = ggplot2::vars(disease), 
             cols = ggplot2::vars(vital_status))
```


Note: `dplyr::vars()` and `dplyr::ggplot2()` are the same function in different packages and can be used interchangeably.


### `case_when` vs. `if_else`

In dplyr, both `if_else()` and `case_when()` are used for conditional transformations, but they have different use cases and behaviors.

1. `if_else` function

+ `if_else()` is designed for simple vectorized conditions and is particularly useful when you have a *binary* condition (i.e., two possible outcomes).
+ It evaluates a condition for each element of a vector and returns one of two values based on whether the condition is `TRUE` or `FALSE`.

```{r}
smoke_complete |> 
  mutate(cigarettes_category = dplyr::if_else(cigarettes_per_day < 6, "0-5", "6+")) |> 
  mutate(cigarettes_category = factor(cigarettes_category)) |> 
  janitor::tabyl(cigarettes_category)
```

In this example, the column `cigarettes_category` is assigned the value "0-5" if `cigarettes_per_day` is less than 6 and "6+" otherwise.

2. `case_when()` function

+ `case_when()` is more versatile and is suitable for handling multiple conditions with multiple possible outcomes. It is essentially a vectorized form of a `switch` or `if_else` chain.
+ It allows you to specify multiple conditions and their corresponding values.

```{r}
smoke_complete |> 
  mutate(cigarettes_category = case_when(
      cigarettes_per_day < 2 ~ "0 to 2", 
      cigarettes_per_day < 4 ~ "2 to 4", 
      cigarettes_per_day < 6 ~ "4 to 6", 
      cigarettes_per_day >= 6 ~ "6+"
    )) |> 
  mutate(cigarettes_category = factor(cigarettes_category)) |> 
  janitor::tabyl(cigarettes_category)
```

In this example, the column `cigarettes_category` is assigned the value "0 to 2" if `cigarettes_per_day` is less than 2, 
"2 to 4" if less than 4 (but greater than 2), "4 to 6" if less than 6 (but greater than 4), and "6+" otherwise.


Use `if_else()` when you have a simple binary condition, and use `case_when()` when you need to handle multiple conditions with different outcomes. `case_when()` is more flexible and expressive when dealing with complex conditional transformations.


### The difference between a theme and and a palette. 


In `ggplot2`, a theme and a palette serve different purposes and are used in different contexts. In summary, a theme controls the overall appearance of the plot, while a palette is specifically related to the colors used to represent different groups or levels within the data. Both themes and palettes contribute to visual appeal and readability of your plot.

1. **Theme:**

- A theme in `ggplot2` refers to the overall visual appearance of the plot. It includes elements such as fonts, colors, grid lines, background, and other visual attributes that define the look and feel of the entire plot.
- Themes are set using functions like `theme_minimal()`, `theme_classic()`, or custom themes created with the `theme()` function. Themes control the global appearance of the plot.

```{r}
library(ggplot2)

# Example using theme_minimal()
ggplot(data = smoke_complete, 
       aes(x = age_at_diagnosis, 
           y = cigarettes_per_day)) + 
  geom_point() + 
  theme_minimal()


```

2. **Palette:**

- A palette, on the other hand, refers to a set of colors used to represent different levels or categories in the data. It is particularly relevant when working with categorical or discrete data where you want to distinguish between different groups.
- Palettes are set using functions like `scale_fill_manual()` or `scale_color_manual()`. You can specify a vector of colors or use pre-defined palettes from packages like RColorBrewer or viridis (we looked at the viridis package in class).

```{r}
# Example using a color palette
ggplot(data = smoke_complete, 
       aes(x = age_at_diagnosis, 
           y = cigarettes_per_day, 
           color = disease)) + 
  geom_point() +
  scale_color_manual(values = c("red", 
                                "blue", 
                                "green"))
```

### Be careful what you pipe to and from

An error came up where a data frame was being piped to a function that did not accept a data frame as an argument (it accepted a vector)

```{r}
#| error: true

# starwars data frame was loaded earlier with the ggplot2 package

starwars |>  
  dplyr::n_distinct(species) 
```

+ `starwars` is a data frame.
+ `dplyr::n_distinct()` only accepts a vector as an argument (check the help `?dplyr::n_distinct`)

So we need to pipe a vector to the `dplyr::n_distinct()` function:

```{r}
starwars |> 
  dplyr::select(species) |> 
  dplyr::n_distinct() 
```

`dplyr::select()` accepts a data frame as its first argument and it return a vector (see the help `?dplyr::select`) which we can then pipe to `dplyr::n_distinct()`.

The `%>%` or `|>` takes the output of the expression on its left and passes it as the first argument to the function on its right. The class / type of output on the left needs to agree or be acceptable as the first argument to the function on the right.


### Other muddy points

+ Remembering applicable functions. Troubleshooting.

> This gets better with experience. You are all still very new to R so be patient with yourself. 

+ How to organize all of the material to understand the structure of how the R language works, rather than to keep track of all of the commands in an anecdotal way.

> Again, I think that this gets better with experience. Though the R language, being open source, a lot of syntax is package dependent. So you need to be careful that some of the syntax we use with `dplyr` and the `tidyverse` will be different in base R or in other packages. This is something that comes with open source software (compared to Stata or SAS). The good news is that learning to use packages sets you up to better learn newer (to you) packages down the road.



## Week 5

### `case_when()` vs `ifelse()`

_The difference between case_when and ifelse_

* `ifelse()` is the base R version of tidyverse's `case_when()`
* I prefer using `case_when()` since it's easier to follow the logic.
* `case_when()` is especially useful when there are more than two logical conditions being used.



The example below creates a binary variable for bill length (long vs not long) using both `case_when()` and `ifelse()` as a comparison.

* Compare the crosstabs of the two variables!

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(janitor)
library(palmerpenguins)

summary(penguins)

penguins <- penguins %>% 
  mutate(
    long_bill1 = case_when(
      bill_length_mm >= 45 ~ "long",
      bill_length_mm < 45 ~ "not long",
    ),
    long_bill2 = ifelse(bill_length_mm >= 45, "long", "not long")
  )

penguins %>% tabyl(long_bill1, long_bill2) %>% 
  adorn_title()

```

Below is an example using `case_when()` to create a categorical variable with 3 groups:

```{r}
penguins <- penguins %>% 
  mutate(
    long_bill3 = case_when(
      bill_length_mm >= 50 ~ "long",
      bill_length_mm <= 40 ~ "short",
      TRUE ~ "medium"
    ))

penguins %>% tabyl(long_bill3, long_bill1) %>% 
  adorn_title()
```

* Creating a categorical variable with 3 groups can be done with `ifelse()`, but it's harder to follow the logic:

```{r}
penguins <- penguins %>% 
  mutate(
    long_bill4 = ifelse(
      bill_length_mm >= 50, "long",
      ifelse(bill_length_mm <= 40, "short", "medium")
      ))

penguins %>% tabyl(long_bill3, long_bill4) %>% 
  adorn_title()
```


### `separate()`

_Different ways of using the function separate, it was a bit unclear that when to use one or the other or examples of my research data where it'll be most relevant to use._

* Choosing the "best" way of using `separate()` is overwhelming at first. 
* I recommend starting with the simplest use case with a string being specified in `sep = " "`:

>`separate(data, col, into, sep = " ")`

* Which of the various versions we showed to use depends on how the data being separated are structured. 
* Most of the time I have a simple character, such as a space (`sep = " "`) or a comma (`sep = ","`) that I want to separate by.
* If the data are structured in a more complex way, then one of the `stringr` package options might come in handy.



### `here::here()`

_TSV files, very neat... But also, I got a bit confused when you did the render process around 22:00-23:00 minutes. Also, "here: and also "here" Directories/root directories. I was a bit confused about in what situations we would tangibly utilize this/if it is beneficial._

* Great question! This is definitely not intuitive, which is why I wanted to demonstrate it in class. 
* The key is that 
    * when rendering a qmd file the current working directory is the folder the file is sitting in, 
    * while when running code in a file within RStudio the working directory is the folder where the `.Rproj` file is located.  
* This distinction is important when loading other files from our computer during our workflow, and why `here::here()` makes our workflow so much easier!


###  what functions will only work within another function (generally)

* I'm not aware of functions that only work standalone within other functions. For example, the `mean()` function works on its own, but can also be used within a `summarise()`.


```{r}
mean(penguins$bill_length_mm, na.rm = TRUE)

penguins %>% summarise(
  m = mean(bill_length_mm, na.rm = TRUE)
)
```

* That being said, a function has a set of parameters to be specified that are specific to that function. 



## Week 6 (Part 5 contd.)


### `across()`

_what exactly the across function does_

_.fns, i.e. .fns=list, etc... I wasn't really sure what that was achieving within across._

* The `across()` function lets us apply a function to many columns at once. 
* For example, let's say we want the mean value for every continuous variable in a dataset.
    * The code below calculates the mean for one variable in the penguins dataset using both base R and `summarize()`. 
    * One option to calculate the mean value for every continuous variable in the dataset is to repeat this code for the 4 other continuous variables.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(janitor)
library(palmerpenguins)
library(gt)

summary(penguins)

  # base R
mean(penguins$bill_length_mm, na.rm = TRUE)

# with summarize
penguins %>% 
  summarize(mean(bill_length_mm, na.rm = TRUE))
```

* In this case `across()` lets us apply the mean function to all the columns of interest at once: 

```{r}
penguins %>%
  summarize(across(.cols = where(is.numeric), 
                   .fns = ~ mean(.x, na.rm = TRUE)
                   )) %>% 
  gt()
```

* The `.fns=list` part of the `across` code is where we specify the function(s) that we want to apply to the specified columns. 
    * Above we only specified one function (`mean()`), but we can specify additional functions as well, which is when we need to create a `list` to list all the functions we want to apply. 
    * Below I apply the mean and standard deviation functions:
    
```{r}
penguins %>%
  summarize(across(.cols = where(is.numeric), 
                   .fns = list(
                     mean = ~ mean(.x, na.rm = TRUE),
                     sd = ~ sd(.x, na.rm = TRUE)
                     ))) %>% 
  gt()
```

* In general, lists are another type of R object to store information, whether data, lists of functions, output from regression models, etc. While concatenate is just a vector of values, lists are multidimensional. We will be learning more about lists in parts 7 and 8. 

* You can learn more about `across()` at its [help file](https://dplyr.tidyverse.org/reference/across.html).



### `case_when()` vs `ifelse()`

_still a little confused on the difference between ifelse and casewhen, understand they are very similar but still confused on when it is best to use one over another_

* The two functions can be used interchangeably.         * `ifelse()` is the original function from base R
  *  `case_when()` is the user-friendly version of `ifelse()` from the `dplyr` package
* I recommend using `case_when()`, and it is what I use almost exclusively in my own work. My guess is that `ifelse()` was included in the notes since you might run into the function when reading R code on the internet.
* Just be careful that you preserve missing values when using `case_when()` as we discussed last time. 


### factor levels

_working with factor levels doesn't feel totally intuitive yet. I think that's because I tend to get confused with anything involving a concatenated list._

* Working with factor variables takes a while to get used to, and in particular with their factor levels. 
* We will be looking at more examples with factor variables in the part 6 notes. See sections 2.8 and 4.
* You can think of a concatenated list(`c(...)`) as a vector of values or a column of a dataset. Concatenating lets us create a set of values, which we typically create to use for some other purpose, such as specifying the levels of a factor variable.
* _Please submit a follow-up question in the post-class survey if this is still muddy after today's class!_


### pivoting tables

* Definitely a tricky topic, and over half of the muddiest points were about pivoting tables. 
* We will be looking at more examples in part 6. 


#### How pivot_longer() would work on very large datasets with many rows/columns

* It works the same way. However the resulting long table will end up being much much longer. 
* Extra columns in the dataset just hang out and their values get repeated (such as an age variable that is not being made long by) over and over again. 
    * We will be pivoting a dataset in part 6 that has extra variables that are not being pivoted.

#### Trying to visualize the joins and pivot longer/wider

* I recommend trying them out with small datasets where you can actually see what is happening. 
* __Joins__: Our [BERD workshop slides](https://jminnier-berd-r-courses.netlify.app/02-data-wrangling-tidyverse/02_data_wrangling_slides_part2.html#18) have another example that might visualize joins. 
    * [Slide 18](https://jminnier-berd-r-courses.netlify.app/02-data-wrangling-tidyverse/02_data_wrangling_slides_part2.html#18) shows to datasets x and y, and what the resulting joins look like. 
    * [Slide 19](https://jminnier-berd-r-courses.netlify.app/02-data-wrangling-tidyverse/02_data_wrangling_slides_part2.html#19) shows Venn diagrams of how the different joins behave. 
* __Pivoting__: There's an [example with a very small dataset](https://niederhausen.github.io/BSTA_511_F23/slides_code/Day03_bsta511_code_part3_data_wrangling.html#reshaping-data) in my (supplemental) notes from BSTA 511. The graphic that goes along with this is on [Slide 28](https://drive.google.com/file/d/1IfubP0ei-5jTIVs33dyoEqjMIY-Q8qBe/view) from the pdf. 

#### pivot_longer makes plotting more understandable in an analysis sense, which situations would call for pivot_wider?

* I tend to use `pivot_longer()` much more frequently. However, there are times when `pivot_wider()` comes in handy. For example, below is a long table of summary statistics created with `group_by()` and `summarize()`. I would use `pivot_wider()` to reshape this table so that I have columns comparing species or columns comparing islands. 

```{r}
penguins %>% 
  group_by(species, island) %>%
  summarize(across(.cols = bill_length_mm, 
                   .fns = list(
                     mean = ~ mean(.x, na.rm = TRUE),
                     sd = ~ sd(.x, na.rm = TRUE)
                     )))
  
```


#### How to use arguments of pivot longer.

* The arguments of the pivot functions take some practice to get used to. I sometimes still pull up an [example](https://niederhausen.github.io/BSTA_511_F23/slides_code/Day03_bsta511_code_part3_data_wrangling.html#reshaping-data) to remind me what I need to specify for the various arguments, such as the one mentioned above that I have used in workshops and classes.  
* We have not covered all the different arguments, and I recommend reviewing the [help file](https://tidyr.tidyverse.org/reference/pivot_longer.html) and in particular the [examples](https://tidyr.tidyverse.org/reference/pivot_longer.html#ref-examples) at the end of the page. 


### `gt::gt()`

_The gt::gt package does make the tables look fancier, how do we add labels to those to have them look nice as well?_

* I highly recommend the [`gt` webpage](https://gt.rstudio.com/) to learn more about all the different options to create pretty tables. Note the tabs at the top of the page for "Get started" and "Reference."
* See also section 3 of part 6 on "Side note about `gt::gt()`" for more on creating pretty tables. 


### `here::here`

_would also love more examples of here() I am starting to understand it better but still am a little confused_

_I am still having trouble getting here() to work consistently. I was going to ask during class, but I think I am just not understanding how to manually nest my files correctly so that "here" works. I am struggling to get that set up correct, and thus, struggling to use it. _


* We'll have some more examples in class, but I recommend reaching out to one of us (instructors or TA) to help you troubleshoot `here::here`. 
* Here are also some resources that might help
    * [https://here.r-lib.org/articles/here.html](https://here.r-lib.org/articles/here.html)
    * [http://jenrichmond.rbind.io/post/how-to-use-the-here-package/](http://jenrichmond.rbind.io/post/how-to-use-the-here-package/)
    * [https://github.com/jennybc/here_here](https://github.com/jennybc/here_here)
    

### Clearest points

* `group_by()` function (n=3)
* `summarize()` (n=2)
* `across()` (n=1)
* `case_when()` (n=1)
* `drop_na( )`  (n=2)
* Joining tables (n=6)




## Week 7 (Part 6)



#### Why we used `full_join()`

>Why we used `full_join()` in the class example instead of the other join options

* In this case both datasets being joined had the same ID's, and thus it did not matter whether we used `left_join()`, `right_join()`, `full_join()` or `inner_join()`. All of these would've given the same results. 

#### Visualizing pivots and joins

>pivot-longer is still hard for me to mentally visualize how it alters the dataset.

>I always struggle to visualize pivots and joins. 

* Reshaping data take lots of practice to get the hang of, and something where I still pause while coding to think through how it will work and how to code it. Especially for pivoting, I often refer back to existing code I am familiar with. _It's normal at this point to still be muddy on these topics. Keep practicing though and read through some more examples._ 
* In the [week 6 muddiest points](https://niederhausen.github.io/BSTA_526_W24/weeks/week_06.html#trying-to-visualize-the-joins-and-pivot-longerwider) I listed some additional resources for visualizing these. 
* See also [Tidy Animated Verbs](https://github.com/gadenbuie/tidyexplain) for visualizing [joins](https://github.com/gadenbuie/tidyexplain?tab=readme-ov-file#mutating-joins) and [pivoting](https://github.com/gadenbuie/tidyexplain#tidy-data). The page  also includes visualizing `union()`, `intersect()`, and `set_diff()`. 
* Another great resource is the [R for Epidemiology](https://www.r4epi.com/) website. 
    * It has sections on [joins](https://www.r4epi.com/working-with-multiple-data-frames#combining-data-frames-horizontally-by-key-values) and [pivoting](https://www.r4epi.com/restructuring-data-frames#restructuring-data-frames).
* Jessica also addressed [pivoting in last year's muddiest points](https://sph-r-programming-2023.netlify.app/class/07-class/#muddiest-parts). 

_Please come to office hours or set up a time to meet if this is still muddy after looking at these resources!_

#### `mutate(factor ( ))`

>`mutate(factor ( ))` problem we ran into in class where Emile posted on Slack.

Below is the code Emile posted on Slack (commented out):
```{r eval=FALSE}
# data <- data |>
#   mutate(timepoint = factor(timepoint,
#                             levels = c(1, 2, 3),
#                             labels = c(“1 month”,
#                                          “6 months”,
#                                          “12 months”)))
```

* At this point we were working through the code of Section 2.8 in the Part 6 notes. 

Load the `mouse_data` dataset we were working with:

```{r}
#| warning: false
#| message: false
 
library(tidyverse)
library(here)
library(janitor)

mouse_data <- read_csv(here("data", "mouse_data_longitudinal_clean.csv"))
glimpse(mouse_data)

mouse_data %>% tabyl(time)
```

* The goal was to create a factor variable of the character time point column called `time` with the levels 1 month, 6 months, and 12 months, instead of `time`'s values tp1, tp2, and tp3. 
* The code presented in class to accomplish this is below:

```{r}
# create time_month factor
mouse_data <- mouse_data %>%
  mutate(time_month = case_when(
    time=="tp1" ~ "1 month",
    time=="tp2" ~ "6 months",
    time=="tp3" ~ "12 months"
  ),
  time_month = factor(time_month,
                      levels = c("1 month", "6 months", "12 months")))
```

* Compare the old and new time variables:

```{r}
mouse_data %>% tabyl(time, time_month)
```

* The question arose as to whether we could include `factor()` in the same step as `case_when()` when creating `time_month` above, instead of having to write it out as a second separate line in the `mutate()`. 
* When using `case_when()`, we can do this as follows by piping the factor after the `case_when()`:

```{r}
mouse_data <- mouse_data %>%
  mutate(time_month2 = case_when(
    time=="tp1" ~ "1 month",
    time=="tp2" ~ "6 months",
    time=="tp3" ~ "12 months"
  ) %>% factor(., levels = c("1 month", "6 months", "12 months"))
  )

mouse_data %>% tabyl(time_month, time_month2)
```

* Another option that is similar, is to enclose the `case_when()` within the `factor()`:

```{r}
mouse_data <- mouse_data %>%
  mutate(time_month3 = factor(
    case_when(
      time=="tp1" ~ "1 month",
      time=="tp2" ~ "6 months",
      time=="tp3" ~ "12 months"
      ), 
    levels = c("1 month", "6 months", "12 months")
    ))

mouse_data %>% tabyl(time_month, time_month3)
```

##### `levels` vs. `labels`

* Emile suggested using `factor()` on the `time` variable directly, and creating the new values using the `labels` option within `factor()`:

```{r}
mouse_data <- mouse_data %>% 
  mutate(time_month4 = factor(time,
                             levels = c("tp1", "tp2", "tp3"),
                             labels = c("1 month", "6 months", "12 months")
                             ))

mouse_data %>% tabyl(time_month, time_month4)
```

* What is new her is that we have not previously discussed `labels`.
* You can think of the __`levels` as the input__ for the `factor()` function. 
    * It's how we specify what the different levels are for the variable we are converting to factor, as well as the __order we want the levels__ to be in.
    * If we do not specify the `levels`, then R will automatically use the different values of the variable being converted and arrange them in alphanumeric order. Example: 

```{r}
mouse_data <- mouse_data %>% 
  mutate(time_month5 = factor(time))

mouse_data %>% tabyl(time_month, time_month5)
```

* While `levels` is an input for the `factor()` function, __`labels` is an output__ for the `factor()` function.
* The values specified in `labels` are the new values for the levels:

```{r}
# time_month4 added labels
# time_month5 did not add labels

mouse_data %>% tabyl(time_month4, time_month5)

levels(mouse_data$time_month4)
levels(mouse_data$time_month5)
```

* Note that both `time_month4` and `time_month5` started with the same `levels`. 
* Instead of using the `labels` option within `factor()` (the base R way), we can also accomplish this by using `fct_recode()` from the `forcats` package (loaded as a part of `tidyverse`):

```{r}
# original tp levels:
levels(mouse_data$time_month5)

mouse_data <- mouse_data %>% 
  mutate(time_month6 = fct_recode(time_month5, 
                            # new_name = "old_name"
                                 "1 month" = "tp1", 
                                 "6 months" = "tp2", 
                                 "12 months" = "tp3"))

levels(mouse_data$time_month6)

mouse_data %>% tabyl(time_month6, time_month5)
```

* Learn more about `fct_recode()` [here](https://forcats.tidyverse.org/reference/fct_recode.html).



#### `%in%`

>`%in%` command, I feel like I understand but have some confusion and think it might just be one of those things I have to work with/apply to fully understand 

* We've used the `%in%` function in some examples, but I don't think we've discussed it in detail.

* The %in% function is used to __test whether elements of one vector are contained in another vector__. It returns a logical vector indicating whether each element of the first vector is found in the second vector.

* Below are some examples that ChatGPT generated (and I slightly edited). 

```{r}
#| warning: false

# Example 1: Using %in% with two numeric vectors
x <- c(1, 2, 3, 4, 5)
y <- c(2, 4, 6)

x %in% y

# Example 2: Using %in% with two character vectors
fruits <- c("apple", "banana", "orange", "grape")
selected_fruits <- c("banana", "grape", "kiwi")

selected_fruits %in% fruits

# Example 3: Using %in% with dataframe columns
library(tidyverse)

# Create a dataframe
df <- tibble(
  ID = c(1, 2, 3, 4, 5),
  fruit = c("apple", "banana", "orange", "grape", "kiwi")
)

df

# Filter rows where 'fruit' column contains values from selected_fruits
selected_fruits <- c("banana", "grape", "kiwi")

df_filtered <- df %>%
  filter(fruit %in% selected_fruits)

df_filtered

```




### Clearest points

> This class was all really clear. It was helpful to be reviewing some of the things we learned last week.

> I appreciate the new codes on how to clean/reshape/combine messy data. I think that was the hardest parts to do in the other Biostatistics courses during projects.

> Data cleaning

> Most of the data cleaning exercises. 

> different strategies to clean data sets

> The data cleaning made a lot of sense but I think I will struggle with solving problems in a really inefficient way.

> Everything before Challenge 3

> methods to merge datasets to create a table

> inner join and full join are the same if all vectors are the same.

> Pivot 

> ggplot and how to code data in to display what we want to display 





### Other comments


> Is there a difference between summarize (with z) and summarise (with s)?

Great question! 

* In English, summarize is American English and summarise is British English. * In R they work the same way. The [reference page for `summarise()`](https://dplyr.tidyverse.org/reference/summarise.html) lists them as synonyms.
* In R code I see summarise more, and now keep mixing up which is American and which is British. 
* In general, R accepts both American and British English, such as both color and colour. 

> Thank you for the survey reminders! The pace of the class feels much better compared to the pace at the beginning of the term

Thanks for the feedback!


> I really enjoyed the walk through from start to finish of how to clean the data sheet and it really helped clear up many of the commands I was previously confused about 

Thanks for the feedback! Glad the data wrangling walk through was helpful. 



## Week 8 (Part 7)

### When loading a dataset, what does <promise> mean?

This occurs when you use the `data()` function to load a data set from a package. Per the help on this function (`?data`):

> `data()` was originally intended to allow users to load datasets from packages for use in their examples, and as such it loaded the datasets into the workspace `.GlobalEnv`. This avoided having large datasets in memory when not in use: that need has been almost entirely superseded by lazy-loading of datasets.

```{r}
data("iris")  # this doesn't actually load the data set, but makes it available for use
head(iris)    # Once it's used it will appear in the Environment as an object.
```

### Challenge # 2

This was where we created a function to load 3 data sets, clean them, and convert them to long format. These are tasks we've seen in previous classes. In this challenge, the main takeaway was to see the DRY (Don't repeat yourself) concept at play. Instead of writing the code 3 times for each data set, we can create a function where we only write the cleaning code once, then use that function 3 times.

Reviewing the challenge solutions and taking more time to work through it on your own is a good idea. We went through it pretty quick in class. You won't usually be limited on time to get a function like that to work. In practice, if it's taking more time and too complicated, then it's fine to duplicate code so that you know it's working correctly. But, with very repetitive tasks, functions can make your code less prone to errors from copying and pasting.

If you have trouble getting your code to work for the challenges, office hours are great for helping to debug code. Else, sharing full code in an email or on Slack. 


### `purrr::pluck`

There was a specific question:

> `purrr::pluck` seems really useful, I wonder if you can tell it to pluck a specific record_ID?

The short answer is no. Not a specific ID. But if you know the *position* of the specific ID then you could. 

```{r}
# Load packages
library(tidyverse)

# Create sample data
df <- tibble::tibble(
  id = c("0001", "0002", "0003", "0004", "0005", "0006", "0007", "0008", "0009", "0010"), 
  sex = sample(x = c("M", "F"), size = 10, replace = TRUE), 
  age = sample(x = 18:65, size = 10, replace = TRUE)
  
)

df

# Say we want to extract ID 0003.

# With purrr::pluck we need to know that it's in the 3rd row of the ID column

purrr::pluck(df, 
             "id", 
             3)

# Gives an error
purrr::pluck(df, 
             "id", 
             "0003")


# More than likely in this scenario, you would use a filter:
df |> 
  dplyr::filter(id == "0003")




```

`purrr::pluck` was created to work with deeply nested data structures. Not necessarily data frames; there's probably a more appropriate function out there for the task.

### Lists -- general confusion

+ What do we do with lists? 
+ Using lists

We will get to work more with lists in Week 9 and get more opportunities to see how they are used.

Lists are more flexible and have the ability to handle various data structures which make them a powerful tool for organizing, manipulating, and representing complex data in R.


### Lists -- One bracket versus two brackets. 

One bracket `[ ]` and two brackets `[[ ]]` serves different purposes, primarily when accessing elements in a data structure like vectors, lists, or data frames.

#### **One Bracket `[ ]`:**

##### **Vectors:**

When used with a single bracket, you can use it to subset or extract elements from a vector.

```{r}
# Example with a vector
my_vector <- c(1, 2, 3, 4, 5)
my_vector[3]  # Extracts the element at index 3
```

##### **Data Frames:**

When used with a data frame, it can be used to extract columns or rows.

```{r}
# Example with a data frame

df <- tibble::tibble(
  name = c("Alice", "Bob", "Charlie"), 
  age = c(25, 30, 22)
  )

# Extract the age column
df["age"]

```

#### **Two Brackets `[[ ]]`:**

##### **Lists:**

When working with lists, double brackets are used to extract elements from the list. The result is the actual element, not a list containing the element.

```{r}
# Example with a list
my_list <- list(1, 
                c(2, 3), 
                "four")

my_list[[2]]  # Extracts the second element (a vector) from the list
```

Compare to using `[]`

```{r}
my_list[2]
```

`[[]]` returned the vector contained in that slot. `[]` returned a list containing the vector.

##### **Nested Data Structures:**

For accessing elements in nested data structures like lists within lists.

```{r}
# Example with a nested list
nested_list <- list(first = list(a = 1, b = 2), 
                    second = list(c = 3, d = 4))

nested_list

nested_list[[1]] # Extract the list contained in the first slot

nested_list[[1]][["b"]]  # Extracts the value associated with "b" in the first list
```

In summary, one bracket `[ ]` is used for general subsetting, whether it's extracting elements from vectors, columns from data frames, or specific elements from lists. On the other hand, two brackets `[[ ]]` are specifically used for extracting elements from lists and accessing elements in nested structures.

### How and when to use curly curly within a function

`{{ }}` will be covered in upcoming class lectures. We talked about it in Week 8 as a quick aside because a specific question came up. Not much detail was given intentionally as it is a separate topic for another day.


## Week 9 (Part 7)

### Matrices

> Not entirely sure how to read or make sense of matrices yet (maybe I should have payed more attention in algebra), like when we saw the structure of a matrix here in the class script: `str(output_model$coefficients)`

In R, matrices are two-dimensional data structures that can store elements of the same data type. They are similar to vectors but have two dimensions (rows and columns). They are widely used in various statistical and mathematical operations, making them a fundamental data structure in the R.

#### Basic way to create matrices

```{r}
# Create a matrix with values filled column-wise
(mat1 <- matrix(1:6, nrow = 2, ncol = 3, byrow = FALSE))

# Create a matrix with values filled row-wise
(mat2 <- matrix(1:6, nrow = 2, ncol = 3, byrow = TRUE))
```

#### Accessing elements of a matrix

```{r}
# Accessing individual elements
element <- mat1[1, 2]  # Row 1, Column 2
element
```

```{r}
# Accessing entire row or column
row_vector <- mat1[1, ]  # Entire first row
row_vector

col_vector <- mat1[, 2]  # Entire second column
col_vector
```

#### Convert to data.frame

```{r}
as.data.frame(mat1)
```

```{r}
library(tibble)
tibble::as_tibble(mat1)

# You can also name the columns (and the rows)

colnames(mat1) <- c("a", "b", "c")
mat1

tibble::as_tibble(mat1)

```


### `for()` loops

> Still a little confused about the for() loops...

For loops are a staple in programming languages, not just R. They are used when we want to repeat the same operation (or a set of operations) several times.

The basis syntax in R looks like:

```{r eval=FALSE}
for (variable in sequence) {
  # Statements to be executed for each iteration
}

```

Here's a breakdown of the components:

+ `variable`: This is a loop variable that takes on each value in the specified sequence during each iteration of the loop.

+ `sequence`: This is the sequence of values over which the loop iterates. It can be a vector, list, or any other iterable object.

+ Loop Body: The statements enclosed within the curly braces `{}` constitute the body of the loop. These statements are executed for each iteration of the loop.

#### Basic example

```{r}
for (i in 1:5) {
  print(i)
}
```

First iteration manually:

```{r}
i <- 1
print(i)
```

Second iteration manually:

```{r}
i <- 2
print(i)
```

Etc.

#### Adapted from [1st edition of R for Data Science](https://r4ds.had.co.nz/iteration.html#for-loops-vs.-functionals)

Here's a tibble for an example

```{r}
pacman::p_load(tidyverse)

df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

df
```

Using a copy and paste method to calculate the mean of each column would look something like this:

```{r}
median(df$a)
median(df$b)
median(df$c)
median(df$d)
```

But this breaks the rule of DRY ("Don't repeat yourself")

```{r}
output <- c()  # vector to store the results of the for loop

for (i in seq_along(df)) {
  
  output[i] <- median(df[[i]])
  
}

output


```


For loops in R are commonly used when you know the number of iterations in advance or when you need to iterate over a specific sequence of values. While for loops are useful, R also provides other ways to perform iteration, such as using vectorized operations (example below) and functions from the apply family (not covered). It's often recommended to explore these alternatives when working with R for better code efficiency and readability.

```{r}
# Creating two vectors
vector1 <- c(1, 2, 3, 4, 5)
vector2 <- c(6, 7, 8, 9, 10)

# Vectorized addition
result_addition <- vector1 + vector2
result_addition

# With a for loop
result_addition_for_loop <- c()

for (i in 1:length(vector1)) {
  
  result_addition_for_loop[i] <- vector1[i] + vector2[i]
  
}

result_addition_for_loop

```



### `na.rm` vs `na.omit`

> Is there a difference between na.rm and na.omit?

Yes, there is a difference. In R, they are used in different context.

1. `na.rm` (Remove)

`na.rm` is an *argument* found in various functions (e.g. `mean()`, `sum()`, etc.) that allows you to specify whether missing values (`NA` or `NaN`) should be removed before performing the calculation.

From the help for `mean()` (`?mean`): *a logical evaluating to TRUE or FALSE indicating whether NA values should be stripped before the computation proceeds.*

```{r}
# A vector with NA values
values_with_na <- c(1, 2, 3, NA, 5)

mean(values_with_na, na.rm = FALSE)  # Result will be NA

# Excluding NA values
mean(values_with_na, na.rm = TRUE)  # Result will be (1+2+3+5)/4 = 2.75

```

2. `na.omit` (Omit missing)

`na.omit` is a *function* that can be used to remove rows with missing values (`NA`) from a data frame or matrix.

```{r}
# Creating a data frame with NA values
df <- data.frame(A = c(1, 2, NA, 4), B = c(5, NA, 7, 8))

# NAs in the columns of the data frame
df

# Using na.omit to remove rows with NA values
df |> 
  na.omit()

```


### `purrr::map()`

> I am still a little foggy on the formatting of purrrmap and how to utilize it effectively.

The `purrr::map` function is used to apply a specified function to each element of a list or vector, returning the results in a new list.

#### Basic Syntax:

```{r}
#| eval: false
purrr::map(.x, .f, ...)
```

- **`.x`:** The input list or vector.

- **`.f`:** The function to apply to each element of `.x`.

- **`...`:** Additional arguments passed to the function specified in `.f`.

#### Key Features:

1. **Consistent Output:**
   - `map` returns a list, ensuring a consistent output format regardless of the input structure.

2. **Function Application:**
   - The primary purpose is to apply a specified function to each element of the input `.x`.

3. **Formula Interface:**
   - Supports a formula interface (`~`) for concise function specifications.

   `purrr::map(.x, ~ function(.))`

#### Example:

```{r}
# Sample list
my_list <- list(a = 1:3, 
                b = c(4, 5, 6), 
                c = rnorm(n = 3))

my_list

# Using map to square each element in the list
squared_list <- purrr::map(.x = my_list, 
                           .f = ~ .x ^ 2)

squared_list

```

In this example, the `map` function applies the squaring function (`~ .x ^ 2`) to each element of the input list `my_list`. The resulting `squared_list` is a list where each element is the squared version of the corresponding element in `my_list`.

The `purrr::map` function is particularly useful when working with lists and helps to create cleaner and more readable code, especially in cases where you want to apply the same operation to each element of a collection.


### General references

> Is there a good dictionary type document with "R language" or very basic function descriptions? ... find it difficult to know what functions I need because it is hard to recall their name or confuse it with a different function.

+ R Documentation (Built-in Help): R itself provides built-in documentation that you can access using the `help()` function or the `?` operator. For example, to get help on the `mean()` function, you can type `help(mean)` or `?mean` in the R console.
+ R Manuals and Guides: The official R documentation, including manuals and guides, is available on the R Project website: [R Manuals](https://cran.r-project.org/manuals.html).
+ R Packages Documentation: Many R packages come with detailed documentation. You can find documentation for a specific package by visiting the CRAN website (Comprehensive R Archive Network) and searching for the package of interest.
+ Online Resources: Websites like [RDocumentation](https://www.rdocumentation.org/) provide a searchable database of R functions along with their documentation. You can search for a specific function and find details on its usage and parameters.
+ [RStudio cheatsheets](https://posit.co/resources/cheatsheets/)
+ [Base R cheatsheet](https://iqss.github.io/dss-workshops/R/Rintro/base-r-cheat-sheet.pdf)
+ [R: A Language and Environment for Statistical Computing: Reference Index](https://cran.r-project.org/doc/manuals/r-release/fullrefman.pdf)
+ [CRAN Task Views](https://cran.r-project.org/web/views/)
+ Part 3 section on getting help with errors.
+ Books like ["R for Data Science"](https://r4ds.hadley.nz/) by Hadley Wickham
+ When you use a function or learn to use it, make notes to yourself using Google Doc or OneNote or something similar.



## Week 10 (Part 8)

### Confusion on details of `purrr::map()`

`purrr::map()` applies a function to each element of a vector or list and returns a new list where each element is the result of applying that function to the corresponding element of the original vector or list.

```{r}
#| eval: false

map(.x, .f, ..., .progress = FALSE)
```

+ `.x` the vector or list that you operate on
+ `.f` the function you want to apply to each element of the input vector or list. This function can be a built-in R function, a user-defined function, or an anonymous function defined on the fly.

#### Simple example

```{r}
#| message: false
library(tidyverse)

# Example list
numbers <- list(1, 2, 3, 4, 5)
numbers

# Using map to square each element of the list
squared_numbers <- purrr::map(.x = numbers, 
                              .f = ~ .x ^ 2)
```

In this example:
- `numbers` is a list containing numbers from 1 to 5.
- `~ .x ^ 2` is an anonymous function that squares its input.
- `map()` applies this anonymous function to each element of the `numbers` list, resulting in a new list where each element is the square of the corresponding element in the original list.

After executing this code, the `squared_numbers` variable will contain the squared values of the original list:

```{r}
squared_numbers
```


#### Example with a list of data frames

Suppose we have a list of data frames where each data frame represents the sales data for different products. We want to calculate the total sales for each product across all the data frames in the list.

```{r}
# Sample list of data frames
sales_data <- list(
  product1 = data.frame(month = 1:3, sales = c(100, 150, 200)),
  product2 = data.frame(month = 1:3, sales = c(120, 180, 220)),
  product3 = data.frame(month = 1:3, sales = c(90, 130, 170))
)

sales_data

```

Create a function `` and apply it to each slot in `sales_data` list:

```{r}
# Function to calculate total sales for each data frame
calculate_total_sales <- function(df) {
  total_sales <- sum(df$sales)
  return(total_sales)
}

# Applying the function to each data frame in the list
total_sales_per_product <- purrr::map(.x = sales_data, 
                                      .f = calculate_total_sales)
```

In this example:
- `sales_data` is a list containing three data frames, each representing the sales data for a different product.
- `calculate_total_sales()` is a function that takes a data frame as input and calculates the total sales for that product.
- `map()` applies the `calculate_total_sales()` function to each data frame in the `sales_data` list, resulting in a new list `total_sales_per_product`, where each element is the total sales for a specific product across all months.

After executing this code, the `total_sales_per_product` variable will contain the total sales for each product:

```{r}
total_sales_per_product
```


So, `total_sales_per_product` is a named list where each element represents the total sales for a specific product across all the data frames in the original list.


### `purrr::reduce()`

#### How does it compare to `purrr::map()`? 

The big difference between map() and reduce() has to do with what it returns:

> `map()` usually returns a list or data structure with the same number as its input; The goal of `reduce()` is to take a list of items and return a single object.

See the [purrr cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/purrr.pdf).


#### Simple example

```{r}
# Example vector
numbers <- c(1, 2, 3, 4, 5)
numbers

# Using reduce to calculate cumulative sum
cumulative_sum <- purrr::reduce(.x = numbers, 
                                .f = `+`)

```

In this example:
- `numbers` is the vector we want to operate on.
- The function `+` is used as the operation to perform at each step of reduction, which in this case is addition.
- `reduce()` will start by adding the first two elements (1 and 2), then add the result to the third element (3), and so on, until all elements have been processed.

After executing this code, the `cumulative_sum` variable will contain the cumulative sum of the numbers:

```{r}
cumulative_sum
```

The steps are as follows:

```{r}

(cum_numbers <- numbers[1])

(cum_numbers <- cum_numbers + numbers[2])

(cum_numbers <- cum_numbers + numbers[3])

(cum_numbers <- cum_numbers + numbers[4])

(cum_numbers <- cum_numbers + numbers[5])
```


#### With data frames

Using our sales data list from above

```{r}
sales_data
```

We can combined the data sets in the list with `reduce()` and `bind_rows()`

```{r}
# Using an anonymous function, note bind_rows takes 2 arguments.
combined_sales_data <- purrr::reduce(.x = sales_data, 
                                     .f = function(x, y) bind_rows(x, y))


# Using a named function
combined_sales_data <- purrr::reduce(.x = sales_data, 
                                     .f = dplyr::bind_rows)
```

In this example:
- We use an anonymous function within `reduce()` that takes two arguments `x` and `y`, representing the accumulated result and the next element in the list, respectively.
- Inside the anonymous function, we use `bind_rows()` to combine the accumulated result `x` with the next element `y`, effectively stacking them on top of each other.
- `reduce()` applies this anonymous function iteratively to the list of data frames, resulting in a single data frame `combined_sales_data` that contains the combined sales data for all products.

```{r}
combined_sales_data
```

Doing this in steps:

```{r}

(cum_sales_data <- dplyr::bind_rows(sales_data[[1]]))

(cum_sales_data <- dplyr::bind_rows(cum_sales_data, 
                                    sales_data[[2]]))

(cum_sales_data <- dplyr::bind_rows(cum_sales_data, 
                                    sales_data[[3]]))


```


#### Examples of reduce

+ [Pretty involved example from Maelle Salmon, but good practice](https://masalmon.eu/2023/07/26/reduce/)
+ [Tidyverse reference with examples](https://purrr.tidyverse.org/reference/reduce.html)
+ [R for Data Science, First Edition](https://r4ds.had.co.nz/iteration.html?q=reduce#reduce-and-accumulate)
+ [Another exmple blog post](https://yjunechoe.github.io/posts/2020-12-13-collapse-repetitive-piping-with-reduce/)


### List.files function

the `list.files()` function is used to obtain a character vector of file names in a specified directory. Here's a breakdown of how it works and its common parameters:

1. **Directory Path**: The primary argument of `list.files()` is the path to the directory you want to list files from. If not specified, it defaults to the current working directory.

2. **Pattern Matching**: `pattern` is an optional argument that allows you to specify a pattern for file names. Only file names matching this pattern will be returned. This can be useful for filtering specific types of files.

3. **Recursive Listing**: If `recursive = TRUE`, the function will list files recursively, i.e., it will include files from subdirectories as well. By default, `recursive` is set to `FALSE`.

4. **File Type**: The `full.names` argument controls whether the returned file names should include the full path (if `TRUE`) or just the file names (if `FALSE`, the default).

5. **Character Encoding**: You can specify the `encoding` argument to handle file names with non-ASCII characters. This argument is especially useful on Windows systems where file names may use a different character encoding.

Here's a simple example demonstrating the basic usage of `list.files()`:

```{r}
# List files in the current directory
files <- list.files()

# Print the file names
print(files)
```

This will print the names of all files in the current working directory.

```{r}

#| eval: false

# List CSV files in a specific directory
csv_files <- list.files(path = "path/to/directory", pattern = "\\.csv$")

# Print the CSV file names
print(csv_files)
```

This will print the names of all CSV files in the specified directory.

Overall, `list.files()` is a handy function for obtaining file names within a directory, providing flexibility through various parameters for customization according to specific needs, such as filtering by pattern or handling file names with non-standard characters.

**NOTE** You need to pay attention to your working directory and your relative file paths. See Week 2 or 3 (?) about `here` package and the discussion about files paths. Best to always use Rprojects and the `here` package.

