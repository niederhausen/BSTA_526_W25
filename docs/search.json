[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to BSTA 526!",
    "section": "",
    "text": "Welcome to BSTA 526!\n\nR Programming for Health Data Science\nWinter 2024\nOHSU-PSU School of Public Health\nOregon Health & Science University\n\n\n\n\n\n\n\nInstructors\n Meike Niederhausen, PhD\n niederha@ohsu.edu\n Emile Latour, MS\n latour@ohsu.edu\n\n\nCourse details\n Wednesdays\n 3:15 pm - 6:05 pm\n In-person\nSee schedule for room information\n\n\nOffice Hours\n\nSee Sakai for Webex links to office hours.\nMondays 3:00-4:00 pm (Emile)\nTuesdays 7:30-8:30 pm (Tia)\nWednesdays 6:05-7:05 pm (Tia) - Contact Tia to set up in-person option in classroom for Wed office hour\nFridays 3:30-4:30 pm (Meike; starting Feb 9th)\n\n\n\n\n\nContacting us\nE-mail or Slack is the best way to get in contact with us.\nWe will try to respond to all course-related e-mails within 24 hours Monday-Friday.\n\n\n\n\n\n\n\n\n View the source on GitHub"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Assistant Professor of Biostatistics in the OHSU-PSU School of Public Health\nFaculty Biostatistician for OHSU’s Biostatistics & Design Program\nAffiliate Investigator for the HSR&D Center to Improve Veteran Involvement in Care (CIVIC) at the Portland VA\n\n\n\n\n\nSenior Biostatistician in the Biostatistics Shared Resource of OHSU’s Knight Cancer Institute."
  },
  {
    "objectID": "about.html#instructors",
    "href": "about.html#instructors",
    "title": "About",
    "section": "",
    "text": "Assistant Professor of Biostatistics in the OHSU-PSU School of Public Health\nFaculty Biostatistician for OHSU’s Biostatistics & Design Program\nAffiliate Investigator for the HSR&D Center to Improve Veteran Involvement in Care (CIVIC) at the Portland VA\n\n\n\n\n\nSenior Biostatistician in the Biostatistics Shared Resource of OHSU’s Knight Cancer Institute."
  },
  {
    "objectID": "about.html#course-info",
    "href": "about.html#course-info",
    "title": "About",
    "section": "Course info",
    "text": "Course info\nThis webpage was created for BSTA 526 (R Programming for Health Data Science) in the OHSU-PSU School of Public Health."
  },
  {
    "objectID": "about.html#acknowledgements",
    "href": "about.html#acknowledgements",
    "title": "About",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\nBSTA 526 class materials\n\nBSTA 526 was taught in previous years as BSTA 504 by Ted Laderas (2021) and Jessica Minnier (2022, 2023).\nAlmost all course materials were created by Ted and Jessica with minor changes for BSTA 526 (such as updating from RMarkdown to Quarto). Their work is licensed under a Creative Commons Attribution 4.0 International License. See previous class websites linked to above for links to their source code on GitHub.\n\n\n\nQuarto webpage\n\nThank you to Nicky Wakim for creating her amazing webpage for BSTA 550, and sharing her code on GitHub. Having her template made creating this website a much smoother process.\nThank you also to Andrew Bray for presenting the From R Markdown to Quarto ASA Travelling Workshop to the Oregon Chapter of the ASA in June 2023. This workshop was a great starting point in making the switch from RMarkdown to Quarto and also create Quarto webpages."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Schedule is subject to change.\nLinks have been added to all weeks, but weeks we have not covered yet will have broken links.\n\n\n\n\nWeek\nDate\nTopics\nClassroom\nInstructor\n\n\n\n\n1\n1/10\nIntroduction to course/expectations, Intro to R/RStudio, Functions, Vectors, Data Types\nRLSB 2S014/ 2S018\nMeike\n\n\n2\n1/17\nLoading Data, data.frames, and ggplot2\nRPV 1217\nMeike\n\n\n3\n1/24\ndplyr: subsetting using filter()/select()\nRLSB 2S014/ 2S018\nEmile\n\n\n4\n1/31\ndplyr: mutate(),across(), case_when(), factors, ggplot2 boxplots, facets, scales\nRPV 1217\nEmile\n\n\n5\n2/7\nsummarize() and group_by(), doing things with multiple tables (left_join() etc), reshaping data (i.e. pivot_longer())\nRLSB 2S014/ 2S018\nMeike\n\n\n\n2/7\nTake Home Midterm Assigned\n\n\n\n\n6\n2/14\nMore data wrangling practice\nRPV 1217\nMeike\n\n\n\n\n\n\n\n\n\n7\n2/21\nMore data wrangling practice\nRPV 1217\nMeike\n\n\n\n2/25\nTake home midterm due (Sunday)\n\n\n\n\n8\n2/28\nIntro to functions, working with lists\nRPV 1217\nEmile\n\n\n9\n3/6\nIntro to functions, working with lists cont’d\nRLSB 2S014/ 2S018\nEmile\n\n\n10\n3/10\nFinal Project Assigned (Monday)\n\n\n\n\n10\n3/13\nFunctions/batch processing/purrr; Intro to stats/formulas/broom/More Purrr\nRPV 1217\nEmile\n\n\n11\n3/20\nNo Class, Office Hour\nRPV 1217\n\n\n\n\n3/22\nFinal Project Due"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course aims to develop programming skills in R, a powerful statistical programming language. This course assumes some prior familiarity with R and ranges from advanced beginner topics to intermediate topics. It will cover practical data science skills in R that are useful for a career in statistics, epidemiology, or data science, including loading data, data wrangling, visualization, automation, machine learning, and running statistical models. A laptop is required for class to participate in coding exercises."
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "",
    "text": "This course aims to develop programming skills in R, a powerful statistical programming language. This course assumes some prior familiarity with R and ranges from advanced beginner topics to intermediate topics. It will cover practical data science skills in R that are useful for a career in statistics, epidemiology, or data science, including loading data, data wrangling, visualization, automation, machine learning, and running statistical models. A laptop is required for class to participate in coding exercises."
  },
  {
    "objectID": "syllabus.html#credit-hours",
    "href": "syllabus.html#credit-hours",
    "title": "Syllabus",
    "section": "Credit Hours",
    "text": "Credit Hours\n3 credit hours."
  },
  {
    "objectID": "syllabus.html#learning-objectives",
    "href": "syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand and utilize R/RStudio, including using Quarto to create reproducible documents of statistical analyses.\nUnderstand basic data types and data structures in R.\nFamiliarize and load data files (Excel, Comma Separated Value files) into R/Rstudio, with tips on formatting.\nVisualize datasets using ggplot2 and understand how to build basic plots using ggplot2 syntax.\nFilter and format data in R for use with various routines.\nRun and Interpret some basic statistics in R.\nAutomate repetitive tasks in R, such as loading a folder of files.\n\nIf time allows:\n\nCreate nice tables in our R markdown reports with gt and/or kableExtra."
  },
  {
    "objectID": "syllabus.html#course-website",
    "href": "syllabus.html#course-website",
    "title": "Syllabus",
    "section": "Course Website",
    "text": "Course Website\nAll course information will be available here:\nhttps://niederhausen.github.io/BSTA_526_W24/\nInformation will also be available on Sakai.\nSlack will be used for course discussions. Link to join Slack is posted on Sakai."
  },
  {
    "objectID": "syllabus.html#office-hours",
    "href": "syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "Office Hours",
    "text": "Office Hours\n\nSee Sakai for Webex links to office hours\nIn addition to times below, office hours can be set up by appointment at other times. Please email or message on Slack whom who would like to set up an office hour with.\nMondays 3:00-4:00 pm (Emile)\nTuesdays 7:30-8:30 pm (Tia)\nWednesdays 6:05-7:05 pm (Tia) - Contact Tia to set up in-person option in classroom for Wed office hour\nFridays 3:30-4:30 pm (Meike; starting Feb 9th)"
  },
  {
    "objectID": "syllabus.html#prerequisites-or-concurrent-enrollment-requirements",
    "href": "syllabus.html#prerequisites-or-concurrent-enrollment-requirements",
    "title": "Syllabus",
    "section": "Prerequisites or Concurrent Enrollment Requirements",
    "text": "Prerequisites or Concurrent Enrollment Requirements\n\nBSTA 511 or permission by instructor."
  },
  {
    "objectID": "syllabus.html#instructor-information",
    "href": "syllabus.html#instructor-information",
    "title": "Syllabus",
    "section": "Instructor Information",
    "text": "Instructor Information\n\nInstructors\n\nPreferred Method of Contact: Email or Slack. When emailing, please include BSTA 526 in the subject line.\n\nExpected Response Time: 1 business day\nMeike Niederhausen, PhD\n\nniederha@ohsu.edu\n\nEmile Latour, MS\n\nlatour@ohsu.edu\n\n\n\n\nTeaching Assistant\n\nTia Vafeas\n\nvafeas@ohsu.edu"
  },
  {
    "objectID": "syllabus.html#attendance",
    "href": "syllabus.html#attendance",
    "title": "Syllabus",
    "section": "Attendance",
    "text": "Attendance\n\nThis class will meet in-person and you are expected to attend class regularly. However, we understand that it is not always possible to attend class and daily attendance will not be monitored.\nClasses will be recorded, but we cannot guarantee the in-person format will lend itself to effective recordings. If you miss class, please reach out to a classmate for missed material.\n\n\nPost-class surveys\n\n5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\nThe questions on the survey are:\n\nRating the pace of the lecture and lab\nClearest Point: What point of the class was clearest for you?\nMuddiest Point: What point of class was the muddiest (unclear) for you?\nAnything Else: Anything else you’d like me to know?"
  },
  {
    "objectID": "syllabus.html#homework",
    "href": "syllabus.html#homework",
    "title": "Syllabus",
    "section": "Homework",
    "text": "Homework\nHomework will be assigned weekly using Quarto in RStudio. It will be due via Sakai upload Wednesdays at 11:55pm the night of the following week’s class (unless otherwise noted). Please turn in both your .qmd and rendered .html file.\nThe homework with the lowest score will be dropped from your homework average.\n\nLate Policy\nStudents get 1 free homework assignment to submit late within 3 days without penalties. Please email the instructors and the TA that you need more time. If you need an accommodation, please email us so we can figure out a way to help you."
  },
  {
    "objectID": "syllabus.html#function-of-the-week",
    "href": "syllabus.html#function-of-the-week",
    "title": "Syllabus",
    "section": "Function of the Week",
    "text": "Function of the Week\nPlease choose a function from the Function of the Week sign-up sheet (link will be posted on Sakai). A Quarto template to format your Function of the Week and presentation will be provided. Function of the Week presentations will start in week 4. On the sign-up sheet you will choose a week to present your function to the class, as well as the function. The presentation should be short, around 5 minutes. If presenting to the class feels prohibitive, you may submit a 5-10 minute screen recording with your voice narrating the presentation, and this will be distributed to the class.\nPrevious years’ Functions of the Week can be found on the previous class websites:\n\nhttps://sph-r-programming-2023.netlify.app/functions/\nhttps://sph-r-programming-2022.netlify.app/functions/\nhttps://sph-r-programming.netlify.app/functions/ (2021)\n\nWe will create a similar website for this year’s Functions of the Week. If you do not wish yours to be on the public facing website, just let us know. Alternatively, we can also post it anonymously. See submitted Functions of the Week for this quarter at this link."
  },
  {
    "objectID": "syllabus.html#midterm-and-final-projects",
    "href": "syllabus.html#midterm-and-final-projects",
    "title": "Syllabus",
    "section": "Midterm and Final Projects",
    "text": "Midterm and Final Projects\n\nMidterm and final projects/tests will be take home.\n\nThe midterm will be a project based on a dataset of your choosing.\n\nThe final will be based on an assigned dataset.\n\nPrevious years’ midterms can be found on the class websites:\n\nhttps://sph-r-programming-2023-midterms.netlify.app/\nhttps://sph-r-programming-2022-midterms.netlify.app/\nhttps://sph-midterm-projects.netlify.app/ (2021)\nWe will create a similar website for this year’s midterm projects.\n\nIf you do not wish your project to be on the public facing website, just let us know. Alternatively, we can also post it anonymously."
  },
  {
    "objectID": "syllabus.html#grading-policy",
    "href": "syllabus.html#grading-policy",
    "title": "Syllabus",
    "section": "Grading Policy",
    "text": "Grading Policy\n\nAttendance (based on post-class surveys) 5%\nMidterm Project 20%\nFunction of the Week 10%\nHomework Assignments 45%\nFinal Project 20%\n\n\nGrading Scale\n\nAssessments will be graded on a 10 pt scale (0-10 points).\nA weighted average of the grade will be calculated using the percentages listed above, and final grades will be assigned based on the table below. Scores will be rounded up; for example an average of 7.5 will be assigned an A-.\n\n\n\n\n\nPoints\nLetter Grade\n\n\n\n\n10\nA\n\n\n9\nA\n\n\n8\nA-\n\n\n7\nB+\n\n\n6\nB\n\n\n5\nB-\n\n\n4\nC+\n\n\n3\nC\n\n\n2\nC-\n\n\n1\nD\n\n\n0\nF\n\n\n\nIn assigning points 0-10, the following general guidelines will be applied:\n\n\n\n\nA\nExceeds the standard\n\n\nB\nMeets the standard\n\n\nC\nKey gaps in understanding of the standard\n\n\nD\nUnable to demonstrate B or C without assistance\n\n\nF\nNo evidence\n\n\n\nThis rubric was adapted from Chapter 12 of Grading for Equity by Joe Feldman.\n\n\nGrading Rubric\n\nAssessments will be graded on a 10 pt scale (0-10 points) using the rubric below.\nThe 10 pts for each assessment will be based on:\n\nAnswers: 4 pts\nDemonstrating process: 3 pts\nProviding context and relevance: 3 pts\n\n\nThe table below will be used to determine points for each of the three categories.\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\nAnswers\n(4 pts max)\nAnswers are correct at least 90% of the time\nAnswers are usually correct (75-90%)\nAnswers are sometimes correct (50-74%)\nAnswers are generally incorrect (&lt;50%)\nAnswers are incorrect and no work was shown (demonstrating process has 0 pts)\n\n\nDemonstrating process\n(3 pts max)\n\nAll relevant work is shown, including all steps for figuring out answers.\nR code and output are provided for every question for which R was used.\nRelevant work and steps for figuring out answers are generally provided but incomplete.\nR code and output are generally provided but incomplete for questions that use R.\nRelevant work and steps for figuring out answers are generally missing.\nR code and output are generally missing for questions that use R.\nNo relevant work is shown, including steps for figuring out answers.\nR code and output are not provided for questions for which R was used.\n\n\nProviding context and relevance\n(3 pts max)\n\nAnswers are given in complete sentences with all relevant information for the question as appropriate (context of research question, units, descriptive statistics, explanation of what data visualization is showing, confidence intervals, p-values, test- statistics, etc.), and interpretation of results.\nAnswers are given in complete sentences. Some relevant information may be provided, but much is missing. Context of research question only sometimes provided.\nAnswers are rarely given in complete sentences. Relevant information is not provided. Little to no context is provided.\nAnswers are not in complete sentences. Relevant information and context are not provided."
  },
  {
    "objectID": "syllabus.html#code-of-conduct",
    "href": "syllabus.html#code-of-conduct",
    "title": "Syllabus",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nThis class is governed by the BioData Club Code of Conduct: https://biodata-club.github.io/code_of_conduct/\nAnd as students of an OHSU course, we must abide by the OHSU Code of Conduct: https://www.ohsu.edu/integrity-department/code-conduct\nThis class is meant to be a psychologically safe space where it’s ok to ask questions. We want to normalize your own curiosity and fuel your desire to learn more.\nThere is a link on Sakai to a form to anonymously report to us any possible code of conduct violations, based on the OHSU Code of Conduct or the OHSU Biodata Code of Conduct."
  },
  {
    "objectID": "syllabus.html#required-texts-and-readings",
    "href": "syllabus.html#required-texts-and-readings",
    "title": "Syllabus",
    "section": "Required Texts and Readings",
    "text": "Required Texts and Readings\nWe will be drawing on the following online textbooks during class and labs. These books are online and free, though you can order them as textbooks if you prefer that format.\n\nR for Data Science. Garret Grolemund and Hadley Wickham. 2nd Edition. https://r4ds.hadley.nz/\nGetting Used to R, RStudio, and RMarkdown. Chester Ismay. https://ismayc.github.io/rbasics-book/\nData Science: A First Introduction. Tiffany Timbers, Trevor Campbell, Melissa Lee. https://datasciencebook.ca/\nRMarkdown for Scientists. Nick Tierney. https://rmd4sci.njtierney.com/\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse. Chester Ismay and Albert Y. Kim. https://moderndive.com/\nAdvanced R. Hadley Wickham. https://adv-r.hadley.nz/\nQuarto webpage https://quarto.org/\n\nThe Guide and Reference tabs have very helpful documentation.\n\n\n\nNote on RMarkdown vs. Quarto\n\nWe will be using the newer Quarto instead of RMarkdown for creating reproducible documents. Some of the links above are for RMarkdown, which is very similar.\n\nThe main differences are in setting up the yaml and code chunk options.\nMany of the RMarkdown code chunk options work with Quarto though.\nWith Quarto you will see a Render button instead of a Knit button to create the html output of the file."
  },
  {
    "objectID": "syllabus.html#words-of-encouragement",
    "href": "syllabus.html#words-of-encouragement",
    "title": "Syllabus",
    "section": "Words of Encouragement",
    "text": "Words of Encouragement\n\nThis was adopted from Andrew Heiss. Thanks!\n\nI promise you can succeed in this class.\nLearning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like ggplot2—made this wise observation:\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\nEven experienced programmers find themselves bashing their heads against seemingly intractable errors. If you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, e-mail us, etc.\n\n\n\nAlison Horst Jan 3, 2020 tweet\n\n\n\n\n\nAlison Horst: Gator error"
  },
  {
    "objectID": "syllabus.html#learning-is-social",
    "href": "syllabus.html#learning-is-social",
    "title": "Syllabus",
    "section": "LeaRning is Social",
    "text": "LeaRning is Social\nStudents who struggle in courses often are ones who don’t work with each other to learn. We are a learning community, and we should help each other to learn.\nIf you understand something and know someone is struggling with it, try and help them. If you are struggling, take a breath, and try to pinpoint what you are struggling with.\nOur goal is to be better programmers each day, not to be the perfect programmer. There’s no such thing as a perfect programmer. We’ve been learning new things almost every day."
  },
  {
    "objectID": "syllabus.html#copyright-information",
    "href": "syllabus.html#copyright-information",
    "title": "Syllabus",
    "section": "Copyright Information",
    "text": "Copyright Information\nEvery reasonable effort has been made to protect the copyright requirements of materials used in this course. Class participants are warned not to copy, audio, or videotape in violation of copyright laws.\nJournal articles will be kept on reserve at the library or online for student access. Copyright law does allow for making one personal copy of each article from the original article. This limit also applies to electronic sources.\nTo comply with the fair use fair use doctrine of the US copyright law, Sakai course sites close three weeks after grades are posted with the Registrar. Please be sure to download all course material you wish to keep before this time as you will have no further access to your courses."
  },
  {
    "objectID": "syllabus.html#school-of-public-health-handbook",
    "href": "syllabus.html#school-of-public-health-handbook",
    "title": "Syllabus",
    "section": "School of Public Health Handbook",
    "text": "School of Public Health Handbook\nAll students are responsible for following the policies and expectations outlined in the student handbook for their program of study. Students are responsible for their own academic work and are expected to have read and practice principles of academic honesty, as presented in the handbook: https://ohsu-psu-sph.org/current-graduate-students/policies-procedures/#academic-dishonesty."
  },
  {
    "objectID": "syllabus.html#syllabus-changes-and-retention",
    "href": "syllabus.html#syllabus-changes-and-retention",
    "title": "Syllabus",
    "section": "Syllabus Changes and Retention",
    "text": "Syllabus Changes and Retention\nThis syllabus is not to be considered a contract between the student and the School of Public Health. It is recognized that changes may be made as the need arises. Students are responsible for keeping a copy of the course syllabus for their records.\nSyllabi are considered to be a learning agreement between students and the faculty of record. Information contained in syllabi, other than the minimum requirements, may be subject to change as deemed appropriate by the faculty of record in concurrence with the academic program and the Office of the Provost. Refer to the Course Syllabi Policy, 02-50-050."
  },
  {
    "objectID": "syllabus.html#syllabus-statement-regarding-disability-services",
    "href": "syllabus.html#syllabus-statement-regarding-disability-services",
    "title": "Syllabus",
    "section": "Syllabus Statement Regarding Disability Services",
    "text": "Syllabus Statement Regarding Disability Services\nOHSU is committed to providing equal access to qualified students who experience a disability in compliance with Section 504 of the Rehabilitation Act of 1973, the Americans with Disabilities Act (ADA) of 1990, and the ADA Amendments Act (ADA-AA) of 2008. If you have a disability or think you may have a disability (physical, sensory, chronic health, psychological or learning) please contact the Office for Student Access at (503) 494-0082 or studentaccess@ohsu.edu to discuss eligibility for academic accommodations. Information is also available at www.ohsu.edu/student-access. Because accommodations may take time to implement and cannot be applied retroactively, it is important to have this discussion as soon as possible. All information regarding a student’s disability is kept in accordance with relevant state and federal laws.\nPlease see Student Access & Accomodations section for more details on the Sakai version of this Syllabus."
  },
  {
    "objectID": "syllabus.html#commitment-of-equity-and-inclusion",
    "href": "syllabus.html#commitment-of-equity-and-inclusion",
    "title": "Syllabus",
    "section": "Commitment of Equity and Inclusion",
    "text": "Commitment of Equity and Inclusion\nThe School of Public Health is committed to providing an environment free of all forms of prohibited discrimination and discriminatory harassment. The School of Public Health students who have questions about an incident related to Title IX are welcome to contact either the OHSU or PSU’s Title IX Coordinator and they will direct you to the appropriate resource or office. Title IX pertains to any form of sex/gender discrimination, discriminatory harassment, sexual harassment or sexual violence.\nPSU’s Title IX Coordinator is Julie Caron, she may be reached at titleixccordinator@pdx.edu or 503-725-4410. Julie’s office is located at 1600 SW 4th Ave, In the Richard and Maureen Neuberger Center RMNC - Suite 830.\nThe OHSU Title IX Coordinator’s may be reached at 503-494-0258 or titleix@ohsu.edu and is located at 2525 SW 3rd St.\nPlease note that faculty and the Title IX Coordinators will keep the information you disclose private but are not confidential. If you would like to speak with a confidential advocate, who will not disclose the information to a university official without your written consent, you may contact an advocate at PSU or OHSU.\nPSU’s confidential advocates are available in Women’s Resource Center (serving all genders) in Smith Student Memorial Union 479. You may schedule an appointment by (503-725-5672) or schedule on line at https://psuwrc.youcanbook.me. For more information about resources at PSU, please see PSU’s Response to Sexual Misconduct website.\nOHSU’s advocates are available through the Confidential Advocacy Program (CAP) at 833-495-CAPS (2277) or by email CAPsupport@ohsu.edu, but please note, email is not a secure form of communication. Also visit www.ohsu.edu/CAP.\nAt OHSU, if you encounter any harassment, or discrimination based on race, color, religion, age, national origin or ancestry, veteran or military status, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity or expression, disability or any other protected status, please contact the Affirmative Action and Equal Opportunity (AAEO) Department at 503- 494-5148 or aaeo@ohsu.edu.\nAt PSU, you may contact the Office of Equity and Compliance if you experience any form of discrimination or discriminatory harassment as listed above at equityandcompliance@pdx.edu or by calling 503-725-5919."
  },
  {
    "objectID": "syllabus.html#academic-honesty",
    "href": "syllabus.html#academic-honesty",
    "title": "Syllabus",
    "section": "Academic Honesty",
    "text": "Academic Honesty\n\nCourse participants are expected to maintain academic honesty in their course work. Participants should refrain from seeking past published solutions to any assignments. Literature and resources (including internet resources and generative AI) employed in fulfilling assignments must be cited.\n\nSee Purdue University’s Online Writing Lab for resources on plagiarism and importantly avoiding plagiarism (thanks to Steve Bedrick for this link!).\nAssignments suspected of plagiarism (including copying past solutions or another student’s assignment) will receive 0 points for the assignment and the dean of the student’s academic program will be notified.\n\nIn an effort to uphold the principles and practice of academic honesty, faculty members at OHSU may use originality checking systems such as Turnitin to compare a student’s submitted work against multiple sources.\n\nTo protect student privacy in this process, it will be necessary to remove all personal information, i.e. student name, email address, student u-number, or any other personal information, from documents BEFORE submission.*\n\n\n\nUse of ChatGPT or other generative AI for assignments\nChatGPT and other generative AI tools can be great resources for learning how to code and/or troubleshoot code that does not work. However, the work you turn in must be your own. Thus it is inappropriate to directly ask AI to provide you with solutions to homework questions or write text that you are submitting in your assignment. If you do use AI tools to help you with an assignment, these must be cited along with how they were used.\nPlease see the Plagiarism & Attribution section (Code Snippets and AI Tools subsection) of Dr. Steve Bedrick’s BMI 525: Principles and Practice of DataVisualization webpage for examples of appropriate and inappropriate uses generative AI."
  },
  {
    "objectID": "syllabus.html#use-of-sakai",
    "href": "syllabus.html#use-of-sakai",
    "title": "Syllabus",
    "section": "Use of Sakai",
    "text": "Use of Sakai\nSakai is OHSU’s online course management system. Some course information will only be available on Sakai, and you will be turning in assignments using Sakai. For any technical questions or if you need help logging in, please contact the Sakai Help Desk. See also the Sakai Student Guide for more information.\n\nHours: Sakai Help Desk is available Mon – Fri, 8 am – 5 pm, Pacific Time.\nContact Information:\n\n(Toll-free) 877-972-5249\n(Web) http://atech.ohsu.edu/help\n(Email) sakai@ohsu.edu"
  },
  {
    "objectID": "weeks.html",
    "href": "weeks.html",
    "title": "Weekly Pages",
    "section": "",
    "text": "Links to weekly pages\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n1/10/24\n\n\nWeek 1\n\n\nIntro to R/RStudio, Functions, Vectors, Data Types\n\n\n\n\n1/17/24\n\n\nWeek 2\n\n\nProjects, data frames, reading in data, visualizing data with ggplot2\n\n\n\n\n1/24/24\n\n\nWeek 3\n\n\nErrors, more data loading, data manipulation, ggplot themes, factors\n\n\n\n\n1/31/24\n\n\nWeek 4\n\n\nmutate(), case_when(), more ggplot2\n\n\n\n\n2/7/24\n\n\nWeek 5\n\n\nData summarizing, reshaping, and wrangling with multiple tables\n\n\n\n\n2/14/24\n\n\nWeek 6\n\n\nStart with your goal: more data wrangling\n\n\n\n\n2/21/24\n\n\nWeek 7\n\n\nStart with your goal: more data wrangling\n\n\n\n\n2/28/24\n\n\nWeek 8\n\n\nLists and Functions\n\n\n\n\n3/6/24\n\n\nWeek 9\n\n\nLists and Functions (continued)\n\n\n\n\n3/13/24\n\n\nWeek 10\n\n\nIntro to stats, broom, more purrr\n\n\n\n\n3/20/24\n\n\nWeek 11\n\n\nFinal week\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "readings.html",
    "href": "readings.html",
    "title": "Readings",
    "section": "",
    "text": "Links to weekly readings\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n1/10/24\n\n\nWeek 1 Readings\n\n\nIntroduction to R/RStudio/Vectors\n\n\n\n\n1/17/24\n\n\nWeek 2 Readings\n\n\nLoading data, data.frames, and ggplot2\n\n\n\n\n1/24/24\n\n\nWeek 3 Readings\n\n\nggplot2, factors, boxplots, dplyr: subsetting using filter()/select()\n\n\n\n\n1/31/24\n\n\nWeek 4 Readings\n\n\ndplyr: mutate(), across(), ggplot: faceting, scales\n\n\n\n\n2/7/24\n\n\nWeek 5 Readings\n\n\nsummarize() and group_by(), doing things with multiple tables (left_join() etc), reshaping data (i.e. pivot_longer())\n\n\n\n\n2/14/24\n\n\nWeek 6 Readings\n\n\nMore practice with data wrangling\n\n\n\n\n2/21/24\n\n\nWeek 7 Readings\n\n\nMore practice with data wrangling\n\n\n\n\n2/28/24\n\n\nWeek 8 Readings\n\n\nLists and Functions\n\n\n\n\n3/6/24\n\n\nWeek 9 Readings\n\n\nIntro to stats/broom/More Purrrs\n\n\n\n\n3/13/24\n\n\nWeek 10 Readings\n\n\nMore stats, broom, and tables (gt, gtsummary)\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "weeks/week_01.html",
    "href": "weeks/week_01.html",
    "title": "Week 1",
    "section": "",
    "text": "Introduction to course/expectations (syllabus)\nIntro to R & RStudio\n\nHandout with directions on installing R & RStudio\n\nIntroduction to Quarto\nFunctions, Vectors, Data Types"
  },
  {
    "objectID": "weeks/week_01.html#topics",
    "href": "weeks/week_01.html#topics",
    "title": "Week 1",
    "section": "",
    "text": "Introduction to course/expectations (syllabus)\nIntro to R & RStudio\n\nHandout with directions on installing R & RStudio\n\nIntroduction to Quarto\nFunctions, Vectors, Data Types"
  },
  {
    "objectID": "weeks/week_01.html#announcements",
    "href": "weeks/week_01.html#announcements",
    "title": "Week 1",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared OneDrive folder BSTA_526_W24_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_01, and then open RStudio by double-clicking on the file called part_01.Rproj.\nPlease join the BSTA 526 Slack channel and introduce yourself by posting in the #random channel."
  },
  {
    "objectID": "weeks/week_01.html#class-materials",
    "href": "weeks/week_01.html#class-materials",
    "title": "Week 1",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nOne Drive part_01 Project folder"
  },
  {
    "objectID": "weeks/week_01.html#post-class-survey",
    "href": "weeks/week_01.html#post-class-survey",
    "title": "Week 1",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_01.html#homework",
    "href": "weeks/week_01.html#homework",
    "title": "Week 1",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 1 due on 1/17."
  },
  {
    "objectID": "weeks/week_01.html#recording",
    "href": "weeks/week_01.html#recording",
    "title": "Week 1",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_01.html#muddiest-points",
    "href": "weeks/week_01.html#muddiest-points",
    "title": "Week 1",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nClass logistics\n\nWill there be presentation slides in future classes, or is everything embedded into the quarto/html files for all lectures?\n\nThe material will primarily be in quarto/html files and not slides.\n\nSpecifics of what topics will be covered exactly. * I don’t have a list of all the specific functions we will be covering, but you are welcome to peruse the BSTA 504 webpage from Winter 2023 to get more details on topics we will be covering. We will be closely following the same class materials.\nIdentifying which section of the code we were discussing during the lecture\n\nThanks for letting me know. I will try to be clearer in the future, and also jump around less. Please let me know in class if you’re not sure where we are at.\n\nThe material covered towards the end of the class felt a bit difficult to keep up with. I wish we would have been told to read the materials from Week 1 (or at least skim them) ahead of Day 1, because I quickly lost track of the conversation when shortcuts were used super quickly, for example, or when we jumped from chunks of code to another topic without reflecting on them. I still had 70% of the material down and I wrote great notes during the discussion (which I later filled in with the script that was on the class website), but I think it the beginner/intermediate programming lingo that was used to explain ideas here confused me at times. Thus, I struggled to keep up with discussions around packages / best coding practices, especially when they were not mentioned directly on the script (where I could follow along!).\n\nThanks for the feedback. In future years, we will reach out to students before the term to let them know about the readings to prepare for class. Please let us know if there is lingo we are using that you are not familiar with. Learning R and coding is a whole new language!\n\n\n\n\nRStudio\n\nI have trouble thinking through where things are automatically downloaded, saved, and running from. I can attend office hours for this!\n\nOffice hours are always a great idea. I do recommend paying close attention to where files are being saved when downloading and preferably specifying their location instead using the default location. Having organized files will make working on complex analyses much easier.\n\nHow to read the course material in R. While it made sense in real time it may be difficult when going back over the material.\n\nGetting used to reading code and navigating the rendered html files takes a while, and is a part of learning R. Figuring out how to take notes for yourself that works for you is also a learning curve. I recommend taking notes in the qmd files as we go through them in class. After class you can summarize and transfer key points to other file formats that you are more used to using. I personally have a folder in my Google drive filled with documents on different R programming topics. It started with one file, and then eventually expanded to multiple files on different topics in an attempt to organize my notes better. Whenever I learn something new (such as an R function or handy R package) that I want to keep for future reference, I add to them with links to relevant webpages and/or filenames and locations of where I used them.\n\n\n\n\nCode\n\nWhat does the pacman package do? I have it installed but I’m not sure what it is actually used for.\n\nI didn’t go into pacman in Day 1. The p_load() function from the pacman package (usually run as pacman::p_load()) lets you load many packages at once without separately using the library() function for each individually.\nAn added bonus is that by default it will install packages you don’t already have, unless you specify install = FALSE.\nAnother option is to set update = TRUE so that it will automatically update packages. I do not use this option though since sometimes updating packages causes conflicts with other packages or older code.\nYou can read more about the different options in the documentation. This Medium article also has some tips on using pacman.\n\nThe part on when to load in packages once they’ve already been loaded in - like for example would it be good to put that as a step in our homework 1 .qmd at the top? Or not necessary since they’re already loaded in to R Studio from the work we did in class yesterday? What would happen if we try to load them in and they were already loaded in, would the .qmd file not render and show an error?\n\nI always load my packages at the very top of the .qmd files, usually in the first code chunk (with the setup label). If you still have a previous R session open, then yes you don’t need to load the packages again to run code within RStudio. However, when a file is rendered it starts with an empty workspace, which is why our qmd file must include code that loads the packages (either using library() or pacman::p_load(). We don’t have to load packages at the beginning of the file, just before we have code that depends on the packages being used.\n\nI didn’t understand the part where we talked about num, char, logical combinations (line 503).\n\nThe content of the objects char_logical, num_char, num_logical, and tricky were designed specifically to be confusing and thus make us aware of how R will decide to assign the data type when a vector is a mix of data types. Some key takeaways are below. Let me know if you sitll have questions about this.\n\nNumbers and logical/boolean (TRUE, FALSE) do not have double quotes around them, but character strings do. If you add double quotes to a number or logical, then R will treat it as a character string.\nIf a vector is a mix of numbers and character strings, then the data type of the vector is character.\nIf a vector is a mix of numbers and logical, then the data type of the vector is numeric and the logical value is converted to a numeric value (TRUE=1, FALSE=0).\nIf a vector is a mix of character strings and logical, then the data type of the vector is character and the logical value is converted to a character string and no longer operates as a logical (i.e. no longer equal to 1 or 0).\n\n\nLines 614-619, confused what the ratio means there. Could you go over the correct code (or options of the correct code) for challenge 5?\n\nThe code 1:4 or 6:9 creates sequences of integers starting with the first specified digit and ending at the last specified digit. For example, 1:4 is the vector with the digits 1 2 3 4. You can also create decreasing sequences by making the first number the bigger one. For example, 9:7 is the vector 9 8 7.\nChallenge 5:\n\nmore_heights_complete &lt;- na.omit(more_heights)\nmedian(more_heights_complete)\nYou could also get the median of more_heights without first removing the missing values with median(more_heights, na.rm = TRUE).\n\n\nhow to count the TRUE values in a logical vector\n\nTRUE is equal to 1 in R (and FALSE is equal to 0), and the function sum() adds up the values in a vector. Thus, sum(TRUE, FALSE, TRUE) is equal to 2. Similarly, sum(TRUE, FALSE, 5) is equal to 6.\nThe way I used it in class though is by counting how many values in the vector z (which was 7 9 11 13) are equal to 9. To do that I used the code sum(z == 9). Breaking that down, the code inside the parentheses z == 9 is equal to FALSE TRUE FALSE FALSE since the == means “equals to” in R.\nYou can read up more on boolean and logical operators at the R-bloggers post."
  },
  {
    "objectID": "weeks/week_01.html#clearest-points",
    "href": "weeks/week_01.html#clearest-points",
    "title": "Week 1",
    "section": "Clearest Points",
    "text": "Clearest Points\nThank you for the feedback!\n\nClass logistics\n\nSyllabus/course structure\nThe syllabus review.\nOverall expectations and course flow\nIntroduction to the class (first half of the class); conversation around syllabus; and the Quarto introduction\n\n\n\nQuarto\n\nHow to create and edit a Quarto document in RStudio.\nThe differences between quarto and markdown\nrmarkdown is no more, quarto it is!\n\n\n\nCoding\n\nHaving code missing and fixing it in front of the class was helpful in troubleshooting.\nJust running through all the commands was very clear and easy to follow\nBasic R set up for quarto and introduction to R objects, vectors, etc.\nIntroduction, functions, and explanations was the clearest for me.\nClassification of the objects in logical, character, and numeric\nNot necessarily a point, but I really liked when we were encouraged to use the shortcut keys for various commands on R and other little things like switching code between console vs inline , I have used R before for a class briefly but I never knew all these ways by which I can save time and be efficient while writing a code."
  },
  {
    "objectID": "weeks/week_02.html",
    "href": "weeks/week_02.html",
    "title": "Week 2",
    "section": "",
    "text": "Links to pre-recorded videos are posted on Sakai, in the table with the links to live class recordings.\nI split the class into 3 recrodings. See the table for details."
  },
  {
    "objectID": "weeks/week_02.html#pre-recorded-videos",
    "href": "weeks/week_02.html#pre-recorded-videos",
    "title": "Week 2",
    "section": "",
    "text": "Links to pre-recorded videos are posted on Sakai, in the table with the links to live class recordings.\nI split the class into 3 recrodings. See the table for details."
  },
  {
    "objectID": "weeks/week_02.html#topics",
    "href": "weeks/week_02.html#topics",
    "title": "Week 2",
    "section": "Topics",
    "text": "Topics\n\nProjects\nData frames\nTidy data\nReading in data\nGetting to know a dataset\nVisualizing data with ggplot2 (intro)"
  },
  {
    "objectID": "weeks/week_02.html#announcements",
    "href": "weeks/week_02.html#announcements",
    "title": "Week 2",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared OneDrive folder BSTA_526_W24_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_02, and then open RStudio by double-clicking on the file called part_02.Rproj.\nIf you have not already done so, please join the BSTA 526 Slack channel and introduce yourself by posting in the #random channel."
  },
  {
    "objectID": "weeks/week_02.html#class-materials",
    "href": "weeks/week_02.html#class-materials",
    "title": "Week 2",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nOne Drive part_02 Project folder"
  },
  {
    "objectID": "weeks/week_02.html#post-class-survey",
    "href": "weeks/week_02.html#post-class-survey",
    "title": "Week 2",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_02.html#homework",
    "href": "weeks/week_02.html#homework",
    "title": "Week 2",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 2 due on 1/29 (updated to Monday)."
  },
  {
    "objectID": "weeks/week_02.html#recording",
    "href": "weeks/week_02.html#recording",
    "title": "Week 2",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_02.html#muddiest-points",
    "href": "weeks/week_02.html#muddiest-points",
    "title": "Week 2",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nWhen discussing untidy data, the difference between long data and wide data was unclear.\n\nWe’ll be discussing the difference between long and wide data in more detail later in the course when we convert a dataset between the two. For now, you can take a look at an example I created for our BERD R workshops. The wide data in that example are not “tidy” since each cell contains two pieces of information: both the SBP and the visit number. In contrast, the long data have a separate column indicating which visit number the data in a given row are from.\n\nfor the “summary()” function, is there a way to summarize all but one variable in a dataset?\n\nYes! I sometimes restrict a dataset to a couple of variables for which I want to see the summary. I usually use the select() function for this, which we will be covering later in the course. For now, you can take a look at some select() examples from the BERD R workshops (see slides 29-32).\n\nDifferences between a tibble and a data.frame\n\nI’m not surprised to see this show up as a muddiest point! Depending on your level of experience with R, at this point in the class some of the differences are difficult to explain since we haven’t done much coding yet. The tibble vignette lists some of the differences though if you are interested. For our purposes, they are almost the same thing. When some differences come up later in the course, I will point them out."
  },
  {
    "objectID": "weeks/week_02.html#clearest-points",
    "href": "weeks/week_02.html#clearest-points",
    "title": "Week 2",
    "section": "Clearest Points",
    "text": "Clearest Points\nThanks for the feedback!\n\nI enjoyed going through the code and viewing the functions. I haven’t really used skimr before and that was nice to see.\n\nI like using skmir, but have recently been using get_summary_stats() from the rstatix package when teaching. It is only for numeric variables though. See a get_summary_stats() example from my BSTA 511 class.\n\nLoading data.\nHow to load data into R was clearest.\n\nGood to know that loading data was clear. This part can be tricky sometimes!\n\nggplot\n\nHopefully this will still be clear when we cover more advanced options in ggplot!"
  },
  {
    "objectID": "weeks/week_03.html",
    "href": "weeks/week_03.html",
    "title": "Week 3",
    "section": "",
    "text": "Where to get help on errors\nRevisiting data loading with the here package\nData manipulation with dplyr package\nThemes in the ggplot2 package\nFactors\nBoxplots and facets"
  },
  {
    "objectID": "weeks/week_03.html#topics",
    "href": "weeks/week_03.html#topics",
    "title": "Week 3",
    "section": "",
    "text": "Where to get help on errors\nRevisiting data loading with the here package\nData manipulation with dplyr package\nThemes in the ggplot2 package\nFactors\nBoxplots and facets"
  },
  {
    "objectID": "weeks/week_03.html#announcements",
    "href": "weeks/week_03.html#announcements",
    "title": "Week 3",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared OneDrive folder BSTA_526_W24_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_03, and then open RStudio by double-clicking on the file called part_03.Rproj.\nIf you have not already done so, please join the BSTA 526 Slack channel and introduce yourself by posting in the #random channel."
  },
  {
    "objectID": "weeks/week_03.html#class-materials",
    "href": "weeks/week_03.html#class-materials",
    "title": "Week 3",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nOne Drive part_03 Project folder"
  },
  {
    "objectID": "weeks/week_03.html#post-class-survey",
    "href": "weeks/week_03.html#post-class-survey",
    "title": "Week 3",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_03.html#homework",
    "href": "weeks/week_03.html#homework",
    "title": "Week 3",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 3 due on 1/31."
  },
  {
    "objectID": "weeks/week_03.html#recording",
    "href": "weeks/week_03.html#recording",
    "title": "Week 3",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_03.html#muddiest-points",
    "href": "weeks/week_03.html#muddiest-points",
    "title": "Week 3",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nhere package\nThe here package takes a bit to explaining, but, compared to the old way of doing things, it is a real life saver. The issue in the past had to do with relative file paths, especially with .qmd files that are saved in sub-folders. The .qmd file recognizes where it is saved as the root file path, which is okay with a one-off .qmd file. But when working in projects (recommended) and striving for reproducible R code (highly recommended), the here package save a lot of headache.\nFor further reading: + Why should I use the here package when I’m already using projects? by Malcolm Barrett. + how to use the here package by Jenny Richmond. + here package vignette + Using here with rmarkdown\nProject-oriented workflows are recommended. Here package solves some old headaches. It gets easier with practice.\n\nQuestion about using here\n\n… how [here] can be used in certain instances where one may not remember if they switched to a new qmd file? In that case, would you suggest to use the “here” command each time you work on a project where there’s a chance that you’ll switch between qmd files and would like to use the same data file throughout? Is there any other way to better use this function or tips on how you deal with it?\n\nThere is a difference between working interactively in RStudio where data are loaded to the Environment. In this case, loading a data set once means that it can be used in any other code while working in the environment.\nIssues will com up when you go to render a .qmd that doesn’t have the data loaded within that .qmd. It won’t look to the environment for the data; it looks to the filepath that you specify in the .qmd. Best practice is to write the code to load the data in each .qmd or .R script so that R knows where to look for the data that you want it to operate on / analyze.\n\n\n\nThe ! function. It seems like sometimes we use ! and sometimes we use -. Are they interchangeable, or each with different types of functions?\n\n! – the exclamation point can be read as “not” it is primarily used in logical statements\n- – the minus sign can be used in more instances\n\nto do actual arithmetic (i.e. subtraction)\nto indicate a negative number\nwith dplyr::select() to remove or not select a column, or exclusion\n\n\n\n# Subtraction\n5 - 3\n\n[1] 2\n\n# Negation\nx &lt;- 10\n-x\n\n[1] -10\n\n# Selection/exclusion\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nselect(starwars, -height) |&gt; dplyr::glimpse()\n\nRows: 87\nColumns: 13\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n\nUsing the fill command\nWe didn’t cover it in the lecture notes, but then it appeared in the example. I suggest to read/work through the fill vignette; the examples there are good ones to show what the function does. Then look back a the smoke_messy data set in Part 3 and think about why this command would be useful to clean up the data and for filling in missing values.\n\n\nLoading data into R\nIt gets easier and hopefully you get to see more example in the notes and practice with the homework. This tutorial is pretty good. So is the readxl vignette and the readr vignette.\n\n\nReasonable width, height, and dpi values when using ggsave\nThis takes some trial and error and depends on the purpose. For draft figures, dpi = 70 might be okay, but a journal might require dpi above 300 for publication. In Quarto, rendering an html, the figure defaults are 7x5 inches (Link). We talked about in class how you can use the plot panes to size your figures by trial and error.\n\n\nThe tidyselect section\nThere were pretty good resources in the notes\n\nSee some more examples in this slide\nFor more info and learning about tidyselect, please run this code in your console:\n\n\n# install remotes package\ninstall.packages(\"remotes\")\n# use remotes to install this package from github\nremotes::install_github(\"laderast/tidyowl\")\n\n# load tidyowl package\nlibrary(tidyowl)\n\n# interactive tutorial\ntidyowl::learn_tidyselect()\n\nHere is also a link with a list of the selectors and links to each one. For example, there is a link to starts_with and a bunch of examples."
  },
  {
    "objectID": "weeks/week_05.html",
    "href": "weeks/week_05.html",
    "title": "Week 5",
    "section": "",
    "text": "Updates made on 2/9/24\n\nHW 5: see the updated HW 5 assignment on OneDrive called hw_05_b526_v2.qmd\nMidterm: due date extended to 2/25/24.\n\nSee the updated midterm file on OneDrive with new yaml, due date, and links to previous midterm projects.\n\nMaterial covered in class on 2/7/24\n\nPart 5 Sections 1-4.4\nSolutions to Challenge 1 from section 4.3 of the Part 5 notes are in OneDrive (Challenge_1_solutions_Part5.html)"
  },
  {
    "objectID": "weeks/week_05.html#post-class-updates",
    "href": "weeks/week_05.html#post-class-updates",
    "title": "Week 5",
    "section": "",
    "text": "Updates made on 2/9/24\n\nHW 5: see the updated HW 5 assignment on OneDrive called hw_05_b526_v2.qmd\nMidterm: due date extended to 2/25/24.\n\nSee the updated midterm file on OneDrive with new yaml, due date, and links to previous midterm projects.\n\nMaterial covered in class on 2/7/24\n\nPart 5 Sections 1-4.4\nSolutions to Challenge 1 from section 4.3 of the Part 5 notes are in OneDrive (Challenge_1_solutions_Part5.html)"
  },
  {
    "objectID": "weeks/week_05.html#topics",
    "href": "weeks/week_05.html#topics",
    "title": "Week 5",
    "section": "Topics",
    "text": "Topics\n\nPractice loading data and using mutate() and separate()\nPractice using here() to load data in a subfolder of the project\nLearn how to summarize() data with group_by() to summarize within categories\nLearn and apply bind_rows() to combine rows from two or more datasets\nLearn about the different kinds of joins and how they merge data\nApply inner_join() and left_join() to join tables on columns\nUtilize pivot_longer() to make a wide dataset long"
  },
  {
    "objectID": "weeks/week_05.html#announcements",
    "href": "weeks/week_05.html#announcements",
    "title": "Week 5",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared OneDrive folder BSTA_526_W24_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_05, and then open RStudio by double-clicking on the file called part_05.Rproj."
  },
  {
    "objectID": "weeks/week_05.html#class-materials",
    "href": "weeks/week_05.html#class-materials",
    "title": "Week 5",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nOne Drive part_05 Project folder"
  },
  {
    "objectID": "weeks/week_05.html#post-class-survey",
    "href": "weeks/week_05.html#post-class-survey",
    "title": "Week 5",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_05.html#homework",
    "href": "weeks/week_05.html#homework",
    "title": "Week 5",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 5 due on 2/14.\n\nSee the updated HW 5 assignment on OneDrive called hw_05_b526_v2.qmd"
  },
  {
    "objectID": "weeks/week_05.html#recording",
    "href": "weeks/week_05.html#recording",
    "title": "Week 5",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_04.html",
    "href": "weeks/week_04.html",
    "title": "Week 4",
    "section": "",
    "text": "Learn and apply mutate() to change the data type of a variable\nApply mutate() to calculate a new variable based on other variables in a data.frame.\nApply case_when in a mutate() statement to make a continuous variable categorical\nLearn how to mutate() across() multiple columns at once.\nLearn to facet and change scales/palettes of ggplots."
  },
  {
    "objectID": "weeks/week_04.html#topics",
    "href": "weeks/week_04.html#topics",
    "title": "Week 4",
    "section": "",
    "text": "Learn and apply mutate() to change the data type of a variable\nApply mutate() to calculate a new variable based on other variables in a data.frame.\nApply case_when in a mutate() statement to make a continuous variable categorical\nLearn how to mutate() across() multiple columns at once.\nLearn to facet and change scales/palettes of ggplots."
  },
  {
    "objectID": "weeks/week_04.html#announcements",
    "href": "weeks/week_04.html#announcements",
    "title": "Week 4",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared OneDrive folder BSTA_526_W24_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_04, and then open RStudio by double-clicking on the file called part_04.Rproj.\nIf you have not already done so, please join the BSTA 526 Slack channel and introduce yourself by posting in the #random channel."
  },
  {
    "objectID": "weeks/week_04.html#class-materials",
    "href": "weeks/week_04.html#class-materials",
    "title": "Week 4",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nOne Drive part_04 Project folder"
  },
  {
    "objectID": "weeks/week_04.html#post-class-survey",
    "href": "weeks/week_04.html#post-class-survey",
    "title": "Week 4",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_04.html#homework",
    "href": "weeks/week_04.html#homework",
    "title": "Week 4",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 4 due on 2/7."
  },
  {
    "objectID": "weeks/week_04.html#recording",
    "href": "weeks/week_04.html#recording",
    "title": "Week 4",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_04.html#keyboard-shortcut-for-the-pipe-or",
    "href": "weeks/week_04.html#keyboard-shortcut-for-the-pipe-or",
    "title": "Week 4",
    "section": "Keyboard shortcut for the pipe (%>% or |>)",
    "text": "Keyboard shortcut for the pipe (%&gt;% or |&gt;)\nIn office hours, someone didn’t know about this fact and wanted to make sure everyone knows about it.\n\n\n\n\n\n\nImportant keyboard shortcut\n\n\n\nIn RStudio the keyboard shortcut for the pipe operator %&gt;% (or native pipe |&gt;) is Ctrl + Shift + M (Windows) or Cmd + Shift + M (Mac).\nNote: Ctrl + Shift + M also works on a Mac."
  },
  {
    "objectID": "weeks/week_04.html#the-difference-between-na-value-and-0",
    "href": "weeks/week_04.html#the-difference-between-na-value-and-0",
    "title": "Week 4",
    "section": "The difference between NA value and 0",
    "text": "The difference between NA value and 0\n\nNA (Not Available)\n\nNA is a special value in R that represents missing or undefined data.\n0 is a numeric value representing the number zero. It is a valid and well-defined numerical value in R.\nIt’s important to handle NA values appropriately in data analysis and to consider their impact on calculations, as operations involving NA may result in NA.\n\n\nNA + 5  # The result is NA\n\n[1] NA\n\n0 + 5  # The results is 5\n\n[1] 5\n\nx &lt;- c(1, 2, NA, 4)\n\nsum(x)  # The result is NA\n\n[1] NA\n\n# Using the argument na.rm = TRUE, means to ignore the NAs\nsum(x, na.rm = TRUE) # The results is 7\n\n[1] 7\n\nx &lt;- c(1, 2, 0, 4)\n\nsum(x) # The result is 7\n\n[1] 7"
  },
  {
    "objectID": "weeks/week_04.html#across-and-its-usage",
    "href": "weeks/week_04.html#across-and-its-usage",
    "title": "Week 4",
    "section": "across() and it’s usage",
    "text": "across() and it’s usage\nThe biggest advantage that across brings is the ability to perform the same data manipulation task to multiple columns.\nBelow the values in three columns are all set to the mean value using the mean(). I had to write out the function and the variable names three times.\n\nsmoke_complete |&gt; \n  mutate(days_to_death = mean(days_to_death, na.rm = TRUE), \n         days_to_birth = mean(days_to_birth, na.rm = TRUE), \n         days_to_last_follow_up = mean(days_to_last_follow_up, na.rm = TRUE)) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\nThe same thing is accomplished using across() but we only have to call the mean() function once.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = ~ mean(.x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\nLinks to check out\n\nacross() vignette\nWhy I love dplyr’s across"
  },
  {
    "objectID": "weeks/week_04.html#and-.x",
    "href": "weeks/week_04.html#and-.x",
    "title": "Week 4",
    "section": "~ and .x",
    "text": "~ and .x\nWe’ve seen the ~ and .x used with dplyr::across(). We will see them again later when we get to the package purrr.\nIn the tidyverse, ~ and .x are used to create what they call lambda functions which are part of the purrr syntax. We have not talked about functions yet, but purrr package and the dplyr::across() function allow you to specify functions to apply in a few different ways:\n\nA named function, e.g. mean.\n\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = mean)) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove, just using the function name, we are not able to provide the additional argument na.rm = TRUE to the mean() function, so the columns are now all NA values because there were missing (NA) values in those columns.\n\n\n\nAn anonymous function, e.g. \\(x) x + 1 or function(x) x + 1.\n\nThis has not been covered yet. R lets you specify your own functions and there are two basic ways to do it.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = \\(x) mean(x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\nor\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = function(x) mean(x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we are able to use the additional argument na.rm = TRUE and the columns are now the means of the valid values in those columns.\n\n\n\nA purrr-style lambda function, e.g. ~ mean(.x, na.rm = TRUE)\n\nWe use ~ to indicate that we are supplying a lambda function and we use .x as a placeholder for the argument within our lambda function to indicate where to use the variable.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = ~ mean(.x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\nLinks to check out\nSome of these are purrr focused which we have not covered yet. Others use dplyr::across() withing the dplyr::summarize() function which we will be covering soon\n\nMeaning of tilde and dot notation in dplyr\nWhat is the meaning of ‘~’ and ‘.’ inside the function map?\nacross() vignette\nWhy I love dplyr’s across"
  },
  {
    "objectID": "weeks/week_04.html#exceptions-where-we-have-seen-the-used",
    "href": "weeks/week_04.html#exceptions-where-we-have-seen-the-used",
    "title": "Week 4",
    "section": "Exceptions where we have seen the ~ used",
    "text": "Exceptions where we have seen the ~ used\nIn class, we have seen three instances where the ~ is used that is not for a lambda function.\n\ncase_when\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = case_when(\n      cigarettes_per_day &lt; 6 ~ \"0-5\", \n      cigarettes_per_day &gt;= 6 ~ \"6+\"\n    )) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category    n    percent\n                 0-5 1100 0.95486111\n                  6+   52 0.04513889\n\n\n\n\nfacet_wrap\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_wrap(~ disease)\n\n\n\n\nPer the facet_wrap vignettte:\n\nFor compatibility with the classic interface, can also be a formula or character vector. Use either a one sided formula, ~a + b, or a character vector, c(\"a\", \"b\").\n\nHere it is being used to specify a formula.\nThough per the vignette, the vars() function is preferred syntax:\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_wrap(ggplot2::vars(disease))\n\n\n\n\n\n\nfacet_grid\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_grid(disease ~ vital_status)\n\n\n\n\nPer the facet_grid vignettte:\n\nFor compatibility with the classic interface, rows can also be a formula with the rows (of the tabular display) on the LHS and the columns (of the tabular display) on the RHS; the dot in the formula is used to indicate there should be no faceting on this dimension (either row or column).\n\nAgain, it is being used to specify a formula.\nThough per the vignette, the ggplot2::vars() function with the arguments rows and cols seems to be preferred:\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_grid(rows = ggplot2::vars(disease), \n             cols = ggplot2::vars(vital_status))\n\n\n\n\nNote: dplyr::vars() and dplyr::ggplot2() are the same function in different packages and can be used interchangeably."
  },
  {
    "objectID": "weeks/week_04.html#case_when-vs.-if_else",
    "href": "weeks/week_04.html#case_when-vs.-if_else",
    "title": "Week 4",
    "section": "case_when vs. if_else",
    "text": "case_when vs. if_else\nIn dplyr, both if_else() and case_when() are used for conditional transformations, but they have different use cases and behaviors.\n\nif_else function\n\n\nif_else() is designed for simple vectorized conditions and is particularly useful when you have a binary condition (i.e., two possible outcomes).\nIt evaluates a condition for each element of a vector and returns one of two values based on whether the condition is TRUE or FALSE.\n\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = dplyr::if_else(cigarettes_per_day &lt; 6, \"0-5\", \"6+\")) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category    n    percent\n                 0-5 1100 0.95486111\n                  6+   52 0.04513889\n\n\nIn this example, the column cigarettes_category is assigned the value “0-5” if cigarettes_per_day is less than 6 and “6+” otherwise.\n\ncase_when() function\n\n\ncase_when() is more versatile and is suitable for handling multiple conditions with multiple possible outcomes. It is essentially a vectorized form of a switch or if_else chain.\nIt allows you to specify multiple conditions and their corresponding values.\n\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = case_when(\n      cigarettes_per_day &lt; 2 ~ \"0 to 2\", \n      cigarettes_per_day &lt; 4 ~ \"2 to 4\", \n      cigarettes_per_day &lt; 6 ~ \"4 to 6\", \n      cigarettes_per_day &gt;= 6 ~ \"6+\"\n    )) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category   n    percent\n              0 to 2 455 0.39496528\n              2 to 4 493 0.42795139\n              4 to 6 152 0.13194444\n                  6+  52 0.04513889\n\n\nIn this example, the column cigarettes_category is assigned the value “0 to 2” if cigarettes_per_day is less than 2, “2 to 4” if less than 4 (but greater than 2), “4 to 6” if less than 6 (but greater than 4), and “6+” otherwise.\nUse if_else() when you have a simple binary condition, and use case_when() when you need to handle multiple conditions with different outcomes. case_when() is more flexible and expressive when dealing with complex conditional transformations."
  },
  {
    "objectID": "weeks/week_04.html#the-difference-between-a-theme-and-and-a-palette.",
    "href": "weeks/week_04.html#the-difference-between-a-theme-and-and-a-palette.",
    "title": "Week 4",
    "section": "The difference between a theme and and a palette.",
    "text": "The difference between a theme and and a palette.\nIn ggplot2, a theme and a palette serve different purposes and are used in different contexts. In summary, a theme controls the overall appearance of the plot, while a palette is specifically related to the colors used to represent different groups or levels within the data. Both themes and palettes contribute to visual appeal and readability of your plot.\n\nTheme:\n\n\nA theme in ggplot2 refers to the overall visual appearance of the plot. It includes elements such as fonts, colors, grid lines, background, and other visual attributes that define the look and feel of the entire plot.\nThemes are set using functions like theme_minimal(), theme_classic(), or custom themes created with the theme() function. Themes control the global appearance of the plot.\n\n\nlibrary(ggplot2)\n\n# Example using theme_minimal()\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\n\nPalette:\n\n\nA palette, on the other hand, refers to a set of colors used to represent different levels or categories in the data. It is particularly relevant when working with categorical or discrete data where you want to distinguish between different groups.\nPalettes are set using functions like scale_fill_manual() or scale_color_manual(). You can specify a vector of colors or use pre-defined palettes from packages like RColorBrewer or viridis (we looked at the viridis package in class).\n\n\n# Example using a color palette\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day, \n           color = disease)) + \n  geom_point() +\n  scale_color_manual(values = c(\"red\", \n                                \"blue\", \n                                \"green\"))"
  },
  {
    "objectID": "weeks/week_04.html#be-careful-what-you-pipe-to-and-from",
    "href": "weeks/week_04.html#be-careful-what-you-pipe-to-and-from",
    "title": "Week 4",
    "section": "Be careful what you pipe to and from",
    "text": "Be careful what you pipe to and from\nAn error came up where a data frame was being piped to a function that did not accept a data frame as an argument (it accepted a vector)\n\n# starwars data frame was loaded earlier with the ggplot2 package\n\nstarwars |&gt;  \n  dplyr::n_distinct(species) \n\nError in list2(...): object 'species' not found\n\n\n\nstarwars is a data frame.\ndplyr::n_distinct() only accepts a vector as an argument (check the help ?dplyr::n_distinct)\n\nSo we need to pipe a vector to the dplyr::n_distinct() function:\n\nstarwars |&gt; \n  dplyr::select(species) |&gt; \n  dplyr::n_distinct() \n\n[1] 38\n\n\ndplyr::select() accepts a data frame as its first argument and it return a vector (see the help ?dplyr::select) which we can then pipe to dplyr::n_distinct().\nThe %&gt;% or |&gt; takes the output of the expression on its left and passes it as the first argument to the function on its right. The class / type of output on the left needs to agree or be acceptable as the first argument to the function on the right."
  },
  {
    "objectID": "weeks/week_04.html#other-muddy-points",
    "href": "weeks/week_04.html#other-muddy-points",
    "title": "Week 4",
    "section": "Other muddy points",
    "text": "Other muddy points\n\nRemembering applicable functions. Troubleshooting.\n\n\nThis gets better with experience. You are all still very new to R so be patient with yourself.\n\n\nHow to organize all of the material to understand the structure of how the R language works, rather than to keep track of all of the commands in an anecdotal way.\n\n\nAgain, I think that this gets better with experience. Though the R language, being open source, a lot of syntax is package dependent. So you need to be careful that some of the syntax we use with dplyr and the tidyverse will be different in base R or in other packages. This is something that comes with open source software (compared to Stata or SAS). The good news is that learning to use packages sets you up to better learn newer (to you) packages down the road."
  },
  {
    "objectID": "readings/01-reading.html",
    "href": "readings/01-reading.html",
    "title": "Week 1 Readings",
    "section": "",
    "text": "Remember, this reading is mostly supplemental and will help you if there are concepts that are unclear in class.\n\nR and RStudio Basics (Chapter 3) - make sure to watch the videos.\n\nSkip the following sections in Chapter 3:\n\n3.3.1, 3.3.3,\n\n\nIntro to R & Rstudio, and Quarto from Day 1 of BSTA 511/611 in Fall 2023 (taught by Meike Niederhausen)\nVectors and Data Frames (Section 3.3)\nWorkflow: scripts and projects\n\nSection 6.1: Scripts\nSection 6.2: Projects"
  },
  {
    "objectID": "readings/01-reading.html#required",
    "href": "readings/01-reading.html#required",
    "title": "Week 1 Readings",
    "section": "",
    "text": "Remember, this reading is mostly supplemental and will help you if there are concepts that are unclear in class.\n\nR and RStudio Basics (Chapter 3) - make sure to watch the videos.\n\nSkip the following sections in Chapter 3:\n\n3.3.1, 3.3.3,\n\n\nIntro to R & Rstudio, and Quarto from Day 1 of BSTA 511/611 in Fall 2023 (taught by Meike Niederhausen)\nVectors and Data Frames (Section 3.3)\nWorkflow: scripts and projects\n\nSection 6.1: Scripts\nSection 6.2: Projects"
  },
  {
    "objectID": "readings/01-reading.html#optional",
    "href": "readings/01-reading.html#optional",
    "title": "Week 1 Readings",
    "section": "Optional",
    "text": "Optional\n\nMarkdown Basics\n\nThis is a short reference on how to do formatting in Markdown. This is optional, but may be a helpful reference as you continue on and work with Markdown and Quarto.\n\nhttps://sph-r-programming-2023.netlify.app/reference/markdown.html\nMost of these topics are covered above in the Day 1 notes of BSTA 511/611.\nSkip the last two sections on Front matter and Citations, since these are different for Quarto.\n\nA similar resource for Quarto specifically\nQuarto YAML for html\nQuarto front matter\n\n\n\n\n\nSwirl Basics\nI’m going to highlight another resource for learning basic R concepts: swirl. This is a software package for R.\nTo start it, run the following code in the console in RStudio Cloud:\n\nlibrary(swirl)\nswirl()\n\nYou’ll want to take a look at the R Programming course, especially the following sections:\n\nBasic Building Blocks\nSequences of Numbers\nVectors\nMissing values"
  },
  {
    "objectID": "readings/02-reading.html",
    "href": "readings/02-reading.html",
    "title": "Week 2 Readings",
    "section": "",
    "text": "Data Organization in Spreadsheets by Kara Woo and Karl Broman - if there is one paper that I think is useful for everyone, it’s this one.\nAbsolute and Relative File Paths - sometimes understanding file paths can be difficult. This is a great follow up reading. The video is very helpful as well.\nWhat are R packages?"
  },
  {
    "objectID": "readings/02-reading.html#required",
    "href": "readings/02-reading.html#required",
    "title": "Week 2 Readings",
    "section": "",
    "text": "Data Organization in Spreadsheets by Kara Woo and Karl Broman - if there is one paper that I think is useful for everyone, it’s this one.\nAbsolute and Relative File Paths - sometimes understanding file paths can be difficult. This is a great follow up reading. The video is very helpful as well.\nWhat are R packages?"
  },
  {
    "objectID": "readings/02-reading.html#optional-meikes-suggestions-for-bsta-526-w24",
    "href": "readings/02-reading.html#optional-meikes-suggestions-for-bsta-526-w24",
    "title": "Week 2 Readings",
    "section": "Optional (Meike’s suggestions for BSTA 526 W24)",
    "text": "Optional (Meike’s suggestions for BSTA 526 W24)\n\nProjects in RStudio resources list Meike created for BSTA 511.\nExploring missing values in naniar . The notes for week 2 refer to the visdat package for visualizing missing values in your data. I also recommend the naniar package, and the link above is a great tutorial with an introduction to some really useful visualizations for missingness."
  },
  {
    "objectID": "readings/03-reading.html",
    "href": "readings/03-reading.html",
    "title": "Week 3 Readings",
    "section": "",
    "text": "ggplot2 BERD workshop slides - lots more on different geoms and how to customize plots\n\n\n\n\n\ndplyr cheatsheet - one of the best references.\nCombining functions using the pipe operator, %&gt;% - if you’re confused about %&gt;%, please read this."
  },
  {
    "objectID": "readings/03-reading.html#required",
    "href": "readings/03-reading.html#required",
    "title": "Week 3 Readings",
    "section": "",
    "text": "ggplot2 BERD workshop slides - lots more on different geoms and how to customize plots\n\n\n\n\n\ndplyr cheatsheet - one of the best references.\nCombining functions using the pipe operator, %&gt;% - if you’re confused about %&gt;%, please read this."
  },
  {
    "objectID": "readings/03-reading.html#optional",
    "href": "readings/03-reading.html#optional",
    "title": "Week 3 Readings",
    "section": "Optional",
    "text": "Optional\n\nCustomizing ggplot2\nIf you are interested in learning more about ggplot:\n\nThemes to improve your ggplot figures by David Keyes is really helpful for learning how to do more styling.\nRStudio also publishes a ggplot cheat sheet that is really handy!\nCustomizing ggplot2 Cheatsheet is also handy, because it organizes ggplot2 commands by task.\nDocumentation for all ggplot features is available here.\n\n\n\nUsing tidyselect (Intermediate Level)\nRemember, select() works on columns.\ntidyselect lets you select columns by matching names. In conjunction with the across() command, you can apply the same operation to multiple columns at once. This is especially handy when you need to produce a summary on all numeric columns.\nYou can run the tidyselect tutorial by first installing the tidyowl package by Ted Laderas:\ninstall.packages(\"remotes\")\nremotes::install_github(\"laderast/tidyowl\")\nand then running this code in your Rstudio console window:\nlibrary(tidyowl)\nlearn_tidyselect()"
  },
  {
    "objectID": "readings/04-reading.html",
    "href": "readings/04-reading.html",
    "title": "Week 4 Readings",
    "section": "",
    "text": "Data Transformation (3.1-3.3) from R for Data Science\nggplot2: Elegant Graphics for Data Analysis, Scales & Guides\nR for Data Science: Factors - we will continue to work with factors in the next few classes with forcats examples like provided here."
  },
  {
    "objectID": "readings/04-reading.html#required",
    "href": "readings/04-reading.html#required",
    "title": "Week 4 Readings",
    "section": "",
    "text": "Data Transformation (3.1-3.3) from R for Data Science\nggplot2: Elegant Graphics for Data Analysis, Scales & Guides\nR for Data Science: Factors - we will continue to work with factors in the next few classes with forcats examples like provided here."
  },
  {
    "objectID": "readings/04-reading.html#optional",
    "href": "readings/04-reading.html#optional",
    "title": "Week 4 Readings",
    "section": "Optional",
    "text": "Optional\n\nTidyverse style guide\nAdvanced R: style guide\nacross(): This column-wise operations vignette will be useful for the next couple classes."
  },
  {
    "objectID": "readings/05-reading.html",
    "href": "readings/05-reading.html",
    "title": "Week 5 Readings",
    "section": "",
    "text": "group_by() Data Transformation (3.5-3.6) from R for Data Science (2e)\n\nThe 1st edition’s Section 5.6 on Grouped summaries with summarise() is more detailed (wordier) and worth looking at as well.\nThe 1st edition also has Section 5.7 on Grouped mutates (and filters) that I did not see in the 2nd edition. Please let me know if you find this content in the 2nd edition!\n\nAggregating data with summarize and map - we will cover map() and rowwise() later, but summarize and mutate with across are described here. You may want to re-visit this when we get to purrr."
  },
  {
    "objectID": "readings/05-reading.html#required",
    "href": "readings/05-reading.html#required",
    "title": "Week 5 Readings",
    "section": "",
    "text": "group_by() Data Transformation (3.5-3.6) from R for Data Science (2e)\n\nThe 1st edition’s Section 5.6 on Grouped summaries with summarise() is more detailed (wordier) and worth looking at as well.\nThe 1st edition also has Section 5.7 on Grouped mutates (and filters) that I did not see in the 2nd edition. Please let me know if you find this content in the 2nd edition!\n\nAggregating data with summarize and map - we will cover map() and rowwise() later, but summarize and mutate with across are described here. You may want to re-visit this when we get to purrr."
  },
  {
    "objectID": "readings/05-reading.html#optional",
    "href": "readings/05-reading.html#optional",
    "title": "Week 5 Readings",
    "section": "Optional",
    "text": "Optional\n\nThis column-wise operations vignette will be useful for the next couple classes.\n\nThe following resources are optional reading, but quite helpful in your Quarto journey.\n\nQuarto Cheatsheet\nQuarto Guide\nQuarto Reference\nChapter 28: Quarto from R for Data Science (2e)"
  },
  {
    "objectID": "function_week.html",
    "href": "function_week.html",
    "title": "Functions of the Week",
    "section": "",
    "text": "Either open the Functions of the week webpage in a new browser window or view the webpage embedded below"
  },
  {
    "objectID": "function_week/Function_of_the_Week_Weingarten.html",
    "href": "function_week/Function_of_the_Week_Weingarten.html",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "In this document, I will introduce the drop_na() function and show what it’s for.\n\n#load tidyverse up\nlibrary(tidyverse)\n#example dataset\nlibrary(palmerpenguins)\ndata(penguins)\n\n\n\nThe drop_na function will drop out rows from your dataset where columns contain missing values. It can take two arguments:\n\ndata : the name of your dataframe\n... : Columns to inspect for missing values. If not specified, all columns are inspected.\n\nExample code setup: data %&gt;% drop_na() or data %&gt;% drop_na(column_name)\n\n\n\n\n#How many NA's in our dataset?\n(sum(is.na(penguins)))\n\n[1] 19\n\n#What columns contain NA's?\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\n\n\n\n#Drop NA's from just one column\npenguins_dropNA_mass &lt;- penguins %&gt;% drop_na(body_mass_g)\nsummary(penguins_dropNA_mass)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :151   Biscoe   :167   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :123   Torgersen: 51   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  :  9   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n\n\n\n\n\n\n#Drop NA's from all columns\npenguins_dropNA_all &lt;- penguins %&gt;% drop_na()\nsummary(penguins_dropNA_all)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :146   Biscoe   :163   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :123   1st Qu.:39.50   1st Qu.:15.60  \n Gentoo   :119   Torgersen: 47   Median :44.50   Median :17.30  \n                                 Mean   :43.99   Mean   :17.16  \n                                 3rd Qu.:48.60   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172       Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190       1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197       Median :4050                Median :2008  \n Mean   :201       Mean   :4207                Mean   :2008  \n 3rd Qu.:213       3rd Qu.:4775                3rd Qu.:2009  \n Max.   :231       Max.   :6300                Max.   :2009  \n\n\n\n\n\n\n\nlibrary(nlme)\nsummary(Glucose)\n\n Subject      Time            conc          Meal   \n 6:63    Min.   :-0.25   Min.   : 2.070   2am :66  \n 2:63    1st Qu.: 0.50   1st Qu.: 4.348   6am :66  \n 3:63    Median : 2.00   Median : 4.900   10am:60  \n 5:63    Mean   : 2.50   Mean   : 5.511   2pm :60  \n 1:63    3rd Qu.: 4.00   3rd Qu.: 6.357   6pm :60  \n 4:63    Max.   : 7.00   Max.   :10.470   10pm:66  \n                         NA's   :2                 \n\n#Drop all NA's\nGlucose_noNA &lt;- Glucose %&gt;% drop_na()\nsummary(Glucose_noNA)\n\n Subject      Time             conc          Meal   \n 6:62    Min.   :-0.250   Min.   : 2.070   2am :65  \n 2:63    1st Qu.: 0.500   1st Qu.: 4.348   6am :66  \n 3:63    Median : 2.000   Median : 4.900   10am:59  \n 5:63    Mean   : 2.484   Mean   : 5.511   2pm :60  \n 1:63    3rd Qu.: 4.000   3rd Qu.: 6.357   6pm :60  \n 4:62    Max.   : 7.000   Max.   :10.470   10pm:66  \n\n\n\n\n\nDoes having NA’s in the graph make sense?\n\nggplot(data = penguins, \n       aes(x = species, fill = species)) + \n    geom_bar() +\n  facet_wrap(vars(sex)) +\n  labs( x = \"Species\",\n        y = \"Count\",\n        title = \"Frequency of Species by Sex\")\n\n\n\n\nDoes having NA’s in the graph make a difference?\n\nggplot(data = Glucose,\n       aes(x = Subject, y = conc)) +\n  geom_boxplot() +\n  labs(x = \"Subject Number\", \n       y = \"Glucose Concentration\",\n       title = \"Boxplot of Glucose by Subject\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\nI find this tool very helpful, but it must be used with care. Some modeling techniques will not work with missing values, so it is necessary to find a solution for this. However, dropping all NA’s in all columns can drastically reduce the size of your dataset. There are several things to consider before dropping NA’s:\n\nHow many NA’s are in your dataset? How much data do you lose if you drop them?\nWhat types of data have NA’s?\nAre the NA’s in the variables you will be considering?\nDoes the modeling technique you want to use accept NA’s?\nDoes the graph you want to generate make sense with NA’s?"
  },
  {
    "objectID": "function_week/Function_of_the_Week_Weingarten.html#what-is-it-for",
    "href": "function_week/Function_of_the_Week_Weingarten.html#what-is-it-for",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "The drop_na function will drop out rows from your dataset where columns contain missing values. It can take two arguments:\n\ndata : the name of your dataframe\n... : Columns to inspect for missing values. If not specified, all columns are inspected.\n\nExample code setup: data %&gt;% drop_na() or data %&gt;% drop_na(column_name)"
  },
  {
    "objectID": "function_week/Function_of_the_Week_Weingarten.html#example-with-penguins-dataset",
    "href": "function_week/Function_of_the_Week_Weingarten.html#example-with-penguins-dataset",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "#How many NA's in our dataset?\n(sum(is.na(penguins)))\n\n[1] 19\n\n#What columns contain NA's?\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\n\n\n\n#Drop NA's from just one column\npenguins_dropNA_mass &lt;- penguins %&gt;% drop_na(body_mass_g)\nsummary(penguins_dropNA_mass)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :151   Biscoe   :167   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :123   Torgersen: 51   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  :  9   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n\n\n\n\n\n\n#Drop NA's from all columns\npenguins_dropNA_all &lt;- penguins %&gt;% drop_na()\nsummary(penguins_dropNA_all)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :146   Biscoe   :163   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :123   1st Qu.:39.50   1st Qu.:15.60  \n Gentoo   :119   Torgersen: 47   Median :44.50   Median :17.30  \n                                 Mean   :43.99   Mean   :17.16  \n                                 3rd Qu.:48.60   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172       Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190       1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197       Median :4050                Median :2008  \n Mean   :201       Mean   :4207                Mean   :2008  \n 3rd Qu.:213       3rd Qu.:4775                3rd Qu.:2009  \n Max.   :231       Max.   :6300                Max.   :2009"
  },
  {
    "objectID": "function_week/Function_of_the_Week_Weingarten.html#example-with-glucose-dataset",
    "href": "function_week/Function_of_the_Week_Weingarten.html#example-with-glucose-dataset",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "library(nlme)\nsummary(Glucose)\n\n Subject      Time            conc          Meal   \n 6:63    Min.   :-0.25   Min.   : 2.070   2am :66  \n 2:63    1st Qu.: 0.50   1st Qu.: 4.348   6am :66  \n 3:63    Median : 2.00   Median : 4.900   10am:60  \n 5:63    Mean   : 2.50   Mean   : 5.511   2pm :60  \n 1:63    3rd Qu.: 4.00   3rd Qu.: 6.357   6pm :60  \n 4:63    Max.   : 7.00   Max.   :10.470   10pm:66  \n                         NA's   :2                 \n\n#Drop all NA's\nGlucose_noNA &lt;- Glucose %&gt;% drop_na()\nsummary(Glucose_noNA)\n\n Subject      Time             conc          Meal   \n 6:62    Min.   :-0.250   Min.   : 2.070   2am :65  \n 2:63    1st Qu.: 0.500   1st Qu.: 4.348   6am :66  \n 3:63    Median : 2.000   Median : 4.900   10am:59  \n 5:63    Mean   : 2.484   Mean   : 5.511   2pm :60  \n 1:63    3rd Qu.: 4.000   3rd Qu.: 6.357   6pm :60  \n 4:62    Max.   : 7.000   Max.   :10.470   10pm:66"
  },
  {
    "objectID": "function_week/Function_of_the_Week_Weingarten.html#graphical-considerations",
    "href": "function_week/Function_of_the_Week_Weingarten.html#graphical-considerations",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "Does having NA’s in the graph make sense?\n\nggplot(data = penguins, \n       aes(x = species, fill = species)) + \n    geom_bar() +\n  facet_wrap(vars(sex)) +\n  labs( x = \"Species\",\n        y = \"Count\",\n        title = \"Frequency of Species by Sex\")\n\n\n\n\nDoes having NA’s in the graph make a difference?\n\nggplot(data = Glucose,\n       aes(x = Subject, y = conc)) +\n  geom_boxplot() +\n  labs(x = \"Subject Number\", \n       y = \"Glucose Concentration\",\n       title = \"Boxplot of Glucose by Subject\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "function_week/Function_of_the_Week_Weingarten.html#is-it-helpful",
    "href": "function_week/Function_of_the_Week_Weingarten.html#is-it-helpful",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "I find this tool very helpful, but it must be used with care. Some modeling techniques will not work with missing values, so it is necessary to find a solution for this. However, dropping all NA’s in all columns can drastically reduce the size of your dataset. There are several things to consider before dropping NA’s:\n\nHow many NA’s are in your dataset? How much data do you lose if you drop them?\nWhat types of data have NA’s?\nAre the NA’s in the variables you will be considering?\nDoes the modeling technique you want to use accept NA’s?\nDoes the graph you want to generate make sense with NA’s?"
  },
  {
    "objectID": "function_week/function_of_the_week_ECHALUSE.html",
    "href": "function_week/function_of_the_week_ECHALUSE.html",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "In this document, I will introduce the ceiling_date() function and show what it’s for.\n\nlibrary(lubridate)\n\n\n\nThe ceiling_date() function is part of the lubridate package. It is used for rounding a given date-time object up to the nearest boundary of a specified time unit.\nThe term  ceiling  means rounding up, and users can specify rounding up to the nearest second, minute, hour, day, week, month, or year.\n\nceiling_date(x, unit=c(\"second\", \"minute\", \"hour\", \"day\",\n    \"week\", \"month\", \"year\"))\n\n\n x  is a vector of date-time objects.\n unit  is a string, period object, or date-time object rounded to the nearest boundary of a specific time unit.\n\n\n\nExample #1\n\n\n# format: year/month/day hour/minute/second\nx &lt;- ymd_hms(\"2009-08-03 12:01:59.23\") # Monday\n\n\n# rounding\nceiling_date(x, \"second\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"minute\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"5 mins\")\n\n[1] \"2009-08-03 12:05:00 UTC\"\n\nceiling_date(x, \"hour\")\n\n[1] \"2009-08-03 13:00:00 UTC\"\n\nceiling_date(x, \"2 hours\")\n\n[1] \"2009-08-03 14:00:00 UTC\"\n\nceiling_date(x, \"day\") # Tuesday\n\n[1] \"2009-08-04 UTC\"\n\nceiling_date(x, \"week\") # Saturday\n\n[1] \"2009-08-09 UTC\"\n\nceiling_date(x, \"month\")\n\n[1] \"2009-09-01 UTC\"\n\nceiling_date(x, \"year\")\n\n[1] \"2010-01-01 UTC\"\n\n\nReference:\n1. https://lubridate.tidyverse.org/reference/round_date.html\n2. RDocumentation\n\n\nExample #2\n\n\nlibrary(nycflights13)\ndata(flights)\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\nhead(flights)\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n# To convert date and time information into a more standard datetime format.\n# We write a `function()` with parameters: year, month, day, and time.\n# Use `lubridate::make_datetime()` to create a new datetime object (make_datetime_100). \n# The time format is in HHMM and splits the time into hours (time %/% 100) and minutes (time %% 100).\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\n\n# Rows with missing departure or arrival times are filtered out. \n# Use `mutate` to create new columns:\n# departure time, arrival time, scheduled departure time, and scheduled arrival time. \n# The make_datetime_100 function is applied to, and after select columns:\n# origin, destination, columns ending with \"delay,\" and columns ending with \"time\".\n\nflights_dt &lt;- flights %&gt;% \n  filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% \n  mutate(dep_time = make_datetime_100(year, month, day, dep_time),\n         arr_time = make_datetime_100(year, month, day, arr_time),\n         sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n         sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)) %&gt;%\n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\n\n# Check\nhead(flights_dt)\n\n# A tibble: 6 × 9\n  origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n# ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;\n\nskim(flights_dt)\n\n\nData summary\n\n\nName\nflights_dt\n\n\nNumber of rows\n328063\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\nPOSIXct\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\norigin\n0\n1\n3\n3\n0\n3\n0\n\n\ndest\n0\n1\n3\n3\n0\n104\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndep_delay\n0\n1\n12.58\n40.09\n-43\n-5\n-2\n11\n1301\n▇▁▁▁▁\n\n\narr_delay\n717\n1\n6.90\n44.63\n-86\n-17\n-5\n14\n1272\n▇▁▁▁▁\n\n\nair_time\n717\n1\n150.69\n93.69\n20\n82\n129\n192\n695\n▇▂▂▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndep_time\n0\n1\n2013-01-01 05:17:00\n2013-12-31 23:56:00\n2013-07-04 09:12:00\n211509\n\n\nsched_dep_time\n0\n1\n2013-01-01 05:15:00\n2013-12-31 23:59:00\n2013-07-04 09:15:00\n125557\n\n\narr_time\n0\n1\n2013-01-01 00:03:00\n2014-01-01 00:00:00\n2013-07-04 11:06:00\n220332\n\n\nsched_arr_time\n0\n1\n2013-01-01 00:05:00\n2013-12-31 23:59:00\n2013-07-04 11:20:00\n204384\n\n\n\n\n\n\n# Plot: Departure time\nggplot(flights_dt, aes(x = dep_time)) +\n  geom_histogram(binwidth = 3600, color = \"purple\", alpha = 0.7) +\n  labs(title = \"Departure Time Distribution\",\n       x = \"Departure Time\",\n       y = \"Frequency\")\n\n\n\n\n\n# Plot: Departure for each week\nflights_dt %&gt;% \n  count(week = ceiling_date(dep_time, \"week\")) %&gt;% \n  ggplot(aes(week, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Week\",\n         x = \"Week\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\n\n# Plot: Departure for each month\nflights_dt %&gt;% \n  count(month = ceiling_date(dep_time, \"month\")) %&gt;% \n  ggplot(aes(month, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Month\",\n         x = \"Month\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\nInstead of plotting the original departure time, we can round up to a nearby unit of time using ceiling_date(), and allows us to plot the number of flights per week and per month.\nReference:\n1. R for Data Science. https://r4ds.had.co.nz/dates-and-times.html\n2. How to Write Fuctions in R\n\n\n\nYes, it is useful in representing time in plots and can offer insights into patterns and/or trends over different time intervals. This can be especially true for large datasets where ceiling_date() can be used to simplify and group dates to provide a more concise and interpretable representation of trends. I don’t use this everyday, but I do think it is pretty neat!"
  },
  {
    "objectID": "function_week/function_of_the_week_ECHALUSE.html#what-is-it-for",
    "href": "function_week/function_of_the_week_ECHALUSE.html#what-is-it-for",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "The ceiling_date() function is part of the lubridate package. It is used for rounding a given date-time object up to the nearest boundary of a specified time unit.\nThe term  ceiling  means rounding up, and users can specify rounding up to the nearest second, minute, hour, day, week, month, or year.\n\nceiling_date(x, unit=c(\"second\", \"minute\", \"hour\", \"day\",\n    \"week\", \"month\", \"year\"))\n\n\n x  is a vector of date-time objects.\n unit  is a string, period object, or date-time object rounded to the nearest boundary of a specific time unit.\n\n\n\nExample #1\n\n\n# format: year/month/day hour/minute/second\nx &lt;- ymd_hms(\"2009-08-03 12:01:59.23\") # Monday\n\n\n# rounding\nceiling_date(x, \"second\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"minute\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"5 mins\")\n\n[1] \"2009-08-03 12:05:00 UTC\"\n\nceiling_date(x, \"hour\")\n\n[1] \"2009-08-03 13:00:00 UTC\"\n\nceiling_date(x, \"2 hours\")\n\n[1] \"2009-08-03 14:00:00 UTC\"\n\nceiling_date(x, \"day\") # Tuesday\n\n[1] \"2009-08-04 UTC\"\n\nceiling_date(x, \"week\") # Saturday\n\n[1] \"2009-08-09 UTC\"\n\nceiling_date(x, \"month\")\n\n[1] \"2009-09-01 UTC\"\n\nceiling_date(x, \"year\")\n\n[1] \"2010-01-01 UTC\"\n\n\nReference:\n1. https://lubridate.tidyverse.org/reference/round_date.html\n2. RDocumentation\n\n\nExample #2\n\n\nlibrary(nycflights13)\ndata(flights)\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\nhead(flights)\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n# To convert date and time information into a more standard datetime format.\n# We write a `function()` with parameters: year, month, day, and time.\n# Use `lubridate::make_datetime()` to create a new datetime object (make_datetime_100). \n# The time format is in HHMM and splits the time into hours (time %/% 100) and minutes (time %% 100).\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\n\n# Rows with missing departure or arrival times are filtered out. \n# Use `mutate` to create new columns:\n# departure time, arrival time, scheduled departure time, and scheduled arrival time. \n# The make_datetime_100 function is applied to, and after select columns:\n# origin, destination, columns ending with \"delay,\" and columns ending with \"time\".\n\nflights_dt &lt;- flights %&gt;% \n  filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% \n  mutate(dep_time = make_datetime_100(year, month, day, dep_time),\n         arr_time = make_datetime_100(year, month, day, arr_time),\n         sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n         sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)) %&gt;%\n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\n\n# Check\nhead(flights_dt)\n\n# A tibble: 6 × 9\n  origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n# ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;\n\nskim(flights_dt)\n\n\nData summary\n\n\nName\nflights_dt\n\n\nNumber of rows\n328063\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\nPOSIXct\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\norigin\n0\n1\n3\n3\n0\n3\n0\n\n\ndest\n0\n1\n3\n3\n0\n104\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndep_delay\n0\n1\n12.58\n40.09\n-43\n-5\n-2\n11\n1301\n▇▁▁▁▁\n\n\narr_delay\n717\n1\n6.90\n44.63\n-86\n-17\n-5\n14\n1272\n▇▁▁▁▁\n\n\nair_time\n717\n1\n150.69\n93.69\n20\n82\n129\n192\n695\n▇▂▂▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndep_time\n0\n1\n2013-01-01 05:17:00\n2013-12-31 23:56:00\n2013-07-04 09:12:00\n211509\n\n\nsched_dep_time\n0\n1\n2013-01-01 05:15:00\n2013-12-31 23:59:00\n2013-07-04 09:15:00\n125557\n\n\narr_time\n0\n1\n2013-01-01 00:03:00\n2014-01-01 00:00:00\n2013-07-04 11:06:00\n220332\n\n\nsched_arr_time\n0\n1\n2013-01-01 00:05:00\n2013-12-31 23:59:00\n2013-07-04 11:20:00\n204384\n\n\n\n\n\n\n# Plot: Departure time\nggplot(flights_dt, aes(x = dep_time)) +\n  geom_histogram(binwidth = 3600, color = \"purple\", alpha = 0.7) +\n  labs(title = \"Departure Time Distribution\",\n       x = \"Departure Time\",\n       y = \"Frequency\")\n\n\n\n\n\n# Plot: Departure for each week\nflights_dt %&gt;% \n  count(week = ceiling_date(dep_time, \"week\")) %&gt;% \n  ggplot(aes(week, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Week\",\n         x = \"Week\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\n\n# Plot: Departure for each month\nflights_dt %&gt;% \n  count(month = ceiling_date(dep_time, \"month\")) %&gt;% \n  ggplot(aes(month, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Month\",\n         x = \"Month\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\nInstead of plotting the original departure time, we can round up to a nearby unit of time using ceiling_date(), and allows us to plot the number of flights per week and per month.\nReference:\n1. R for Data Science. https://r4ds.had.co.nz/dates-and-times.html\n2. How to Write Fuctions in R"
  },
  {
    "objectID": "function_week/function_of_the_week_ECHALUSE.html#is-it-helpful",
    "href": "function_week/function_of_the_week_ECHALUSE.html#is-it-helpful",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "Yes, it is useful in representing time in plots and can offer insights into patterns and/or trends over different time intervals. This can be especially true for large datasets where ceiling_date() can be used to simplify and group dates to provide a more concise and interpretable representation of trends. I don’t use this everyday, but I do think it is pretty neat!"
  },
  {
    "objectID": "function_week/function_of_the_week_McMonigal.html",
    "href": "function_week/function_of_the_week_McMonigal.html",
    "title": "n_distinct",
    "section": "",
    "text": "In this document, I will introduce the n_distinct() function from dplyr and show what it’s for.\n\n#load dplyr\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#example dataset\ndata(starwars)\n\n\n\nThe n_distinct() function counts the number of unique values in a vector or set of vectors. It has two arguments:\n\n... : One or more vectors from your dataset.\nna.rm : Can equal TRUE or FALSE.\n\nThe default is na.rm = FALSE, meaning missing values are included in the count of distinct values by default. If TRUE, missing values will be excluded from the count of distinct values.\n\n\n\n\n#Let's see what is in our dataset.\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n#Let's use n_distinct on a categorical variable, such as species.\nn_distinct(starwars$species)\n\n[1] 38\n\n\n\n#Let's examine how na.rm works.\nn_distinct(starwars$hair_color, na.rm = FALSE)\n\n[1] 13\n\n\n\n#Now let's change to na.rm = TRUE\nn_distinct(starwars$hair_color, na.rm = TRUE)\n\n[1] 12\n\n\n\n#Let's try with multiple vectors. Missing values will be included in the count.\nn_distinct(starwars$hair_color, starwars$eye_color)\n\n[1] 35\n\n\n\n#What are the distinct pairs?\nstarwars %&gt;% distinct(eye_color, hair_color)\n\n# A tibble: 35 × 2\n   eye_color hair_color   \n   &lt;chr&gt;     &lt;chr&gt;        \n 1 blue      blond        \n 2 yellow    &lt;NA&gt;         \n 3 red       &lt;NA&gt;         \n 4 yellow    none         \n 5 brown     brown        \n 6 blue      brown, grey  \n 7 blue      brown        \n 8 brown     black        \n 9 blue-gray auburn, white\n10 blue      auburn, grey \n# ℹ 25 more rows\n\n(tibble1 &lt;- starwars %&gt;% group_by(eye_color) %&gt;%\n  summarise(count = n_distinct(hair_color)))\n\n# A tibble: 15 × 2\n   eye_color     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 black             2\n 2 blue              8\n 3 blue-gray         1\n 4 brown             4\n 5 dark              1\n 6 gold              1\n 7 green, yellow     1\n 8 hazel             2\n 9 orange            2\n10 pink              1\n11 red               2\n12 red, blue         1\n13 unknown           2\n14 white             1\n15 yellow            6\n\nsum(tibble1$count)\n\n[1] 35\n\n\n\n\n\nThe function n_distinct() is helpful for data exploration for categorical variables because it quickly counts the number of distinct values.\nHowever, n_distinct() on its own is not very powerful, and the function is more helpful when used in combination with other functions."
  },
  {
    "objectID": "function_week/function_of_the_week_McMonigal.html#what-is-it-for",
    "href": "function_week/function_of_the_week_McMonigal.html#what-is-it-for",
    "title": "n_distinct",
    "section": "",
    "text": "The n_distinct() function counts the number of unique values in a vector or set of vectors. It has two arguments:\n\n... : One or more vectors from your dataset.\nna.rm : Can equal TRUE or FALSE.\n\nThe default is na.rm = FALSE, meaning missing values are included in the count of distinct values by default. If TRUE, missing values will be excluded from the count of distinct values."
  },
  {
    "objectID": "function_week/function_of_the_week_McMonigal.html#example-using-starwars",
    "href": "function_week/function_of_the_week_McMonigal.html#example-using-starwars",
    "title": "n_distinct",
    "section": "",
    "text": "#Let's see what is in our dataset.\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n#Let's use n_distinct on a categorical variable, such as species.\nn_distinct(starwars$species)\n\n[1] 38\n\n\n\n#Let's examine how na.rm works.\nn_distinct(starwars$hair_color, na.rm = FALSE)\n\n[1] 13\n\n\n\n#Now let's change to na.rm = TRUE\nn_distinct(starwars$hair_color, na.rm = TRUE)\n\n[1] 12\n\n\n\n#Let's try with multiple vectors. Missing values will be included in the count.\nn_distinct(starwars$hair_color, starwars$eye_color)\n\n[1] 35\n\n\n\n#What are the distinct pairs?\nstarwars %&gt;% distinct(eye_color, hair_color)\n\n# A tibble: 35 × 2\n   eye_color hair_color   \n   &lt;chr&gt;     &lt;chr&gt;        \n 1 blue      blond        \n 2 yellow    &lt;NA&gt;         \n 3 red       &lt;NA&gt;         \n 4 yellow    none         \n 5 brown     brown        \n 6 blue      brown, grey  \n 7 blue      brown        \n 8 brown     black        \n 9 blue-gray auburn, white\n10 blue      auburn, grey \n# ℹ 25 more rows\n\n(tibble1 &lt;- starwars %&gt;% group_by(eye_color) %&gt;%\n  summarise(count = n_distinct(hair_color)))\n\n# A tibble: 15 × 2\n   eye_color     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 black             2\n 2 blue              8\n 3 blue-gray         1\n 4 brown             4\n 5 dark              1\n 6 gold              1\n 7 green, yellow     1\n 8 hazel             2\n 9 orange            2\n10 pink              1\n11 red               2\n12 red, blue         1\n13 unknown           2\n14 white             1\n15 yellow            6\n\nsum(tibble1$count)\n\n[1] 35"
  },
  {
    "objectID": "function_week/function_of_the_week_McMonigal.html#is-n_distinct-helpful",
    "href": "function_week/function_of_the_week_McMonigal.html#is-n_distinct-helpful",
    "title": "n_distinct",
    "section": "",
    "text": "The function n_distinct() is helpful for data exploration for categorical variables because it quickly counts the number of distinct values.\nHowever, n_distinct() on its own is not very powerful, and the function is more helpful when used in combination with other functions."
  },
  {
    "objectID": "readings/06-reading.html",
    "href": "readings/06-reading.html",
    "title": "Week 6 Readings",
    "section": "",
    "text": "Control your Factors Using Forcats\nMore on joining data in Joins (Ch 19) from R for Data Science 2nd Ed"
  },
  {
    "objectID": "readings/06-reading.html#required",
    "href": "readings/06-reading.html#required",
    "title": "Week 6 Readings",
    "section": "",
    "text": "Control your Factors Using Forcats\nMore on joining data in Joins (Ch 19) from R for Data Science 2nd Ed"
  },
  {
    "objectID": "readings/06-reading.html#suggested",
    "href": "readings/06-reading.html#suggested",
    "title": "Week 6 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nDates and timess (Ch 17) in R for Data Science 2nd Ed"
  },
  {
    "objectID": "weeks/week_06.html",
    "href": "weeks/week_06.html",
    "title": "Week 6",
    "section": "",
    "text": "HW 5: see the updated HW 5 assignment on OneDrive called hw_05_b526_v2.qmd\nMidterm: due date extended to 2/25/24.\n\nSee the updated midterm file on OneDrive with new yaml, due date, and links to previous midterm projects.\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_06.html#announcements",
    "href": "weeks/week_06.html#announcements",
    "title": "Week 6",
    "section": "",
    "text": "HW 5: see the updated HW 5 assignment on OneDrive called hw_05_b526_v2.qmd\nMidterm: due date extended to 2/25/24.\n\nSee the updated midterm file on OneDrive with new yaml, due date, and links to previous midterm projects.\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_06.html#topics",
    "href": "weeks/week_06.html#topics",
    "title": "Week 6",
    "section": "Topics",
    "text": "Topics\n\nFinish week 5\n\nWe will first finish the material not covered from Week 5, starting with section 4.6.\n\nNote: I created a new version of the code file (inside the code folder) called part_05_b526_v2.qmd/.html.\nI decided not to move the Week 5 material not covered to the Week 6 notes.\n\n\nFrom Week 5:\n\nLearn how to summarize() data with group_by() to summarize within categories\nLearn about the different kinds of joins and how they merge data\n\nApply inner_join() and left_join() to join tables on columns\n\nUtilize pivot_longer() to make a wide dataset long\n\n\n\nNew Week 6 topics - did not get to Part 6\n\nPractice working with real data\nPractice joining and pivoting\nPractice ggplot and learn more geometries\nLearn how to deal with missing data"
  },
  {
    "objectID": "weeks/week_06.html#class-materials",
    "href": "weeks/week_06.html#class-materials",
    "title": "Week 6",
    "section": "Class materials",
    "text": "Class materials\n\nWeek 5 Readings\nWeek 6 Readings\nOne Drive part_05 & part_06 Project folders"
  },
  {
    "objectID": "weeks/week_06.html#post-class-survey",
    "href": "weeks/week_06.html#post-class-survey",
    "title": "Week 6",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_06.html#homework",
    "href": "weeks/week_06.html#homework",
    "title": "Week 6",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 6 due on 2/21."
  },
  {
    "objectID": "weeks/week_06.html#recording",
    "href": "weeks/week_06.html#recording",
    "title": "Week 6",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_05.html#case_when-vs-ifelse",
    "href": "weeks/week_05.html#case_when-vs-ifelse",
    "title": "Week 5",
    "section": "case_when() vs ifelse()",
    "text": "case_when() vs ifelse()\nThe difference between case_when and ifelse\n\nifelse() is the base R version of tidyverse’s case_when()\nI prefer using case_when() since it’s easier to follow the logic.\ncase_when() is especially useful when there are more than two logical conditions being used.\n\nThe example below creates a binary variable for bill length (long vs not long) using both case_when() and ifelse() as a comparison.\n\nCompare the crosstabs of the two variables!\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(palmerpenguins)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill1 = case_when(\n      bill_length_mm &gt;= 45 ~ \"long\",\n      bill_length_mm &lt; 45 ~ \"not long\",\n    ),\n    long_bill2 = ifelse(bill_length_mm &gt;= 45, \"long\", \"not long\")\n  )\n\npenguins %&gt;% tabyl(long_bill1, long_bill2) %&gt;% \n  adorn_title()\n\n            long_bill2             \n long_bill1       long not long NA_\n       long        166        0   0\n   not long          0      176   0\n       &lt;NA&gt;          0        0   2\n\n\nBelow is an example using case_when() to create a categorical variable with 3 groups:\n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill3 = case_when(\n      bill_length_mm &gt;= 50 ~ \"long\",\n      bill_length_mm &lt;= 40 ~ \"short\",\n      TRUE ~ \"medium\"\n    ))\n\npenguins %&gt;% tabyl(long_bill3, long_bill1) %&gt;% \n  adorn_title()\n\n            long_bill1             \n long_bill3       long not long NA_\n       long         57        0   0\n     medium        109       76   2\n      short          0      100   0\n\n\n\nCreating a categorical variable with 3 groups can be done with ifelse(), but it’s harder to follow the logic:\n\n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill4 = ifelse(\n      bill_length_mm &gt;= 50, \"long\",\n      ifelse(bill_length_mm &lt;= 40, \"short\", \"medium\")\n      ))\n\npenguins %&gt;% tabyl(long_bill3, long_bill4) %&gt;% \n  adorn_title()\n\n            long_bill4                 \n long_bill3       long medium short NA_\n       long         57      0     0   0\n     medium          0    185     0   2\n      short          0      0   100   0"
  },
  {
    "objectID": "weeks/week_05.html#separate",
    "href": "weeks/week_05.html#separate",
    "title": "Week 5",
    "section": "separate()",
    "text": "separate()\nDifferent ways of using the function separate, it was a bit unclear that when to use one or the other or examples of my research data where it’ll be most relevant to use.\n\nChoosing the “best” way of using separate() is overwhelming at first.\nI recommend starting with the simplest use case with a string being specified in sep = \" \":\n\n\nseparate(data, col, into, sep = \" \")\n\n\nWhich of the various versions we showed to use depends on how the data being separated are structured.\nMost of the time I have a simple character, such as a space (sep = \" \") or a comma (sep = \",\") that I want to separate by.\nIf the data are structured in a more complex way, then one of the stringr package options might come in handy."
  },
  {
    "objectID": "weeks/week_05.html#herehere",
    "href": "weeks/week_05.html#herehere",
    "title": "Week 5",
    "section": "here::here()",
    "text": "here::here()\nTSV files, very neat… But also, I got a bit confused when you did the render process around 22:00-23:00 minutes. Also, “here: and also”here” Directories/root directories. I was a bit confused about in what situations we would tangibly utilize this/if it is beneficial.\n\nGreat question! This is definitely not intuitive, which is why I wanted to demonstrate it in class.\nThe key is that\n\nwhen rendering a qmd file the current working directory is the folder the file is sitting in,\nwhile when running code in a file within RStudio the working directory is the folder where the .Rproj file is located.\n\n\nThis distinction is important when loading other files from our computer during our workflow, and why here::here() makes our workflow so much easier!"
  },
  {
    "objectID": "weeks/week_05.html#what-functions-will-only-work-within-another-function-generally",
    "href": "weeks/week_05.html#what-functions-will-only-work-within-another-function-generally",
    "title": "Week 5",
    "section": "what functions will only work within another function (generally)",
    "text": "what functions will only work within another function (generally)\n\nI’m not aware of functions that only work standalone within other functions. For example, the mean() function works on its own, but can also be used within a summarise().\n\n\nmean(penguins$bill_length_mm, na.rm = TRUE)\n\n[1] 43.92193\n\npenguins %&gt;% summarise(\n  m = mean(bill_length_mm, na.rm = TRUE)\n)\n\n# A tibble: 1 × 1\n      m\n  &lt;dbl&gt;\n1  43.9\n\n\n\nThat being said, a function has a set of parameters to be specified that are specific to that function."
  },
  {
    "objectID": "weeks/week_07.html",
    "href": "weeks/week_07.html",
    "title": "Week 7",
    "section": "",
    "text": "HW 7 is in the part 6 folder\nHW 6: see the updated HW 6 assignment on OneDrive in the pat06 folder called hw_06_b526-final-version.qmd\nMidterm: due date extended to 2/25/24.\n\nSee the updated midterm file on OneDrive with new yaml, due date, and links to previous midterm projects.\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_07.html#announcements",
    "href": "weeks/week_07.html#announcements",
    "title": "Week 7",
    "section": "",
    "text": "HW 7 is in the part 6 folder\nHW 6: see the updated HW 6 assignment on OneDrive in the pat06 folder called hw_06_b526-final-version.qmd\nMidterm: due date extended to 2/25/24.\n\nSee the updated midterm file on OneDrive with new yaml, due date, and links to previous midterm projects.\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_07.html#topics",
    "href": "weeks/week_07.html#topics",
    "title": "Week 7",
    "section": "Topics",
    "text": "Topics\n\nPart 6\n\nPractice working with real data\nPractice joining and pivoting\nPractice ggplot and learn more geometries\nLearn how to deal with missing data"
  },
  {
    "objectID": "weeks/week_07.html#class-materials",
    "href": "weeks/week_07.html#class-materials",
    "title": "Week 7",
    "section": "Class materials",
    "text": "Class materials\n\nWeek 6 Readings\nOne Drive part_06 Project folders"
  },
  {
    "objectID": "weeks/week_07.html#post-class-survey",
    "href": "weeks/week_07.html#post-class-survey",
    "title": "Week 7",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_07.html#homework",
    "href": "weeks/week_07.html#homework",
    "title": "Week 7",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 7 due on 2/28. Assignment is in the part 6 folder."
  },
  {
    "objectID": "weeks/week_07.html#recording",
    "href": "weeks/week_07.html#recording",
    "title": "Week 7",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_06.html#across",
    "href": "weeks/week_06.html#across",
    "title": "Week 6",
    "section": "across()",
    "text": "across()\nwhat exactly the across function does\n.fns, i.e. .fns=list, etc… I wasn’t really sure what that was achieving within across.\n\nThe across() function lets us apply a function to many columns at once.\nFor example, let’s say we want the mean value for every continuous variable in a dataset.\n\nThe code below calculates the mean for one variable in the penguins dataset using both base R and summarize().\nOne option to calculate the mean value for every continuous variable in the dataset is to repeat this code for the 4 other continuous variables.\n\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(gt)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n  # base R\nmean(penguins$bill_length_mm, na.rm = TRUE)\n\n[1] 43.92193\n\n# with summarize\npenguins %&gt;% \n  summarize(mean(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  `mean(bill_length_mm, na.rm = TRUE)`\n                                 &lt;dbl&gt;\n1                                 43.9\n\n\n\nIn this case across() lets us apply the mean function to all the columns of interest at once:\n\n\npenguins %&gt;%\n  summarize(across(.cols = where(is.numeric), \n                   .fns = ~ mean(.x, na.rm = TRUE)\n                   )) %&gt;% \n  gt()\n\n\n\n\n\n  \n    \n    \n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      year\n    \n  \n  \n    43.92193\n17.15117\n200.9152\n4201.754\n2008.029\n  \n  \n  \n\n\n\n\n\nThe .fns=list part of the across code is where we specify the function(s) that we want to apply to the specified columns.\n\nAbove we only specified one function (mean()), but we can specify additional functions as well, which is when we need to create a list to list all the functions we want to apply.\nBelow I apply the mean and standard deviation functions:\n\n\n\npenguins %&gt;%\n  summarize(across(.cols = where(is.numeric), \n                   .fns = list(\n                     mean = ~ mean(.x, na.rm = TRUE),\n                     sd = ~ sd(.x, na.rm = TRUE)\n                     ))) %&gt;% \n  gt()\n\n\n\n\n\n  \n    \n    \n      bill_length_mm_mean\n      bill_length_mm_sd\n      bill_depth_mm_mean\n      bill_depth_mm_sd\n      flipper_length_mm_mean\n      flipper_length_mm_sd\n      body_mass_g_mean\n      body_mass_g_sd\n      year_mean\n      year_sd\n    \n  \n  \n    43.92193\n5.459584\n17.15117\n1.974793\n200.9152\n14.06171\n4201.754\n801.9545\n2008.029\n0.8183559\n  \n  \n  \n\n\n\n\n\nIn general, lists are another type of R object to store information, whether data, lists of functions, output from regression models, etc. While concatenate is just a vector of values, lists are multidimensional. We will be learning more about lists in parts 7 and 8.\nYou can learn more about across() at its help file."
  },
  {
    "objectID": "weeks/week_06.html#case_when-vs-ifelse",
    "href": "weeks/week_06.html#case_when-vs-ifelse",
    "title": "Week 6",
    "section": "case_when() vs ifelse()",
    "text": "case_when() vs ifelse()\nstill a little confused on the difference between ifelse and casewhen, understand they are very similar but still confused on when it is best to use one over another\n\nThe two functions can be used interchangeably. * ifelse() is the original function from base R\n\ncase_when() is the user-friendly version of ifelse() from the dplyr package\n\nI recommend using case_when(), and it is what I use almost exclusively in my own work. My guess is that ifelse() was included in the notes since you might run into the function when reading R code on the internet.\nJust be careful that you preserve missing values when using case_when() as we discussed last time."
  },
  {
    "objectID": "weeks/week_06.html#factor-levels",
    "href": "weeks/week_06.html#factor-levels",
    "title": "Week 6",
    "section": "factor levels",
    "text": "factor levels\nworking with factor levels doesn’t feel totally intuitive yet. I think that’s because I tend to get confused with anything involving a concatenated list.\n\nWorking with factor variables takes a while to get used to, and in particular with their factor levels.\nWe will be looking at more examples with factor variables in the part 6 notes. See sections 2.8 and 4.\nYou can think of a concatenated list(c(...)) as a vector of values or a column of a dataset. Concatenating lets us create a set of values, which we typically create to use for some other purpose, such as specifying the levels of a factor variable.\nPlease submit a follow-up question in the post-class survey if this is still muddy after today’s class!"
  },
  {
    "objectID": "weeks/week_06.html#pivoting-tables",
    "href": "weeks/week_06.html#pivoting-tables",
    "title": "Week 6",
    "section": "pivoting tables",
    "text": "pivoting tables\n\nDefinitely a tricky topic, and over half of the muddiest points were about pivoting tables.\nWe will be looking at more examples in part 6.\n\n\nHow pivot_longer() would work on very large datasets with many rows/columns\n\nIt works the same way. However the resulting long table will end up being much much longer.\nExtra columns in the dataset just hang out and their values get repeated (such as an age variable that is not being made long by) over and over again.\n\nWe will be pivoting a dataset in part 6 that has extra variables that are not being pivoted.\n\n\n\n\nTrying to visualize the joins and pivot longer/wider\n\nI recommend trying them out with small datasets where you can actually see what is happening.\nJoins: Our BERD workshop slides have another example that might visualize joins.\n\nSlide 18 shows to datasets x and y, and what the resulting joins look like.\nSlide 19 shows Venn diagrams of how the different joins behave.\n\nPivoting: There’s an example with a very small dataset in my (supplemental) notes from BSTA 511. The graphic that goes along with this is on Slide 28 from the pdf.\n\n\n\npivot_longer makes plotting more understandable in an analysis sense, which situations would call for pivot_wider?\n\nI tend to use pivot_longer() much more frequently. However, there are times when pivot_wider() comes in handy. For example, below is a long table of summary statistics created with group_by() and summarize(). I would use pivot_wider() to reshape this table so that I have columns comparing species or columns comparing islands.\n\n\npenguins %&gt;% \n  group_by(species, island) %&gt;%\n  summarize(across(.cols = bill_length_mm, \n                   .fns = list(\n                     mean = ~ mean(.x, na.rm = TRUE),\n                     sd = ~ sd(.x, na.rm = TRUE)\n                     )))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 4\n# Groups:   species [3]\n  species   island    bill_length_mm_mean bill_length_mm_sd\n  &lt;fct&gt;     &lt;fct&gt;                   &lt;dbl&gt;             &lt;dbl&gt;\n1 Adelie    Biscoe                   39.0              2.48\n2 Adelie    Dream                    38.5              2.47\n3 Adelie    Torgersen                39.0              3.03\n4 Chinstrap Dream                    48.8              3.34\n5 Gentoo    Biscoe                   47.5              3.08\n\n\n\n\nHow to use arguments of pivot longer.\n\nThe arguments of the pivot functions take some practice to get used to. I sometimes still pull up an example to remind me what I need to specify for the various arguments, such as the one mentioned above that I have used in workshops and classes.\n\nWe have not covered all the different arguments, and I recommend reviewing the help file and in particular the examples at the end of the page."
  },
  {
    "objectID": "weeks/week_06.html#gtgt",
    "href": "weeks/week_06.html#gtgt",
    "title": "Week 6",
    "section": "gt::gt()",
    "text": "gt::gt()\nThe gt::gt package does make the tables look fancier, how do we add labels to those to have them look nice as well?\n\nI highly recommend the gt webpage to learn more about all the different options to create pretty tables. Note the tabs at the top of the page for “Get started” and “Reference.”\nSee also section 3 of part 6 on “Side note about gt::gt()” for more on creating pretty tables."
  },
  {
    "objectID": "weeks/week_06.html#herehere",
    "href": "weeks/week_06.html#herehere",
    "title": "Week 6",
    "section": "here::here",
    "text": "here::here\nwould also love more examples of here() I am starting to understand it better but still am a little confused\nI am still having trouble getting here() to work consistently. I was going to ask during class, but I think I am just not understanding how to manually nest my files correctly so that “here” works. I am struggling to get that set up correct, and thus, struggling to use it. \n\nWe’ll have some more examples in class, but I recommend reaching out to one of us (instructors or TA) to help you troubleshoot here::here.\nHere are also some resources that might help\n\nhttps://here.r-lib.org/articles/here.html\nhttp://jenrichmond.rbind.io/post/how-to-use-the-here-package/\nhttps://github.com/jennybc/here_here"
  },
  {
    "objectID": "weeks/week_06.html#clearest-points",
    "href": "weeks/week_06.html#clearest-points",
    "title": "Week 6",
    "section": "Clearest points",
    "text": "Clearest points\n\ngroup_by() function (n=3)\nsummarize() (n=2)\nacross() (n=1)\ncase_when() (n=1)\ndrop_na( ) (n=2)\nJoining tables (n=6)"
  },
  {
    "objectID": "readings/07-reading.html",
    "href": "readings/07-reading.html",
    "title": "Week 7 Readings",
    "section": "",
    "text": "Continue with Week 6 readings."
  },
  {
    "objectID": "weeks/week_08.html",
    "href": "weeks/week_08.html",
    "title": "Week 8",
    "section": "",
    "text": "This is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_08.html#announcements",
    "href": "weeks/week_08.html#announcements",
    "title": "Week 8",
    "section": "",
    "text": "This is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_08.html#topics",
    "href": "weeks/week_08.html#topics",
    "title": "Week 8",
    "section": "Topics",
    "text": "Topics\n\nPart 7\n\nWriting functions\nlists()\nFor Loops\nIteration"
  },
  {
    "objectID": "weeks/week_08.html#class-materials",
    "href": "weeks/week_08.html#class-materials",
    "title": "Week 8",
    "section": "Class materials",
    "text": "Class materials\n\nWeek 8 Readings\nOne Drive part_07 Project folders"
  },
  {
    "objectID": "weeks/week_08.html#post-class-survey",
    "href": "weeks/week_08.html#post-class-survey",
    "title": "Week 8",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_08.html#homework",
    "href": "weeks/week_08.html#homework",
    "title": "Week 8",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 8 due on 3/6. Assignment is in the part 7 folder."
  },
  {
    "objectID": "weeks/week_08.html#recording",
    "href": "weeks/week_08.html#recording",
    "title": "Week 8",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "readings/08-reading.html#suggested",
    "href": "readings/08-reading.html#suggested",
    "title": "Week 8 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nVectors and Lists - Jenny Bryan\nIntroduction to map() - Jenny Bryan\nSoftware Carpentry’s lesson on functions in R"
  },
  {
    "objectID": "readings/08-reading.html",
    "href": "readings/08-reading.html",
    "title": "Week 8 Readings",
    "section": "",
    "text": "Introduction to Functions and Arguments\nIntroduction to Lists in R\nFunctions in R for Data Science\nIteration in R for Data Science\nLearn to purrr"
  },
  {
    "objectID": "readings/08-reading.html#required",
    "href": "readings/08-reading.html#required",
    "title": "Week 8 Readings",
    "section": "",
    "text": "Introduction to Functions and Arguments\nIntroduction to Lists in R\nFunctions in R for Data Science\nIteration in R for Data Science\nLearn to purrr"
  },
  {
    "objectID": "readings/10-reading.html",
    "href": "readings/10-reading.html",
    "title": "Week 10 Readings",
    "section": "",
    "text": "Introduction to map() - Jenny Bryan\nPurrr Tips and Tricks by Emil Hvitfeldt.\nIntroduction to broom"
  },
  {
    "objectID": "readings/10-reading.html#required",
    "href": "readings/10-reading.html#required",
    "title": "Week 10 Readings",
    "section": "",
    "text": "Introduction to map() - Jenny Bryan\nPurrr Tips and Tricks by Emil Hvitfeldt.\nIntroduction to broom"
  },
  {
    "objectID": "readings/10-reading.html#suggested",
    "href": "readings/10-reading.html#suggested",
    "title": "Week 10 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nMore on using map and nested data with modeling: R for Data Science: Many Models, First edition\nbroom and dplyr\nJoy of Functional programming talk by Hadley Wickham - more on nesting/iteration\n\nFor learning more about statistics with R:\n\nModern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.com/\nDanielle Navarro’s Learning Statistics with R is excellent and talks much more about statistics: https://learningstatisticswithr.com/\nModel Basics from R for Data Science\nMore on survival analysis in R\n\nSurvival Analysis in R Tutorial by Dr. Emily C Zabor\nSurvminer survival plot vignette\nUVA’s Survival Workshop materials\nRview’s Survival Analysis\n\nProgramming with dplyr - in case I can’t get to tidyeval use for functions with tidyverse\nggplot2 in packages - examples how to use ggplot inside functions\nResources for learning more statistics:\n\nModern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.com/\nDanielle Navarro’s Learning Statistics with R is excellent and talks much more about statistics: https://learningstatisticswithr.com/\n\nMore on using map and nested data with modeling: R for Data Science: Many Models\nbroom and dplyr\nUseful vignettes on table output: gtsummary intro to tbl_summary\nTed Laderas’s interactive workbook on learning rowwise and nested data: learning rowwise\nWe might not get to dates but in case you want to learn more: Dates and times in R for Data Science\nIf you want to learn about tidymodels: Introduction to Machine Learning with the Tidyverse\nJoy of Functional programming talk by Hadley Wickham - more on nesting/iteration\nMore on model building and machine learning\n\nModel Building from R for Data Science\nMany Models - from R for Data science. Covers group_by()/nest() and list-columns\nTidymodels with R: Recipes\nTidymodels with R: Fitting Models with Parsnip\nTidymodels with R: Judging Model Effectiveness\nUMAP and Cocktail Recipes\nTidymodels: K-means\nPCA and Penguins"
  },
  {
    "objectID": "readings/09-reading.html",
    "href": "readings/09-reading.html",
    "title": "Week 9 Readings",
    "section": "",
    "text": "Same readings as Week 8."
  },
  {
    "objectID": "readings/09-reading.html#required",
    "href": "readings/09-reading.html#required",
    "title": "Week 9 Readings",
    "section": "",
    "text": "Introduction to map() - Jenny Bryan\nPurrr Tips and Tricks by Emil Hvitfeldt."
  },
  {
    "objectID": "readings/09-reading.html#suggested",
    "href": "readings/09-reading.html#suggested",
    "title": "Week 9 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nMore on using map and nested data with modeling: R for Data Science: Many Models\nbroom and dplyr\nJoy of Functional programming talk by Hadley Wickham - more on nesting/iteration\n\nFor learning more about statistics with R:\n\nModern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.com/\nDanielle Navarro’s Learning Statistics with R is excellent and talks much more about statistics: https://learningstatisticswithr.com/\nModel Basics from R for Data Science\nMore on survival analysis in R\n\nSurvival Analysis in R Tutorial by Dr. Emily C Zabor\nSurvminer survival plot vignette\nUVA’s Survival Workshop materials\nRview’s Survival Analysis"
  },
  {
    "objectID": "weeks/week_07.html#clearest-points",
    "href": "weeks/week_07.html#clearest-points",
    "title": "Week 7",
    "section": "Clearest points",
    "text": "Clearest points\n\nThis class was all really clear. It was helpful to be reviewing some of the things we learned last week.\n\n\nI appreciate the new codes on how to clean/reshape/combine messy data. I think that was the hardest parts to do in the other Biostatistics courses during projects.\n\n\nData cleaning\n\n\nMost of the data cleaning exercises.\n\n\ndifferent strategies to clean data sets\n\n\nThe data cleaning made a lot of sense but I think I will struggle with solving problems in a really inefficient way.\n\n\nEverything before Challenge 3\n\n\nmethods to merge datasets to create a table\n\n\ninner join and full join are the same if all vectors are the same.\n\n\nPivot\n\n\nggplot and how to code data in to display what we want to display"
  },
  {
    "objectID": "weeks/week_07.html#other-comments",
    "href": "weeks/week_07.html#other-comments",
    "title": "Week 7",
    "section": "Other comments",
    "text": "Other comments\n\nIs there a difference between summarize (with z) and summarise (with s)?\n\nGreat question!\n\nIn English, summarize is American English and summarise is British English. * In R they work the same way. The reference page for summarise() lists them as synonyms.\nIn R code I see summarise more, and now keep mixing up which is American and which is British.\nIn general, R accepts both American and British English, such as both color and colour.\n\n\nThank you for the survey reminders! The pace of the class feels much better compared to the pace at the beginning of the term\n\nThanks for the feedback!\n\nI really enjoyed the walk through from start to finish of how to clean the data sheet and it really helped clear up many of the commands I was previously confused about\n\nThanks for the feedback! Glad the data wrangling walk through was helpful."
  },
  {
    "objectID": "weeks/week_09.html",
    "href": "weeks/week_09.html",
    "title": "Week 9",
    "section": "",
    "text": "This is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_09.html#announcements",
    "href": "weeks/week_09.html#announcements",
    "title": "Week 9",
    "section": "",
    "text": "This is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_09.html#topics",
    "href": "weeks/week_09.html#topics",
    "title": "Week 9",
    "section": "Topics",
    "text": "Topics\n\nPart 7\n\nWriting functions\nlists()\nFor Loops\nIteration"
  },
  {
    "objectID": "weeks/week_09.html#class-materials",
    "href": "weeks/week_09.html#class-materials",
    "title": "Week 9",
    "section": "Class materials",
    "text": "Class materials\nReadings are still the same as for Week 8, and we are using the part_07 material on One Drive.\n\nWeek 8 Readings\nOneDrive part_07 Project folders"
  },
  {
    "objectID": "weeks/week_09.html#post-class-survey",
    "href": "weeks/week_09.html#post-class-survey",
    "title": "Week 9",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_09.html#homework",
    "href": "weeks/week_09.html#homework",
    "title": "Week 9",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 9 due on 3/13. Assignment is in the part 7 folder."
  },
  {
    "objectID": "weeks/week_09.html#recording",
    "href": "weeks/week_09.html#recording",
    "title": "Week 9",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_09.html#feedback-from-post-class-surveys",
    "href": "weeks/week_09.html#feedback-from-post-class-surveys",
    "title": "Week 9",
    "section": "Feedback from post-class surveys",
    "text": "Feedback from post-class surveys\n\nWeek 9 feedback will be added here during Week 10.\nSee Week 8 page for Week 8 feedback."
  },
  {
    "objectID": "weeks/week_08.html#muddiest-points-from-week-8",
    "href": "weeks/week_08.html#muddiest-points-from-week-8",
    "title": "Week 8",
    "section": "Muddiest points from Week 8",
    "text": "Muddiest points from Week 8\n\nSee Week 7 page for Week 7 feedback.\n\n\nWhen loading a dataset, what does  mean?\nThis occurs when you use the data() function to load a data set from a package. Per the help on this function (?data):\n\ndata() was originally intended to allow users to load datasets from packages for use in their examples, and as such it loaded the datasets into the workspace .GlobalEnv. This avoided having large datasets in memory when not in use: that need has been almost entirely superseded by lazy-loading of datasets.\n\n\ndata(\"iris\")  # this doesn't actually load the data set, but makes it available for use\nhead(iris)    # Once it's used it will appear in the Environment as an object.\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\n\nChallenge # 2\nThis was where we created a function to load 3 data sets, clean them, and convert them to long format. These are tasks we’ve seen in previous classes. In this challenge, the main takeaway was to see the DRY (Don’t repeat yourself) concept at play. Instead of writing the code 3 times for each data set, we can create a function where we only write the cleaning code once, then use that function 3 times.\nReviewing the challenge solutions and taking more time to work through it on your own is a good idea. We went through it pretty quick in class. You won’t usually be limited on time to get a function like that to work. In practice, if it’s taking more time and too complicated, then it’s fine to duplicate code so that you know it’s working correctly. But, with very repetitive tasks, functions can make your code less prone to errors from copying and pasting.\nIf you have trouble getting your code to work for the challenges, office hours are great for helping to debug code. Else, sharing full code in an email or on Slack.\n\n\npurrr::pluck\nThere was a specific question:\n\npurrr::pluck seems really useful, I wonder if you can tell it to pluck a specific record_ID?\n\nThe short answer is no. Not a specific ID. But if you know the position of the specific ID then you could.\n\n# Load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Create sample data\ndf &lt;- tibble::tibble(\n  id = c(\"0001\", \"0002\", \"0003\", \"0004\", \"0005\", \"0006\", \"0007\", \"0008\", \"0009\", \"0010\"), \n  sex = sample(x = c(\"M\", \"F\"), size = 10, replace = TRUE), \n  age = sample(x = 18:65, size = 10, replace = TRUE)\n  \n)\n\ndf\n\n# A tibble: 10 × 3\n   id    sex     age\n   &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n 1 0001  F        39\n 2 0002  M        32\n 3 0003  F        24\n 4 0004  F        29\n 5 0005  F        31\n 6 0006  M        56\n 7 0007  F        25\n 8 0008  F        56\n 9 0009  F        43\n10 0010  F        52\n\n# Say we want to extract ID 0003.\n\n# With purrr::pluck we need to know that it's in the 3rd row of the ID column\n\npurrr::pluck(df, \n             \"id\", \n             3)\n\n[1] \"0003\"\n\n# Gives an error\npurrr::pluck(df, \n             \"id\", \n             \"0003\")\n\nNULL\n\n# More than likely in this scenario, you would use a filter:\ndf |&gt; \n  dplyr::filter(id == \"0003\")\n\n# A tibble: 1 × 3\n  id    sex     age\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 0003  F        24\n\n\npurrr::pluck was created to work with deeply nested data structures. Not necessarily data frames; there’s probably a more appropriate function out there for the task.\n\n\nLists – general confusion\n\nWhat do we do with lists?\nUsing lists\n\nWe will get to work more with lists in Week 9 and get more opportunities to see how they are used.\nLists are more flexible and have the ability to handle various data structures which make them a powerful tool for organizing, manipulating, and representing complex data in R.\n\n\nLists – One bracket versus two brackets.\nOne bracket [ ] and two brackets [[ ]] serves different purposes, primarily when accessing elements in a data structure like vectors, lists, or data frames.\n\nOne Bracket [ ]:\n\nVectors:\nWhen used with a single bracket, you can use it to subset or extract elements from a vector.\n\n# Example with a vector\nmy_vector &lt;- c(1, 2, 3, 4, 5)\nmy_vector[3]  # Extracts the element at index 3\n\n[1] 3\n\n\n\n\nData Frames:\nWhen used with a data frame, it can be used to extract columns or rows.\n\n# Example with a data frame\n\ndf &lt;- tibble::tibble(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"), \n  age = c(25, 30, 22)\n  )\n\n# Extract the age column\ndf[\"age\"]\n\n# A tibble: 3 × 1\n    age\n  &lt;dbl&gt;\n1    25\n2    30\n3    22\n\n\n\n\n\nTwo Brackets [[ ]]:\n\nLists:\nWhen working with lists, double brackets are used to extract elements from the list. The result is the actual element, not a list containing the element.\n\n# Example with a list\nmy_list &lt;- list(1, \n                c(2, 3), \n                \"four\")\n\nmy_list[[2]]  # Extracts the second element (a vector) from the list\n\n[1] 2 3\n\n\nCompare to using []\n\nmy_list[2]\n\n[[1]]\n[1] 2 3\n\n\n[[]] returned the vector contained in that slot. [] returned a list containing the vector.\n\n\nNested Data Structures:\nFor accessing elements in nested data structures like lists within lists.\n\n# Example with a nested list\nnested_list &lt;- list(first = list(a = 1, b = 2), \n                    second = list(c = 3, d = 4))\n\nnested_list\n\n$first\n$first$a\n[1] 1\n\n$first$b\n[1] 2\n\n\n$second\n$second$c\n[1] 3\n\n$second$d\n[1] 4\n\nnested_list[[1]] # Extract the list contained in the first slot\n\n$a\n[1] 1\n\n$b\n[1] 2\n\nnested_list[[1]][[\"b\"]]  # Extracts the value associated with \"b\" in the first list\n\n[1] 2\n\n\nIn summary, one bracket [ ] is used for general subsetting, whether it’s extracting elements from vectors, columns from data frames, or specific elements from lists. On the other hand, two brackets [[ ]] are specifically used for extracting elements from lists and accessing elements in nested structures.\n\n\n\n\nHow and when to use curly curly within a function\n{{ }} will be covered in upcoming class lectures. We talked about it in Week 8 as a quick aside because a specific question came up. Not much detail was given intentionally as it is a separate topic for another day."
  },
  {
    "objectID": "weeks/week_10.html",
    "href": "weeks/week_10.html",
    "title": "Week 10",
    "section": "",
    "text": "Grades for midterm projects will be released in 1-2 days.\n\nYou will be notified by Sakai via your OHSU email address when grades are released.\nPlease review the comments and let us know if you have any questions.\n\nPlease fill out the course evaluations for the class.\n\nCourse evaluations are very helpful for making improvements to our classes.\nIf too few students fill out the evaluations, they are not released to us.\nYou might have two evaluations since there are two instructors.\n\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_10.html#announcements",
    "href": "weeks/week_10.html#announcements",
    "title": "Week 10",
    "section": "",
    "text": "Grades for midterm projects will be released in 1-2 days.\n\nYou will be notified by Sakai via your OHSU email address when grades are released.\nPlease review the comments and let us know if you have any questions.\n\nPlease fill out the course evaluations for the class.\n\nCourse evaluations are very helpful for making improvements to our classes.\nIf too few students fill out the evaluations, they are not released to us.\nYou might have two evaluations since there are two instructors.\n\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_10.html#topics",
    "href": "weeks/week_10.html#topics",
    "title": "Week 10",
    "section": "Topics",
    "text": "Topics\n\nPart 8\n\nIntroduce simple statistical modelling\nLearn about the useful broom package\nMore iteration with purrr\nSlitting up data for iteration\nOther useful purrr"
  },
  {
    "objectID": "weeks/week_10.html#class-materials",
    "href": "weeks/week_10.html#class-materials",
    "title": "Week 10",
    "section": "Class materials",
    "text": "Class materials\nReadings are linked below, and we are using the part_08 material on One Drive.\n\nWeek 10 Readings\nOneDrive part_08 Project folders"
  },
  {
    "objectID": "weeks/week_10.html#post-class-survey",
    "href": "weeks/week_10.html#post-class-survey",
    "title": "Week 10",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_10.html#homework",
    "href": "weeks/week_10.html#homework",
    "title": "Week 10",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 10 due on 3/20. Assignment is in the part 8 folder."
  },
  {
    "objectID": "weeks/week_10.html#recording",
    "href": "weeks/week_10.html#recording",
    "title": "Week 10",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_10.html#feedback-from-post-class-surveys",
    "href": "weeks/week_10.html#feedback-from-post-class-surveys",
    "title": "Week 10",
    "section": "Feedback from post-class surveys",
    "text": "Feedback from post-class surveys\n\nWeek 10 feedback will be added here during Week 11.\nSee Week 9 page for Week 9 feedback."
  },
  {
    "objectID": "weeks/week_09.html#muddiest-points-from-week-9",
    "href": "weeks/week_09.html#muddiest-points-from-week-9",
    "title": "Week 9",
    "section": "Muddiest points from Week 9",
    "text": "Muddiest points from Week 9\n\nSee Week 8 page for Week 8 feedback."
  },
  {
    "objectID": "weeks/week_09.html#matrices",
    "href": "weeks/week_09.html#matrices",
    "title": "Week 9",
    "section": "Matrices",
    "text": "Matrices\n\nNot entirely sure how to read or make sense of matrices yet (maybe I should have payed more attention in algebra), like when we saw the structure of a matrix here in the class script: str(output_model$coefficients)\n\nIn R, matrices are two-dimensional data structures that can store elements of the same data type. They are similar to vectors but have two dimensions (rows and columns). They are widely used in various statistical and mathematical operations, making them a fundamental data structure in the R.\n\nBasic way to create matrices\n\n# Create a matrix with values filled column-wise\n(mat1 &lt;- matrix(1:6, nrow = 2, ncol = 3, byrow = FALSE))\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n# Create a matrix with values filled row-wise\n(mat2 &lt;- matrix(1:6, nrow = 2, ncol = 3, byrow = TRUE))\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n\n\n\n\nAccessing elements of a matrix\n\n# Accessing individual elements\nelement &lt;- mat1[1, 2]  # Row 1, Column 2\nelement\n\n[1] 3\n\n\n\n# Accessing entire row or column\nrow_vector &lt;- mat1[1, ]  # Entire first row\nrow_vector\n\n[1] 1 3 5\n\ncol_vector &lt;- mat1[, 2]  # Entire second column\ncol_vector\n\n[1] 3 4\n\n\n\n\nConvert to data.frame\n\nas.data.frame(mat1)\n\n  V1 V2 V3\n1  1  3  5\n2  2  4  6\n\n\n\nlibrary(tibble)\ntibble::as_tibble(mat1)\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\n# A tibble: 2 × 3\n     V1    V2    V3\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n# You can also name the columns (and the rows)\n\ncolnames(mat1) &lt;- c(\"a\", \"b\", \"c\")\nmat1\n\n     a b c\n[1,] 1 3 5\n[2,] 2 4 6\n\ntibble::as_tibble(mat1)\n\n# A tibble: 2 × 3\n      a     b     c\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6"
  },
  {
    "objectID": "weeks/week_09.html#for-loops",
    "href": "weeks/week_09.html#for-loops",
    "title": "Week 9",
    "section": "for() loops",
    "text": "for() loops\n\nStill a little confused about the for() loops…\n\nFor loops are a staple in programming languages, not just R. They are used when we want to repeat the same operation (or a set of operations) several times.\nThe basis syntax in R looks like:\n\nfor (variable in sequence) {\n  # Statements to be executed for each iteration\n}\n\nHere’s a breakdown of the components:\n\nvariable: This is a loop variable that takes on each value in the specified sequence during each iteration of the loop.\nsequence: This is the sequence of values over which the loop iterates. It can be a vector, list, or any other iterable object.\nLoop Body: The statements enclosed within the curly braces {} constitute the body of the loop. These statements are executed for each iteration of the loop.\n\n\nBasic example\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nFirst iteration manually:\n\ni &lt;- 1\nprint(i)\n\n[1] 1\n\n\nSecond iteration manually:\n\ni &lt;- 2\nprint(i)\n\n[1] 2\n\n\nEtc.\n\n\nAdapted from 1st edition of R for Data Science\nHere’s a tibble for an example\n\npacman::p_load(tidyverse)\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf\n\n# A tibble: 10 × 4\n        a       b      c      d\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 -0.462 -1.51    0.528 -0.802\n 2 -0.278  0.225   0.523 -0.625\n 3  0.432  1.22    1.07   1.44 \n 4 -1.67   1.20   -0.203  1.63 \n 5 -0.478 -0.814   0.336 -1.87 \n 6 -0.466  0.529   1.74   0.984\n 7 -0.934 -0.0985  0.668  1.08 \n 8 -0.600 -1.98    0.674 -0.469\n 9 -0.820 -0.316  -1.38   1.59 \n10 -1.71   1.25   -1.26   1.33 \n\n\nUsing a copy and paste method to calculate the mean of each column would look something like this:\n\nmedian(df$a)\n\n[1] -0.5388446\n\nmedian(df$b)\n\n[1] 0.06331579\n\nmedian(df$c)\n\n[1] 0.5253658\n\nmedian(df$d)\n\n[1] 1.030272\n\n\nBut this breaks the rule of DRY (“Don’t repeat yourself”)\n\noutput &lt;- c()  # vector to store the results of the for loop\n\nfor (i in seq_along(df)) {\n  \n  output[i] &lt;- median(df[[i]])\n  \n}\n\noutput\n\n[1] -0.53884460  0.06331579  0.52536580  1.03027185\n\n\nFor loops in R are commonly used when you know the number of iterations in advance or when you need to iterate over a specific sequence of values. While for loops are useful, R also provides other ways to perform iteration, such as using vectorized operations (example below) and functions from the apply family (not covered). It’s often recommended to explore these alternatives when working with R for better code efficiency and readability.\n\n# Creating two vectors\nvector1 &lt;- c(1, 2, 3, 4, 5)\nvector2 &lt;- c(6, 7, 8, 9, 10)\n\n# Vectorized addition\nresult_addition &lt;- vector1 + vector2\nresult_addition\n\n[1]  7  9 11 13 15\n\n# With a for loop\nresult_addition_for_loop &lt;- c()\n\nfor (i in 1:length(vector1)) {\n  \n  result_addition_for_loop[i] &lt;- vector1[i] + vector2[i]\n  \n}\n\nresult_addition_for_loop\n\n[1]  7  9 11 13 15"
  },
  {
    "objectID": "weeks/week_09.html#na.rm-vs-na.omit",
    "href": "weeks/week_09.html#na.rm-vs-na.omit",
    "title": "Week 9",
    "section": "na.rm vs na.omit",
    "text": "na.rm vs na.omit\n\nIs there a difference between na.rm and na.omit?\n\nYes, there is a difference. In R, they are used in different context.\n\nna.rm (Remove)\n\nna.rm is an argument found in various functions (e.g. mean(), sum(), etc.) that allows you to specify whether missing values (NA or NaN) should be removed before performing the calculation.\nFrom the help for mean() (?mean): a logical evaluating to TRUE or FALSE indicating whether NA values should be stripped before the computation proceeds.\n\n# A vector with NA values\nvalues_with_na &lt;- c(1, 2, 3, NA, 5)\n\nmean(values_with_na, na.rm = FALSE)  # Result will be NA\n\n[1] NA\n\n# Excluding NA values\nmean(values_with_na, na.rm = TRUE)  # Result will be (1+2+3+5)/4 = 2.75\n\n[1] 2.75\n\n\n\nna.omit (Omit missing)\n\nna.omit is a function that can be used to remove rows with missing values (NA) from a data frame or matrix.\n\n# Creating a data frame with NA values\ndf &lt;- data.frame(A = c(1, 2, NA, 4), B = c(5, NA, 7, 8))\n\n# NAs in the columns of the data frame\ndf\n\n   A  B\n1  1  5\n2  2 NA\n3 NA  7\n4  4  8\n\n# Using na.omit to remove rows with NA values\ndf |&gt; \n  na.omit()\n\n  A B\n1 1 5\n4 4 8"
  },
  {
    "objectID": "weeks/week_09.html#purrrmap",
    "href": "weeks/week_09.html#purrrmap",
    "title": "Week 9",
    "section": "purrr::map()",
    "text": "purrr::map()\n\nI am still a little foggy on the formatting of purrrmap and how to utilize it effectively.\n\nThe purrr::map function is used to apply a specified function to each element of a list or vector, returning the results in a new list.\n\nBasic Syntax:\n\npurrr::map(.x, .f, ...)\n\n\n.x: The input list or vector.\n.f: The function to apply to each element of .x.\n...: Additional arguments passed to the function specified in .f.\n\n\n\nKey Features:\n\nConsistent Output:\n\nmap returns a list, ensuring a consistent output format regardless of the input structure.\n\nFunction Application:\n\nThe primary purpose is to apply a specified function to each element of the input .x.\n\nFormula Interface:\n\nSupports a formula interface (~) for concise function specifications.\n\npurrr::map(.x, ~ function(.))\n\n\n\nExample:\n\n# Sample list\nmy_list &lt;- list(a = 1:3, \n                b = c(4, 5, 6), \n                c = rnorm(n = 3))\n\nmy_list\n\n$a\n[1] 1 2 3\n\n$b\n[1] 4 5 6\n\n$c\n[1]  0.246615980 -0.005590403 -0.151755392\n\n# Using map to square each element in the list\nsquared_list &lt;- purrr::map(.x = my_list, \n                           .f = ~ .x ^ 2)\n\nsquared_list\n\n$a\n[1] 1 4 9\n\n$b\n[1] 16 25 36\n\n$c\n[1] 0.0608194414 0.0000312526 0.0230296988\n\n\nIn this example, the map function applies the squaring function (~ .x ^ 2) to each element of the input list my_list. The resulting squared_list is a list where each element is the squared version of the corresponding element in my_list.\nThe purrr::map function is particularly useful when working with lists and helps to create cleaner and more readable code, especially in cases where you want to apply the same operation to each element of a collection."
  },
  {
    "objectID": "weeks/week_09.html#general-references",
    "href": "weeks/week_09.html#general-references",
    "title": "Week 9",
    "section": "General references",
    "text": "General references\n\nIs there a good dictionary type document with “R language” or very basic function descriptions? … find it difficult to know what functions I need because it is hard to recall their name or confuse it with a different function.\n\n\nR Documentation (Built-in Help): R itself provides built-in documentation that you can access using the help() function or the ? operator. For example, to get help on the mean() function, you can type help(mean) or ?mean in the R console.\nR Manuals and Guides: The official R documentation, including manuals and guides, is available on the R Project website: R Manuals.\nR Packages Documentation: Many R packages come with detailed documentation. You can find documentation for a specific package by visiting the CRAN website (Comprehensive R Archive Network) and searching for the package of interest.\nOnline Resources: Websites like RDocumentation provide a searchable database of R functions along with their documentation. You can search for a specific function and find details on its usage and parameters.\nRStudio cheatsheets\nBase R cheatsheet\nR: A Language and Environment for Statistical Computing: Reference Index\nCRAN Task Views\nPart 3 section on getting help with errors.\nBooks like “R for Data Science” by Hadley Wickham\nWhen you use a function or learn to use it, make notes to yourself using Google Doc or OneNote or something similar."
  },
  {
    "objectID": "weeks/week_11.html",
    "href": "weeks/week_11.html",
    "title": "Week 11",
    "section": "",
    "text": "No new material this week.\n\nClass will be office hours and held online via Webex.\nSee your email, Slack, or Sakai for the link.\n\n\nMeike’s office hours this week\n\nThursday 4-5 pm (instead of Friday at 3:30).\nUse same Webex link as usual office hours.\n\nFinal exam due Friday 3/22/2024 at 5:00 pm.\n\nSee OneDrive folder final_exam for files.\n\nGrades for midterm projects have been released.\n\nCheck the feedback attachment in Sakai (Excel file) for grade calculation and comments for each section.\nPoints were calculated using the grading rubric in the syllabus. The final grade is out of 10 points. See the grading scale for letter grade conversion.\nPlease review the comments and let us know if you have any questions.\n\nPlease fill out the course evaluations for the class.\n\nCourse evaluations are very helpful for making improvements to our classes.\nIf too few students fill out the evaluations, they are not released to us.\nYou might have two evaluations since there are two instructors."
  },
  {
    "objectID": "weeks/week_11.html#announcements",
    "href": "weeks/week_11.html#announcements",
    "title": "Week 11",
    "section": "",
    "text": "No new material this week.\n\nClass will be office hours and held online via Webex.\nSee your email, Slack, or Sakai for the link.\n\n\nMeike’s office hours this week\n\nThursday 4-5 pm (instead of Friday at 3:30).\nUse same Webex link as usual office hours.\n\nFinal exam due Friday 3/22/2024 at 5:00 pm.\n\nSee OneDrive folder final_exam for files.\n\nGrades for midterm projects have been released.\n\nCheck the feedback attachment in Sakai (Excel file) for grade calculation and comments for each section.\nPoints were calculated using the grading rubric in the syllabus. The final grade is out of 10 points. See the grading scale for letter grade conversion.\nPlease review the comments and let us know if you have any questions.\n\nPlease fill out the course evaluations for the class.\n\nCourse evaluations are very helpful for making improvements to our classes.\nIf too few students fill out the evaluations, they are not released to us.\nYou might have two evaluations since there are two instructors."
  },
  {
    "objectID": "weeks/week_11.html#topics",
    "href": "weeks/week_11.html#topics",
    "title": "Week 11",
    "section": "Topics",
    "text": "Topics\n\nNo new material will be covered this week."
  },
  {
    "objectID": "weeks/week_11.html#class-materials",
    "href": "weeks/week_11.html#class-materials",
    "title": "Week 11",
    "section": "Class materials",
    "text": "Class materials\nReadings are linked below, and we are using the part_08 material on One Drive.\n\nWeek 10 Readings\nOneDrive part_08 Project folders"
  },
  {
    "objectID": "weeks/week_11.html#post-class-survey",
    "href": "weeks/week_11.html#post-class-survey",
    "title": "Week 11",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!"
  },
  {
    "objectID": "weeks/week_11.html#homework",
    "href": "weeks/week_11.html#homework",
    "title": "Week 11",
    "section": "Homework",
    "text": "Homework\n\nSee OneDrive folder for homework assignment.\nHW 10 due on 3/20. Assignment is in the part 8 folder.\n\nRecall that the lowest HW score is dropped"
  },
  {
    "objectID": "weeks/week_11.html#recording",
    "href": "weeks/week_11.html#recording",
    "title": "Week 11",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_11.html#feedback-from-post-class-surveys",
    "href": "weeks/week_11.html#feedback-from-post-class-surveys",
    "title": "Week 11",
    "section": "Feedback from post-class surveys",
    "text": "Feedback from post-class surveys\n\nWeek 10 feedback will be added here during Week 11.\nSee Week 9 page for Week 9 feedback."
  },
  {
    "objectID": "weeks/week_10.html#muddiest-points-from-week-10",
    "href": "weeks/week_10.html#muddiest-points-from-week-10",
    "title": "Week 10",
    "section": "Muddiest points from Week 10",
    "text": "Muddiest points from Week 10\n\nSee Week 9 page for Week 9 feedback."
  },
  {
    "objectID": "weeks/week_10.html#confusion-on-details-of-purrrmap",
    "href": "weeks/week_10.html#confusion-on-details-of-purrrmap",
    "title": "Week 10",
    "section": "Confusion on details of purrr::map()",
    "text": "Confusion on details of purrr::map()\npurrr::map() applies a function to each element of a vector or list and returns a new list where each element is the result of applying that function to the corresponding element of the original vector or list.\n\nmap(.x, .f, ..., .progress = FALSE)\n\n\n.x the vector or list that you operate on\n.f the function you want to apply to each element of the input vector or list. This function can be a built-in R function, a user-defined function, or an anonymous function defined on the fly.\n\n\nSimple example\n\nlibrary(tidyverse)\n\n# Example list\nnumbers &lt;- list(1, 2, 3, 4, 5)\nnumbers\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] 5\n\n# Using map to square each element of the list\nsquared_numbers &lt;- purrr::map(.x = numbers, \n                              .f = ~ .x ^ 2)\n\nIn this example: - numbers is a list containing numbers from 1 to 5. - ~ .x ^ 2 is an anonymous function that squares its input. - map() applies this anonymous function to each element of the numbers list, resulting in a new list where each element is the square of the corresponding element in the original list.\nAfter executing this code, the squared_numbers variable will contain the squared values of the original list:\n\nsquared_numbers\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\n\n\n\n\nExample with a list of data frames\nSuppose we have a list of data frames where each data frame represents the sales data for different products. We want to calculate the total sales for each product across all the data frames in the list.\n\n# Sample list of data frames\nsales_data &lt;- list(\n  product1 = data.frame(month = 1:3, sales = c(100, 150, 200)),\n  product2 = data.frame(month = 1:3, sales = c(120, 180, 220)),\n  product3 = data.frame(month = 1:3, sales = c(90, 130, 170))\n)\n\nsales_data\n\n$product1\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n$product2\n  month sales\n1     1   120\n2     2   180\n3     3   220\n\n$product3\n  month sales\n1     1    90\n2     2   130\n3     3   170\n\n\nCreate a function `and apply it to each slot insales_data` list:\n\n# Function to calculate total sales for each data frame\ncalculate_total_sales &lt;- function(df) {\n  total_sales &lt;- sum(df$sales)\n  return(total_sales)\n}\n\n# Applying the function to each data frame in the list\ntotal_sales_per_product &lt;- purrr::map(.x = sales_data, \n                                      .f = calculate_total_sales)\n\nIn this example: - sales_data is a list containing three data frames, each representing the sales data for a different product. - calculate_total_sales() is a function that takes a data frame as input and calculates the total sales for that product. - map() applies the calculate_total_sales() function to each data frame in the sales_data list, resulting in a new list total_sales_per_product, where each element is the total sales for a specific product across all months.\nAfter executing this code, the total_sales_per_product variable will contain the total sales for each product:\n\ntotal_sales_per_product\n\n$product1\n[1] 450\n\n$product2\n[1] 520\n\n$product3\n[1] 390\n\n\nSo, total_sales_per_product is a named list where each element represents the total sales for a specific product across all the data frames in the original list."
  },
  {
    "objectID": "weeks/week_10.html#purrrreduce",
    "href": "weeks/week_10.html#purrrreduce",
    "title": "Week 10",
    "section": "purrr::reduce()",
    "text": "purrr::reduce()\n\nHow does it compare to purrr::map()?\nThe big difference between map() and reduce() has to do with what it returns:\n\nmap() usually returns a list or data structure with the same number as its input; The goal of reduce() is to take a list of items and return a single object.\n\nSee the purrr cheatsheet.\n\n\nSimple example\n\n# Example vector\nnumbers &lt;- c(1, 2, 3, 4, 5)\nnumbers\n\n[1] 1 2 3 4 5\n\n# Using reduce to calculate cumulative sum\ncumulative_sum &lt;- purrr::reduce(.x = numbers, \n                                .f = `+`)\n\nIn this example: - numbers is the vector we want to operate on. - The function + is used as the operation to perform at each step of reduction, which in this case is addition. - reduce() will start by adding the first two elements (1 and 2), then add the result to the third element (3), and so on, until all elements have been processed.\nAfter executing this code, the cumulative_sum variable will contain the cumulative sum of the numbers:\n\ncumulative_sum\n\n[1] 15\n\n\nThe steps are as follows:\n\n(cum_numbers &lt;- numbers[1])\n\n[1] 1\n\n(cum_numbers &lt;- cum_numbers + numbers[2])\n\n[1] 3\n\n(cum_numbers &lt;- cum_numbers + numbers[3])\n\n[1] 6\n\n(cum_numbers &lt;- cum_numbers + numbers[4])\n\n[1] 10\n\n(cum_numbers &lt;- cum_numbers + numbers[5])\n\n[1] 15\n\n\n\n\nWith data frames\nUsing our sales data list from above\n\nsales_data\n\n$product1\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n$product2\n  month sales\n1     1   120\n2     2   180\n3     3   220\n\n$product3\n  month sales\n1     1    90\n2     2   130\n3     3   170\n\n\nWe can combined the data sets in the list with reduce() and bind_rows()\n\n# Using an anonymous function, note bind_rows takes 2 arguments.\ncombined_sales_data &lt;- purrr::reduce(.x = sales_data, \n                                     .f = function(x, y) bind_rows(x, y))\n\n\n# Using a named function\ncombined_sales_data &lt;- purrr::reduce(.x = sales_data, \n                                     .f = dplyr::bind_rows)\n\nIn this example: - We use an anonymous function within reduce() that takes two arguments x and y, representing the accumulated result and the next element in the list, respectively. - Inside the anonymous function, we use bind_rows() to combine the accumulated result x with the next element y, effectively stacking them on top of each other. - reduce() applies this anonymous function iteratively to the list of data frames, resulting in a single data frame combined_sales_data that contains the combined sales data for all products.\n\ncombined_sales_data\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n7     1    90\n8     2   130\n9     3   170\n\n\nDoing this in steps:\n\n(cum_sales_data &lt;- dplyr::bind_rows(sales_data[[1]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n(cum_sales_data &lt;- dplyr::bind_rows(cum_sales_data, \n                                    sales_data[[2]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n\n(cum_sales_data &lt;- dplyr::bind_rows(cum_sales_data, \n                                    sales_data[[3]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n7     1    90\n8     2   130\n9     3   170\n\n\n\n\nExamples of reduce\n\nPretty involved example from Maelle Salmon, but good practice\nTidyverse reference with examples\nR for Data Science, First Edition\nAnother exmple blog post"
  },
  {
    "objectID": "weeks/week_10.html#list.files-function",
    "href": "weeks/week_10.html#list.files-function",
    "title": "Week 10",
    "section": "List.files function",
    "text": "List.files function\nthe list.files() function is used to obtain a character vector of file names in a specified directory. Here’s a breakdown of how it works and its common parameters:\n\nDirectory Path: The primary argument of list.files() is the path to the directory you want to list files from. If not specified, it defaults to the current working directory.\nPattern Matching: pattern is an optional argument that allows you to specify a pattern for file names. Only file names matching this pattern will be returned. This can be useful for filtering specific types of files.\nRecursive Listing: If recursive = TRUE, the function will list files recursively, i.e., it will include files from subdirectories as well. By default, recursive is set to FALSE.\nFile Type: The full.names argument controls whether the returned file names should include the full path (if TRUE) or just the file names (if FALSE, the default).\nCharacter Encoding: You can specify the encoding argument to handle file names with non-ASCII characters. This argument is especially useful on Windows systems where file names may use a different character encoding.\n\nHere’s a simple example demonstrating the basic usage of list.files():\n\n# List files in the current directory\nfiles &lt;- list.files()\n\n# Print the file names\nprint(files)\n\n [1] \"_extensions\"        \"_quarto.yml\"        \"about.qmd\"         \n [4] \"BSTA_526_W24.Rproj\" \"data\"               \"docs\"              \n [7] \"function_week\"      \"function_week.qmd\"  \"images\"            \n[10] \"index.qmd\"          \"readings\"           \"readings.qmd\"      \n[13] \"resources\"          \"schedule.qmd\"       \"styles.css\"        \n[16] \"syllabus.qmd\"       \"weeks\"              \"weeks.qmd\"         \n\n\nThis will print the names of all files in the current working directory.\n\n#| eval: false\n\n# List CSV files in a specific directory\ncsv_files &lt;- list.files(path = \"path/to/directory\", pattern = \"\\\\.csv$\")\n\n# Print the CSV file names\nprint(csv_files)\n\ncharacter(0)\n\n\nThis will print the names of all CSV files in the specified directory.\nOverall, list.files() is a handy function for obtaining file names within a directory, providing flexibility through various parameters for customization according to specific needs, such as filtering by pattern or handling file names with non-standard characters.\nNOTE You need to pay attention to your working directory and your relative file paths. See Week 2 or 3 (?) about here package and the discussion about files paths. Best to always use Rprojects and the here package."
  },
  {
    "objectID": "weeks/week_11.html#muddiest-points",
    "href": "weeks/week_11.html#muddiest-points",
    "title": "Week 11",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nSee Week 10 page for Week 10 feedback."
  }
]