[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Schedule is subject to change.\nLinks have been added to all weeks, but weeks we have not covered yet will have broken links.\n\n\n\n\nWeek\nDate\nTopics\nInstructor\n\n\n\n\n1\n1/09\nIntroduction to course/expectations, Intro to R/RStudio, Functions, Vectors, Data Types\nMeike\n\n\n2\n1/16\nLoading Data, data.frames, and ggplot2\nJessica\n\n\n3\n1/23\ndplyr: subsetting using filter()/select(), more ggplot: themes, scales, facets\nJessica\n\n\n4\n1/30\ndplyr: mutate(), across(), case_when(), factors, summarize() and group_by(); ggplot: boxplots, scales\nJessica\n\n\n5\n2/6\ndata wrangling practice: forcats, stringr, separate(); combining multiple tables (left_join() etc); reshaping data (i.e. pivot_longer())\nMeike\n\n\n\n2/6\nTake Home Midterm Assigned\n\n\n\n6\n2/13\nMore data wrangling practice\nMeike\n\n\n\n\n\n\n\n\n7\n2/20\nMore data wrangling practice ctd.\nMeike\n\n\n\n2/23\nTake home midterm due (Sunday)\n\n\n\n8\n2/27\nIntro to functions, working with lists\nJessica\n\n\n9\n3/6\nIteration\nJessica\n\n\n10\n3/10\nFinal Project Assigned (Monday)\n\n\n\n10\n3/13\nMore Stats/Purrr\nMeike\n\n\n11\n3/20\nNo Class, Office Hour\n\n\n\n\n3/22\nFinal Project Due (Saturday)"
  },
  {
    "objectID": "readings/06-reading.html",
    "href": "readings/06-reading.html",
    "title": "Week 6 Readings",
    "section": "",
    "text": "No new readings. Catch up on the previously assigned ones. :)"
  },
  {
    "objectID": "readings/06-reading.html#required",
    "href": "readings/06-reading.html#required",
    "title": "Week 6 Readings",
    "section": "",
    "text": "coming soon!"
  },
  {
    "objectID": "readings/06-reading.html#suggested",
    "href": "readings/06-reading.html#suggested",
    "title": "Week 6 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nDates and timess (Ch 17) in R for Data Science 2nd Ed"
  },
  {
    "objectID": "readings/09-reading.html",
    "href": "readings/09-reading.html",
    "title": "Week 9 Readings",
    "section": "",
    "text": "Same readings as Week 8."
  },
  {
    "objectID": "readings/05-reading.html",
    "href": "readings/05-reading.html",
    "title": "Week 5 Readings",
    "section": "",
    "text": "Control your Factors Using Forcats\nMore on joining data in Joins (Ch 19) from R for Data Science 2nd Ed"
  },
  {
    "objectID": "readings/05-reading.html#required",
    "href": "readings/05-reading.html#required",
    "title": "Week 5 Readings",
    "section": "",
    "text": "Control your Factors Using Forcats\nMore on joining data in Joins (Ch 19) from R for Data Science 2nd Ed"
  },
  {
    "objectID": "readings/05-reading.html#optional",
    "href": "readings/05-reading.html#optional",
    "title": "Week 5 Readings",
    "section": "Optional",
    "text": "Optional\nThe following resources are optional reading, but quite helpful in your Quarto journey.\n\nQuarto Cheatsheet\nQuarto Guide\nQuarto Reference\nChapter 28: Quarto from R for Data Science (2e)"
  },
  {
    "objectID": "readings/07-reading.html",
    "href": "readings/07-reading.html",
    "title": "Week 7 Readings",
    "section": "",
    "text": "Continue with Week 6 readings."
  },
  {
    "objectID": "readings/08-reading.html",
    "href": "readings/08-reading.html",
    "title": "Week 8 Readings",
    "section": "",
    "text": "Iteration in R for Data Science\nLearn to purrr"
  },
  {
    "objectID": "readings/08-reading.html#required",
    "href": "readings/08-reading.html#required",
    "title": "Week 8 Readings",
    "section": "",
    "text": "Iteration in R for Data Science\nLearn to purrr"
  },
  {
    "objectID": "readings/08-reading.html#suggested",
    "href": "readings/08-reading.html#suggested",
    "title": "Week 8 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nIntroduction to map() - Jenny Bryan\nSoftware Carpentry’s lesson on functions in R"
  },
  {
    "objectID": "weeks.html",
    "href": "weeks.html",
    "title": "Weekly Pages",
    "section": "",
    "text": "Links to weekly pages\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n1/9/25\n\n\nWeek 1\n\n\nIntro to R/RStudio, Functions, Vectors, Data Types\n\n\n\n\n1/16/25\n\n\nWeek 2\n\n\nProjects, data frames, reading in data, visualizing data with ggplot2\n\n\n\n\n1/23/25\n\n\nWeek 3\n\n\nErrors, more data loading, data manipulation, ggplot themes, factors\n\n\n\n\n1/30/25\n\n\nWeek 4\n\n\nmutate(), case_when(), summarize(), group_by(), across(), more ggplot2\n\n\n\n\n2/6/25\n\n\nWeek 5\n\n\nData cleaning, reshaping, and wrangling with multiple tables\n\n\n\n\n2/13/25\n\n\nWeek 6\n\n\nStart with your goal: more data wrangling\n\n\n\n\n2/20/25\n\n\nWeek 7\n\n\nStart with your goal: more data wrangling (cont’d)\n\n\n\n\n2/27/25\n\n\nWeek 8\n\n\nLists and Functions\n\n\n\n\n3/6/25\n\n\nWeek 9\n\n\nIteration\n\n\n\n\n3/13/25\n\n\nWeek 10\n\n\nMore stats and purrr\n\n\n\n\n3/20/25\n\n\nWeek 11\n\n\nFinal week\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to BSTA 526!",
    "section": "",
    "text": "Welcome to BSTA 526!\n\nR Programming for Health Data Science\nWinter 2025\nOHSU-PSU School of Public Health\nOregon Health & Science University\n\n\n\n\n\n\n\nInstructors\n Meike Niederhausen, PhD\n niederha@ohsu.edu\n Jessica Minnier, PhD  minnier@ohsu.edu\n\n\nCourse details\n Thursdays\n 9:00 am - 11:45 am  In-person, VPT 620M\n\n\nOffice Hours\n\nSee Sakai for Webex links to office hours.\n\n\n\n\n\nContacting us\nE-mail or Slack is the best way to get in contact with us.\nWe will try to respond to all course-related e-mails within 24 hours Monday-Friday.\n\n\n\n\n\n\n\n\n View the source on GitHub",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "weeks/week_09.html",
    "href": "weeks/week_09.html",
    "title": "Week 9",
    "section": "",
    "text": "For Loops\nIteration\nPurrr"
  },
  {
    "objectID": "weeks/week_09.html#announcements",
    "href": "weeks/week_09.html#announcements",
    "title": "Week 9",
    "section": "",
    "text": "This is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_09.html#topics",
    "href": "weeks/week_09.html#topics",
    "title": "Week 9",
    "section": "",
    "text": "For Loops\nIteration\nPurrr"
  },
  {
    "objectID": "weeks/week_09.html#class-materials",
    "href": "weeks/week_09.html#class-materials",
    "title": "Week 9",
    "section": "Class materials",
    "text": "Class materials\n\nWeek 8 Readings\nWeek 9 Readings\nDropbox part_08 Project folder"
  },
  {
    "objectID": "weeks/week_09.html#post-class-survey",
    "href": "weeks/week_09.html#post-class-survey",
    "title": "Week 9",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_09.html#homework",
    "href": "weeks/week_09.html#homework",
    "title": "Week 9",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment 9."
  },
  {
    "objectID": "weeks/week_09.html#recording",
    "href": "weeks/week_09.html#recording",
    "title": "Week 9",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_09.html#muddiest-points-from-week-9",
    "href": "weeks/week_09.html#muddiest-points-from-week-9",
    "title": "Week 9",
    "section": "Muddiest points from Week 9",
    "text": "Muddiest points from Week 9\n\nSee Week 8 page for Week 8 feedback."
  },
  {
    "objectID": "weeks/week_09.html#matrices",
    "href": "weeks/week_09.html#matrices",
    "title": "Week 9",
    "section": "Matrices",
    "text": "Matrices\n\nNot entirely sure how to read or make sense of matrices yet (maybe I should have payed more attention in algebra), like when we saw the structure of a matrix here in the class script: str(output_model$coefficients)\n\nIn R, matrices are two-dimensional data structures that can store elements of the same data type. They are similar to vectors but have two dimensions (rows and columns). They are widely used in various statistical and mathematical operations, making them a fundamental data structure in the R.\n\nBasic way to create matrices\n\n# Create a matrix with values filled column-wise\n(mat1 &lt;- matrix(1:6, nrow = 2, ncol = 3, byrow = FALSE))\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n# Create a matrix with values filled row-wise\n(mat2 &lt;- matrix(1:6, nrow = 2, ncol = 3, byrow = TRUE))\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n\n\n\n\nAccessing elements of a matrix\n\n# Accessing individual elements\nelement &lt;- mat1[1, 2]  # Row 1, Column 2\nelement\n\n[1] 3\n\n\n\n# Accessing entire row or column\nrow_vector &lt;- mat1[1, ]  # Entire first row\nrow_vector\n\n[1] 1 3 5\n\ncol_vector &lt;- mat1[, 2]  # Entire second column\ncol_vector\n\n[1] 3 4\n\n\n\n\nConvert to data.frame\n\nas.data.frame(mat1)\n\n  V1 V2 V3\n1  1  3  5\n2  2  4  6\n\n\n\nlibrary(tibble)\ntibble::as_tibble(mat1)\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\n# A tibble: 2 × 3\n     V1    V2    V3\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n# You can also name the columns (and the rows)\n\ncolnames(mat1) &lt;- c(\"a\", \"b\", \"c\")\nmat1\n\n     a b c\n[1,] 1 3 5\n[2,] 2 4 6\n\ntibble::as_tibble(mat1)\n\n# A tibble: 2 × 3\n      a     b     c\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6"
  },
  {
    "objectID": "weeks/week_09.html#for-loops",
    "href": "weeks/week_09.html#for-loops",
    "title": "Week 9",
    "section": "for() loops",
    "text": "for() loops\n\nStill a little confused about the for() loops…\n\nFor loops are a staple in programming languages, not just R. They are used when we want to repeat the same operation (or a set of operations) several times.\nThe basis syntax in R looks like:\n\nfor (variable in sequence) {\n  # Statements to be executed for each iteration\n}\n\nHere’s a breakdown of the components:\n\nvariable: This is a loop variable that takes on each value in the specified sequence during each iteration of the loop.\nsequence: This is the sequence of values over which the loop iterates. It can be a vector, list, or any other iterable object.\nLoop Body: The statements enclosed within the curly braces {} constitute the body of the loop. These statements are executed for each iteration of the loop.\n\n\nBasic example\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nFirst iteration manually:\n\ni &lt;- 1\nprint(i)\n\n[1] 1\n\n\nSecond iteration manually:\n\ni &lt;- 2\nprint(i)\n\n[1] 2\n\n\nEtc.\n\n\nAdapted from 1st edition of R for Data Science\nHere’s a tibble for an example\n\npacman::p_load(tidyverse)\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf\n\n# A tibble: 10 × 4\n         a       b      c      d\n     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1  0.162   0.588  -0.411  0.382\n 2 -0.723   0.0728  1.99   1.18 \n 3 -0.129  -0.0748  0.587 -0.362\n 4 -1.00   -1.75    0.815  1.07 \n 5 -0.359  -0.101  -0.537 -0.791\n 6  0.985   0.482  -0.704  0.716\n 7  0.144  -0.675   0.380 -1.78 \n 8  0.951  -1.38    0.415  0.405\n 9  0.854  -0.744   0.194 -1.23 \n10  0.0741 -0.948  -0.918  0.386\n\n\nUsing a copy and paste method to calculate the mean of each column would look something like this:\n\nmedian(df$a)\n\n[1] 0.1093116\n\nmedian(df$b)\n\n[1] -0.3882745\n\nmedian(df$c)\n\n[1] 0.2874271\n\nmedian(df$d)\n\n[1] 0.3841581\n\n\nBut this breaks the rule of DRY (“Don’t repeat yourself”)\n\noutput &lt;- c()  # vector to store the results of the for loop\n\nfor (i in seq_along(df)) {\n  \n  output[i] &lt;- median(df[[i]])\n  \n}\n\noutput\n\n[1]  0.1093116 -0.3882745  0.2874271  0.3841581\n\n\nFor loops in R are commonly used when you know the number of iterations in advance or when you need to iterate over a specific sequence of values. While for loops are useful, R also provides other ways to perform iteration, such as using vectorized operations (example below) and functions from the apply family (not covered). It’s often recommended to explore these alternatives when working with R for better code efficiency and readability.\n\n# Creating two vectors\nvector1 &lt;- c(1, 2, 3, 4, 5)\nvector2 &lt;- c(6, 7, 8, 9, 10)\n\n# Vectorized addition\nresult_addition &lt;- vector1 + vector2\nresult_addition\n\n[1]  7  9 11 13 15\n\n# With a for loop\nresult_addition_for_loop &lt;- c()\n\nfor (i in 1:length(vector1)) {\n  \n  result_addition_for_loop[i] &lt;- vector1[i] + vector2[i]\n  \n}\n\nresult_addition_for_loop\n\n[1]  7  9 11 13 15"
  },
  {
    "objectID": "weeks/week_09.html#na.rm-vs-na.omit",
    "href": "weeks/week_09.html#na.rm-vs-na.omit",
    "title": "Week 9",
    "section": "na.rm vs na.omit",
    "text": "na.rm vs na.omit\n\nIs there a difference between na.rm and na.omit?\n\nYes, there is a difference. In R, they are used in different context.\n\nna.rm (Remove)\n\nna.rm is an argument found in various functions (e.g. mean(), sum(), etc.) that allows you to specify whether missing values (NA or NaN) should be removed before performing the calculation.\nFrom the help for mean() (?mean): a logical evaluating to TRUE or FALSE indicating whether NA values should be stripped before the computation proceeds.\n\n# A vector with NA values\nvalues_with_na &lt;- c(1, 2, 3, NA, 5)\n\nmean(values_with_na, na.rm = FALSE)  # Result will be NA\n\n[1] NA\n\n# Excluding NA values\nmean(values_with_na, na.rm = TRUE)  # Result will be (1+2+3+5)/4 = 2.75\n\n[1] 2.75\n\n\n\nna.omit (Omit missing)\n\nna.omit is a function that can be used to remove rows with missing values (NA) from a data frame or matrix.\n\n# Creating a data frame with NA values\ndf &lt;- data.frame(A = c(1, 2, NA, 4), B = c(5, NA, 7, 8))\n\n# NAs in the columns of the data frame\ndf\n\n   A  B\n1  1  5\n2  2 NA\n3 NA  7\n4  4  8\n\n# Using na.omit to remove rows with NA values\ndf |&gt; \n  na.omit()\n\n  A B\n1 1 5\n4 4 8"
  },
  {
    "objectID": "weeks/week_09.html#purrrmap",
    "href": "weeks/week_09.html#purrrmap",
    "title": "Week 9",
    "section": "purrr::map()",
    "text": "purrr::map()\n\nI am still a little foggy on the formatting of purrrmap and how to utilize it effectively.\n\nThe purrr::map function is used to apply a specified function to each element of a list or vector, returning the results in a new list.\n\nBasic Syntax:\n\npurrr::map(.x, .f, ...)\n\n\n.x: The input list or vector.\n.f: The function to apply to each element of .x.\n...: Additional arguments passed to the function specified in .f.\n\n\n\nKey Features:\n\nConsistent Output:\n\nmap returns a list, ensuring a consistent output format regardless of the input structure.\n\nFunction Application:\n\nThe primary purpose is to apply a specified function to each element of the input .x.\n\nFormula Interface:\n\nSupports a formula interface (~) for concise function specifications.\n\npurrr::map(.x, ~ function(.))\n\n\n\nExample:\n\n# Sample list\nmy_list &lt;- list(a = 1:3, \n                b = c(4, 5, 6), \n                c = rnorm(n = 3))\n\nmy_list\n\n$a\n[1] 1 2 3\n\n$b\n[1] 4 5 6\n\n$c\n[1] -0.2999317 -0.8807203  1.1688468\n\n# Using map to square each element in the list\nsquared_list &lt;- purrr::map(.x = my_list, \n                           .f = ~ .x ^ 2)\n\nsquared_list\n\n$a\n[1] 1 4 9\n\n$b\n[1] 16 25 36\n\n$c\n[1] 0.08995903 0.77566826 1.36620287\n\n\nIn this example, the map function applies the squaring function (~ .x ^ 2) to each element of the input list my_list. The resulting squared_list is a list where each element is the squared version of the corresponding element in my_list.\nThe purrr::map function is particularly useful when working with lists and helps to create cleaner and more readable code, especially in cases where you want to apply the same operation to each element of a collection."
  },
  {
    "objectID": "weeks/week_09.html#general-references",
    "href": "weeks/week_09.html#general-references",
    "title": "Week 9",
    "section": "General references",
    "text": "General references\n\nIs there a good dictionary type document with “R language” or very basic function descriptions? … find it difficult to know what functions I need because it is hard to recall their name or confuse it with a different function.\n\n\nR Documentation (Built-in Help): R itself provides built-in documentation that you can access using the help() function or the ? operator. For example, to get help on the mean() function, you can type help(mean) or ?mean in the R console.\nR Manuals and Guides: The official R documentation, including manuals and guides, is available on the R Project website: R Manuals.\nR Packages Documentation: Many R packages come with detailed documentation. You can find documentation for a specific package by visiting the CRAN website (Comprehensive R Archive Network) and searching for the package of interest.\nOnline Resources: Websites like RDocumentation provide a searchable database of R functions along with their documentation. You can search for a specific function and find details on its usage and parameters.\nRStudio cheatsheets\nBase R cheatsheet\nR: A Language and Environment for Statistical Computing: Reference Index\nCRAN Task Views\nPart 3 section on getting help with errors.\nBooks like “R for Data Science” by Hadley Wickham\nWhen you use a function or learn to use it, make notes to yourself using Google Doc or OneNote or something similar."
  },
  {
    "objectID": "weeks/week_11.html",
    "href": "weeks/week_11.html",
    "title": "Week 11",
    "section": "",
    "text": "No new material this week.\n\nClass will be office hours and held online via Webex.\nSee your email, Slack, or Sakai for the link.\n\n\nMeike’s office hours this week\n\nThursday 4-5 pm (instead of Friday at 3:30).\nUse same Webex link as usual office hours.\n\nFinal exam due Friday 3/22/2025 at 5:00 pm.\n\nSee OneDrive folder final_exam for files.\n\nGrades for midterm projects have been released.\n\nCheck the feedback attachment in Sakai (Excel file) for grade calculation and comments for each section.\nPoints were calculated using the grading rubric in the syllabus. The final grade is out of 10 points. See the grading scale for letter grade conversion.\nPlease review the comments and let us know if you have any questions.\n\nPlease fill out the course evaluations for the class.\n\nCourse evaluations are very helpful for making improvements to our classes.\nIf too few students fill out the evaluations, they are not released to us.\nYou might have two evaluations since there are two instructors."
  },
  {
    "objectID": "weeks/week_11.html#announcements",
    "href": "weeks/week_11.html#announcements",
    "title": "Week 11",
    "section": "",
    "text": "No new material this week.\n\nClass will be office hours and held online via Webex.\nSee your email, Slack, or Sakai for the link.\n\n\nMeike’s office hours this week\n\nThursday 4-5 pm (instead of Friday at 3:30).\nUse same Webex link as usual office hours.\n\nFinal exam due Friday 3/22/2025 at 5:00 pm.\n\nSee OneDrive folder final_exam for files.\n\nGrades for midterm projects have been released.\n\nCheck the feedback attachment in Sakai (Excel file) for grade calculation and comments for each section.\nPoints were calculated using the grading rubric in the syllabus. The final grade is out of 10 points. See the grading scale for letter grade conversion.\nPlease review the comments and let us know if you have any questions.\n\nPlease fill out the course evaluations for the class.\n\nCourse evaluations are very helpful for making improvements to our classes.\nIf too few students fill out the evaluations, they are not released to us.\nYou might have two evaluations since there are two instructors."
  },
  {
    "objectID": "weeks/week_11.html#topics",
    "href": "weeks/week_11.html#topics",
    "title": "Week 11",
    "section": "Topics",
    "text": "Topics\n\nNo new material will be covered this week."
  },
  {
    "objectID": "weeks/week_11.html#homework",
    "href": "weeks/week_11.html#homework",
    "title": "Week 11",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment.\n\nRecall that the lowest HW score is dropped"
  },
  {
    "objectID": "weeks/week_11.html#recording",
    "href": "weeks/week_11.html#recording",
    "title": "Week 11",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_11.html#muddiest-points",
    "href": "weeks/week_11.html#muddiest-points",
    "title": "Week 11",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nPrevious muddiest and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_04.html",
    "href": "weeks/week_04.html",
    "title": "Week 4",
    "section": "",
    "text": "Learn and apply mutate() to change the data type of a variable\nApply mutate() to calculate a new variable based on other variables in a data.frame.\nApply case_when in a mutate() statement to make a continuous variable categorical\nLearn how to mutate() across() multiple columns at once.\nLearn how to summarize() data with group_by() to summarize within categories\nLearn to facet and change scales/palettes of ggplots."
  },
  {
    "objectID": "weeks/week_04.html#topics",
    "href": "weeks/week_04.html#topics",
    "title": "Week 4",
    "section": "",
    "text": "Learn and apply mutate() to change the data type of a variable\nApply mutate() to calculate a new variable based on other variables in a data.frame.\nApply case_when in a mutate() statement to make a continuous variable categorical\nLearn how to mutate() across() multiple columns at once.\nLearn how to summarize() data with group_by() to summarize within categories\nLearn to facet and change scales/palettes of ggplots."
  },
  {
    "objectID": "weeks/week_04.html#announcements",
    "href": "weeks/week_04.html#announcements",
    "title": "Week 4",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared Dropbox folder BSTA_526_W25_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_04, and then open RStudio by double-clicking on the file called part_04.Rproj.\nIf you have not already done so, please join the BSTA 526 Slack channel and introduce yourself by posting in the #random channel."
  },
  {
    "objectID": "weeks/week_04.html#class-materials",
    "href": "weeks/week_04.html#class-materials",
    "title": "Week 4",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nDropbox part_04 Project folder"
  },
  {
    "objectID": "weeks/week_04.html#post-class-survey",
    "href": "weeks/week_04.html#post-class-survey",
    "title": "Week 4",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_04.html#homework",
    "href": "weeks/week_04.html#homework",
    "title": "Week 4",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment.\nHW 4 due on 2/6."
  },
  {
    "objectID": "weeks/week_04.html#recording",
    "href": "weeks/week_04.html#recording",
    "title": "Week 4",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_04.html#keyboard-shortcut-for-the-pipe-or",
    "href": "weeks/week_04.html#keyboard-shortcut-for-the-pipe-or",
    "title": "Week 4",
    "section": "Keyboard shortcut for the pipe (%>% or |>)",
    "text": "Keyboard shortcut for the pipe (%&gt;% or |&gt;)\nIn office hours, someone didn’t know about this fact and wanted to make sure everyone knows about it.\n\n\n\n\n\n\nImportant keyboard shortcut\n\n\n\nIn RStudio the keyboard shortcut for the pipe operator %&gt;% (or native pipe |&gt;) is Ctrl + Shift + M (Windows) or Cmd + Shift + M (Mac).\nNote: Ctrl + Shift + M also works on a Mac."
  },
  {
    "objectID": "weeks/week_04.html#the-difference-between-na-value-and-0",
    "href": "weeks/week_04.html#the-difference-between-na-value-and-0",
    "title": "Week 4",
    "section": "The difference between NA value and 0",
    "text": "The difference between NA value and 0\n\nNA (Not Available)\n\nNA is a special value in R that represents missing or undefined data.\n0 is a numeric value representing the number zero. It is a valid and well-defined numerical value in R.\nIt’s important to handle NA values appropriately in data analysis and to consider their impact on calculations, as operations involving NA may result in NA.\n\n\nNA + 5  # The result is NA\n\n[1] NA\n\n0 + 5  # The results is 5\n\n[1] 5\n\nx &lt;- c(1, 2, NA, 4)\n\nsum(x)  # The result is NA\n\n[1] NA\n\n# Using the argument na.rm = TRUE, means to ignore the NAs\nsum(x, na.rm = TRUE) # The results is 7\n\n[1] 7\n\nx &lt;- c(1, 2, 0, 4)\n\nsum(x) # The result is 7\n\n[1] 7"
  },
  {
    "objectID": "weeks/week_04.html#across-and-its-usage",
    "href": "weeks/week_04.html#across-and-its-usage",
    "title": "Week 4",
    "section": "across() and it’s usage",
    "text": "across() and it’s usage\nThe biggest advantage that across brings is the ability to perform the same data manipulation task to multiple columns.\nBelow the values in three columns are all set to the mean value using the mean(). I had to write out the function and the variable names three times.\n\nsmoke_complete |&gt; \n  mutate(days_to_death = mean(days_to_death, na.rm = TRUE), \n         days_to_birth = mean(days_to_birth, na.rm = TRUE), \n         days_to_last_follow_up = mean(days_to_last_follow_up, na.rm = TRUE)) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\nThe same thing is accomplished using across() but we only have to call the mean() function once.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = ~ mean(.x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\nLinks to check out\n\nacross() vignette\nWhy I love dplyr’s across"
  },
  {
    "objectID": "weeks/week_04.html#and-.x",
    "href": "weeks/week_04.html#and-.x",
    "title": "Week 4",
    "section": "~ and .x",
    "text": "~ and .x\nWe’ve seen the ~ and .x used with dplyr::across(). We will see them again later when we get to the package purrr.\nIn the tidyverse, ~ and .x are used to create what they call lambda functions which are part of the purrr syntax. We have not talked about functions yet, but purrr package and the dplyr::across() function allow you to specify functions to apply in a few different ways:\n\nA named function, e.g. mean.\n\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = mean)) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove, just using the function name, we are not able to provide the additional argument na.rm = TRUE to the mean() function, so the columns are now all NA values because there were missing (NA) values in those columns.\n\n\n\nAn anonymous function, e.g. \\(x) x + 1 or function(x) x + 1.\n\nThis has not been covered yet. R lets you specify your own functions and there are two basic ways to do it.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = \\(x) mean(x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\nor\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = function(x) mean(x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we are able to use the additional argument na.rm = TRUE and the columns are now the means of the valid values in those columns.\n\n\n\nA purrr-style lambda function, e.g. ~ mean(.x, na.rm = TRUE)\n\nWe use ~ to indicate that we are supplying a lambda function and we use .x as a placeholder for the argument within our lambda function to indicate where to use the variable.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = ~ mean(.x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\nLinks to check out\nSome of these are purrr focused which we have not covered yet. Others use dplyr::across() withing the dplyr::summarize() function which we will be covering soon\n\nMeaning of tilde and dot notation in dplyr\nWhat is the meaning of ‘~’ and ‘.’ inside the function map?\nacross() vignette\nWhy I love dplyr’s across"
  },
  {
    "objectID": "weeks/week_04.html#exceptions-where-we-have-seen-the-used",
    "href": "weeks/week_04.html#exceptions-where-we-have-seen-the-used",
    "title": "Week 4",
    "section": "Exceptions where we have seen the ~ used",
    "text": "Exceptions where we have seen the ~ used\nIn class, we have seen three instances where the ~ is used that is not for a lambda function.\n\ncase_when\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = case_when(\n      cigarettes_per_day &lt; 6 ~ \"0-5\", \n      cigarettes_per_day &gt;= 6 ~ \"6+\"\n    )) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category    n    percent\n                 0-5 1100 0.95486111\n                  6+   52 0.04513889\n\n\n\n\nfacet_wrap\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_wrap(~ disease)\n\n\n\n\n\n\n\n\nPer the facet_wrap vignettte:\n\nFor compatibility with the classic interface, can also be a formula or character vector. Use either a one sided formula, ~a + b, or a character vector, c(\"a\", \"b\").\n\nHere it is being used to specify a formula.\nThough per the vignette, the vars() function is preferred syntax:\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_wrap(ggplot2::vars(disease))\n\n\n\n\n\n\n\n\n\n\nfacet_grid\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_grid(disease ~ vital_status)\n\n\n\n\n\n\n\n\nPer the facet_grid vignettte:\n\nFor compatibility with the classic interface, rows can also be a formula with the rows (of the tabular display) on the LHS and the columns (of the tabular display) on the RHS; the dot in the formula is used to indicate there should be no faceting on this dimension (either row or column).\n\nAgain, it is being used to specify a formula.\nThough per the vignette, the ggplot2::vars() function with the arguments rows and cols seems to be preferred:\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_grid(rows = ggplot2::vars(disease), \n             cols = ggplot2::vars(vital_status))\n\n\n\n\n\n\n\n\nNote: dplyr::vars() and dplyr::ggplot2() are the same function in different packages and can be used interchangeably."
  },
  {
    "objectID": "weeks/week_04.html#case_when-vs.-if_else",
    "href": "weeks/week_04.html#case_when-vs.-if_else",
    "title": "Week 4",
    "section": "case_when vs. if_else",
    "text": "case_when vs. if_else\nIn dplyr, both if_else() and case_when() are used for conditional transformations, but they have different use cases and behaviors.\n\nif_else function\n\n\nif_else() is designed for simple vectorized conditions and is particularly useful when you have a binary condition (i.e., two possible outcomes).\nIt evaluates a condition for each element of a vector and returns one of two values based on whether the condition is TRUE or FALSE.\n\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = dplyr::if_else(cigarettes_per_day &lt; 6, \"0-5\", \"6+\")) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category    n    percent\n                 0-5 1100 0.95486111\n                  6+   52 0.04513889\n\n\nIn this example, the column cigarettes_category is assigned the value “0-5” if cigarettes_per_day is less than 6 and “6+” otherwise.\n\ncase_when() function\n\n\ncase_when() is more versatile and is suitable for handling multiple conditions with multiple possible outcomes. It is essentially a vectorized form of a switch or if_else chain.\nIt allows you to specify multiple conditions and their corresponding values.\n\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = case_when(\n      cigarettes_per_day &lt; 2 ~ \"0 to 2\", \n      cigarettes_per_day &lt; 4 ~ \"2 to 4\", \n      cigarettes_per_day &lt; 6 ~ \"4 to 6\", \n      cigarettes_per_day &gt;= 6 ~ \"6+\"\n    )) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category   n    percent\n              0 to 2 455 0.39496528\n              2 to 4 493 0.42795139\n              4 to 6 152 0.13194444\n                  6+  52 0.04513889\n\n\nIn this example, the column cigarettes_category is assigned the value “0 to 2” if cigarettes_per_day is less than 2, “2 to 4” if less than 4 (but greater than 2), “4 to 6” if less than 6 (but greater than 4), and “6+” otherwise.\nUse if_else() when you have a simple binary condition, and use case_when() when you need to handle multiple conditions with different outcomes. case_when() is more flexible and expressive when dealing with complex conditional transformations."
  },
  {
    "objectID": "weeks/week_04.html#the-difference-between-a-theme-and-and-a-palette.",
    "href": "weeks/week_04.html#the-difference-between-a-theme-and-and-a-palette.",
    "title": "Week 4",
    "section": "The difference between a theme and and a palette.",
    "text": "The difference between a theme and and a palette.\nIn ggplot2, a theme and a palette serve different purposes and are used in different contexts. In summary, a theme controls the overall appearance of the plot, while a palette is specifically related to the colors used to represent different groups or levels within the data. Both themes and palettes contribute to visual appeal and readability of your plot.\n\nTheme:\n\n\nA theme in ggplot2 refers to the overall visual appearance of the plot. It includes elements such as fonts, colors, grid lines, background, and other visual attributes that define the look and feel of the entire plot.\nThemes are set using functions like theme_minimal(), theme_classic(), or custom themes created with the theme() function. Themes control the global appearance of the plot.\n\n\nlibrary(ggplot2)\n\n# Example using theme_minimal()\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\nPalette:\n\n\nA palette, on the other hand, refers to a set of colors used to represent different levels or categories in the data. It is particularly relevant when working with categorical or discrete data where you want to distinguish between different groups.\nPalettes are set using functions like scale_fill_manual() or scale_color_manual(). You can specify a vector of colors or use pre-defined palettes from packages like RColorBrewer or viridis (we looked at the viridis package in class).\n\n\n# Example using a color palette\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day, \n           color = disease)) + \n  geom_point() +\n  scale_color_manual(values = c(\"red\", \n                                \"blue\", \n                                \"green\"))"
  },
  {
    "objectID": "weeks/week_04.html#be-careful-what-you-pipe-to-and-from",
    "href": "weeks/week_04.html#be-careful-what-you-pipe-to-and-from",
    "title": "Week 4",
    "section": "Be careful what you pipe to and from",
    "text": "Be careful what you pipe to and from\nAn error came up where a data frame was being piped to a function that did not accept a data frame as an argument (it accepted a vector)\n\n# starwars data frame was loaded earlier with the ggplot2 package\n\nstarwars |&gt;  \n  dplyr::n_distinct(species) \n\nError in eval(expr, envir, enclos): object 'species' not found\n\n\n\nstarwars is a data frame.\ndplyr::n_distinct() only accepts a vector as an argument (check the help ?dplyr::n_distinct)\n\nSo we need to pipe a vector to the dplyr::n_distinct() function:\n\nstarwars |&gt; \n  dplyr::select(species) |&gt; \n  dplyr::n_distinct() \n\n[1] 38\n\n\ndplyr::select() accepts a data frame as its first argument and it return a vector (see the help ?dplyr::select) which we can then pipe to dplyr::n_distinct().\nThe %&gt;% or |&gt; takes the output of the expression on its left and passes it as the first argument to the function on its right. The class / type of output on the left needs to agree or be acceptable as the first argument to the function on the right."
  },
  {
    "objectID": "weeks/week_04.html#other-muddy-points",
    "href": "weeks/week_04.html#other-muddy-points",
    "title": "Week 4",
    "section": "Other muddy points",
    "text": "Other muddy points\n\nRemembering applicable functions. Troubleshooting.\n\n\nThis gets better with experience. You are all still very new to R so be patient with yourself.\n\n\nHow to organize all of the material to understand the structure of how the R language works, rather than to keep track of all of the commands in an anecdotal way.\n\n\nAgain, I think that this gets better with experience. Though the R language, being open source, a lot of syntax is package dependent. So you need to be careful that some of the syntax we use with dplyr and the tidyverse will be different in base R or in other packages. This is something that comes with open source software (compared to Stata or SAS). The good news is that learning to use packages sets you up to better learn newer (to you) packages down the road."
  },
  {
    "objectID": "weeks/week_06.html",
    "href": "weeks/week_06.html",
    "title": "Week 6",
    "section": "",
    "text": "If you haven’t already, please sign up for your function of the week presentation.\n\nPlease limit presentations to 3 per week.\nLink to sign-up sheet is posted on Sakai.\n\nThe Midterm is now posted in Dropbox. It is due Sunday 2/23/25.\n\nPlease start early on this since finding a suitable dataset might take some time.\nWe encourage you to meet with either of us to discuss your research question and data to make sure you are on the right track.\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_06.html#announcements",
    "href": "weeks/week_06.html#announcements",
    "title": "Week 6",
    "section": "",
    "text": "If you haven’t already, please sign up for your function of the week presentation.\n\nPlease limit presentations to 3 per week.\nLink to sign-up sheet is posted on Sakai.\n\nThe Midterm is now posted in Dropbox. It is due Sunday 2/23/25.\n\nPlease start early on this since finding a suitable dataset might take some time.\nWe encourage you to meet with either of us to discuss your research question and data to make sure you are on the right track.\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_06.html#topics",
    "href": "weeks/week_06.html#topics",
    "title": "Week 6",
    "section": "Topics",
    "text": "Topics\n\nFinish week 5\n\nWe will first finish the material not covered from Week 5, starting with section 4.6.\n\nNote: I created a new version of the code file (inside the code folder) called part_05_b526_v2.qmd/.html.\nI decided not to move the Week 5 material not covered to the Week 6 notes.\n\n\nFrom Week 5:\n\nLearn how to summarize() data with group_by() to summarize within categories\nLearn about the different kinds of joins and how they merge data\n\nApply inner_join() and left_join() to join tables on columns\n\nUtilize pivot_longer() to make a wide dataset long\n\n\n\nNew Week 6 topics - did not get to Part 6\n\nPractice working with real data\nPractice joining and pivoting\nPractice ggplot and learn more geometries\nLearn how to deal with missing data"
  },
  {
    "objectID": "weeks/week_06.html#class-materials",
    "href": "weeks/week_06.html#class-materials",
    "title": "Week 6",
    "section": "Class materials",
    "text": "Class materials\n\nWeek 6 Readings\nDropbox part_05 & part_06 Project folders"
  },
  {
    "objectID": "weeks/week_06.html#post-class-survey",
    "href": "weeks/week_06.html#post-class-survey",
    "title": "Week 6",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_06.html#homework",
    "href": "weeks/week_06.html#homework",
    "title": "Week 6",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment.\nHW 6 due on 2/20."
  },
  {
    "objectID": "weeks/week_06.html#recording",
    "href": "weeks/week_06.html#recording",
    "title": "Week 6",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_06.html#across",
    "href": "weeks/week_06.html#across",
    "title": "Week 6",
    "section": "across()",
    "text": "across()\nwhat exactly the across function does\n.fns, i.e. .fns=list, etc… I wasn’t really sure what that was achieving within across.\n\nThe across() function lets us apply a function to many columns at once.\nFor example, let’s say we want the mean value for every continuous variable in a dataset.\n\nThe code below calculates the mean for one variable in the penguins dataset using both base R and summarize().\nOne option to calculate the mean value for every continuous variable in the dataset is to repeat this code for the 4 other continuous variables.\n\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(gt)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n  # base R\nmean(penguins$bill_length_mm, na.rm = TRUE)\n\n[1] 43.92193\n\n# with summarize\npenguins %&gt;% \n  summarize(mean(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  `mean(bill_length_mm, na.rm = TRUE)`\n                                 &lt;dbl&gt;\n1                                 43.9\n\n\n\nIn this case across() lets us apply the mean function to all the columns of interest at once:\n\n\npenguins %&gt;%\n  summarize(across(.cols = where(is.numeric), \n                   .fns = ~ mean(.x, na.rm = TRUE)\n                   )) %&gt;% \n  gt()\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\n43.92193\n17.15117\n200.9152\n4201.754\n2008.029\n\n\n\n\n\n\n\n\nThe .fns=list part of the across code is where we specify the function(s) that we want to apply to the specified columns.\n\nAbove we only specified one function (mean()), but we can specify additional functions as well, which is when we need to create a list to list all the functions we want to apply.\nBelow I apply the mean and standard deviation functions:\n\n\n\npenguins %&gt;%\n  summarize(across(.cols = where(is.numeric), \n                   .fns = list(\n                     mean = ~ mean(.x, na.rm = TRUE),\n                     sd = ~ sd(.x, na.rm = TRUE)\n                     ))) %&gt;% \n  gt()\n\n\n\n\n\n\n\nbill_length_mm_mean\nbill_length_mm_sd\nbill_depth_mm_mean\nbill_depth_mm_sd\nflipper_length_mm_mean\nflipper_length_mm_sd\nbody_mass_g_mean\nbody_mass_g_sd\nyear_mean\nyear_sd\n\n\n\n\n43.92193\n5.459584\n17.15117\n1.974793\n200.9152\n14.06171\n4201.754\n801.9545\n2008.029\n0.8183559\n\n\n\n\n\n\n\n\nIn general, lists are another type of R object to store information, whether data, lists of functions, output from regression models, etc. While concatenate is just a vector of values, lists are multidimensional. We will be learning more about lists in parts 7 and 8.\nYou can learn more about across() at its help file."
  },
  {
    "objectID": "weeks/week_06.html#case_when-vs-ifelse",
    "href": "weeks/week_06.html#case_when-vs-ifelse",
    "title": "Week 6",
    "section": "case_when() vs ifelse()",
    "text": "case_when() vs ifelse()\nstill a little confused on the difference between ifelse and casewhen, understand they are very similar but still confused on when it is best to use one over another\n\nThe two functions can be used interchangeably. * ifelse() is the original function from base R\n\ncase_when() is the user-friendly version of ifelse() from the dplyr package\n\nI recommend using case_when(), and it is what I use almost exclusively in my own work. My guess is that ifelse() was included in the notes since you might run into the function when reading R code on the internet.\nJust be careful that you preserve missing values when using case_when() as we discussed last time."
  },
  {
    "objectID": "weeks/week_06.html#factor-levels",
    "href": "weeks/week_06.html#factor-levels",
    "title": "Week 6",
    "section": "factor levels",
    "text": "factor levels\nworking with factor levels doesn’t feel totally intuitive yet. I think that’s because I tend to get confused with anything involving a concatenated list.\n\nWorking with factor variables takes a while to get used to, and in particular with their factor levels.\nWe will be looking at more examples with factor variables in the part 6 notes. See sections 2.8 and 4.\nYou can think of a concatenated list(c(...)) as a vector of values or a column of a dataset. Concatenating lets us create a set of values, which we typically create to use for some other purpose, such as specifying the levels of a factor variable.\nPlease submit a follow-up question in the post-class survey if this is still muddy after today’s class!"
  },
  {
    "objectID": "weeks/week_06.html#pivoting-tables",
    "href": "weeks/week_06.html#pivoting-tables",
    "title": "Week 6",
    "section": "pivoting tables",
    "text": "pivoting tables\n\nDefinitely a tricky topic, and over half of the muddiest points were about pivoting tables.\nWe will be looking at more examples in part 6.\n\n\nHow pivot_longer() would work on very large datasets with many rows/columns\n\nIt works the same way. However the resulting long table will end up being much much longer.\nExtra columns in the dataset just hang out and their values get repeated (such as an age variable that is not being made long by) over and over again.\n\nWe will be pivoting a dataset in part 6 that has extra variables that are not being pivoted.\n\n\n\n\nTrying to visualize the joins and pivot longer/wider\n\nI recommend trying them out with small datasets where you can actually see what is happening.\nJoins: Our BERD workshop slides have another example that might visualize joins.\n\nSlide 18 shows to datasets x and y, and what the resulting joins look like.\nSlide 19 shows Venn diagrams of how the different joins behave.\n\nPivoting: There’s an example with a very small dataset in my (supplemental) notes from BSTA 511. The graphic that goes along with this is on Slide 28 from the pdf.\n\n\n\npivot_longer makes plotting more understandable in an analysis sense, which situations would call for pivot_wider?\n\nI tend to use pivot_longer() much more frequently. However, there are times when pivot_wider() comes in handy. For example, below is a long table of summary statistics created with group_by() and summarize(). I would use pivot_wider() to reshape this table so that I have columns comparing species or columns comparing islands.\n\n\npenguins %&gt;% \n  group_by(species, island) %&gt;%\n  summarize(across(.cols = bill_length_mm, \n                   .fns = list(\n                     mean = ~ mean(.x, na.rm = TRUE),\n                     sd = ~ sd(.x, na.rm = TRUE)\n                     )))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 4\n# Groups:   species [3]\n  species   island    bill_length_mm_mean bill_length_mm_sd\n  &lt;fct&gt;     &lt;fct&gt;                   &lt;dbl&gt;             &lt;dbl&gt;\n1 Adelie    Biscoe                   39.0              2.48\n2 Adelie    Dream                    38.5              2.47\n3 Adelie    Torgersen                39.0              3.03\n4 Chinstrap Dream                    48.8              3.34\n5 Gentoo    Biscoe                   47.5              3.08\n\n\n\n\nHow to use arguments of pivot longer.\n\nThe arguments of the pivot functions take some practice to get used to. I sometimes still pull up an example to remind me what I need to specify for the various arguments, such as the one mentioned above that I have used in workshops and classes.\n\nWe have not covered all the different arguments, and I recommend reviewing the help file and in particular the examples at the end of the page."
  },
  {
    "objectID": "weeks/week_06.html#gtgt",
    "href": "weeks/week_06.html#gtgt",
    "title": "Week 6",
    "section": "gt::gt()",
    "text": "gt::gt()\nThe gt::gt package does make the tables look fancier, how do we add labels to those to have them look nice as well?\n\nI highly recommend the gt webpage to learn more about all the different options to create pretty tables. Note the tabs at the top of the page for “Get started” and “Reference.”\nSee also section 3 of part 6 on “Side note about gt::gt()” for more on creating pretty tables."
  },
  {
    "objectID": "weeks/week_06.html#herehere",
    "href": "weeks/week_06.html#herehere",
    "title": "Week 6",
    "section": "here::here",
    "text": "here::here\nwould also love more examples of here() I am starting to understand it better but still am a little confused\nI am still having trouble getting here() to work consistently. I was going to ask during class, but I think I am just not understanding how to manually nest my files correctly so that “here” works. I am struggling to get that set up correct, and thus, struggling to use it. \n\nWe’ll have some more examples in class, but I recommend reaching out to one of us (instructors or TA) to help you troubleshoot here::here.\nHere are also some resources that might help\n\nhttps://here.r-lib.org/articles/here.html\nhttp://jenrichmond.rbind.io/post/how-to-use-the-here-package/\nhttps://github.com/jennybc/here_here"
  },
  {
    "objectID": "weeks/week_06.html#clearest-points",
    "href": "weeks/week_06.html#clearest-points",
    "title": "Week 6",
    "section": "Clearest points",
    "text": "Clearest points\n\ngroup_by() function (n=3)\nsummarize() (n=2)\nacross() (n=1)\ncase_when() (n=1)\ndrop_na( ) (n=2)\nJoining tables (n=6)"
  },
  {
    "objectID": "weeks/week_03.html",
    "href": "weeks/week_03.html",
    "title": "Week 3",
    "section": "",
    "text": "Where to get help on errors\nRevisiting data loading with the here package\nData manipulation with dplyr package\nThemes in the ggplot2 package\nFactors\nBoxplots and facets"
  },
  {
    "objectID": "weeks/week_03.html#topics",
    "href": "weeks/week_03.html#topics",
    "title": "Week 3",
    "section": "",
    "text": "Where to get help on errors\nRevisiting data loading with the here package\nData manipulation with dplyr package\nThemes in the ggplot2 package\nFactors\nBoxplots and facets"
  },
  {
    "objectID": "weeks/week_03.html#announcements",
    "href": "weeks/week_03.html#announcements",
    "title": "Week 3",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared Dropbox folder BSTA_526_W25_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_03, and then open RStudio by double-clicking on the file called part_03.Rproj.\nIf you have not already done so, please join the BSTA 526 Slack channel and introduce yourself by posting in the #random channel."
  },
  {
    "objectID": "weeks/week_03.html#class-materials",
    "href": "weeks/week_03.html#class-materials",
    "title": "Week 3",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nDropbox part_03 Project folder"
  },
  {
    "objectID": "weeks/week_03.html#post-class-survey",
    "href": "weeks/week_03.html#post-class-survey",
    "title": "Week 3",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_03.html#homework",
    "href": "weeks/week_03.html#homework",
    "title": "Week 3",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment.\nHW 3 due on 1/30."
  },
  {
    "objectID": "weeks/week_03.html#recording",
    "href": "weeks/week_03.html#recording",
    "title": "Week 3",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_03.html#muddiest-points",
    "href": "weeks/week_03.html#muddiest-points",
    "title": "Week 3",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nhere package\nThe here package takes a bit to explaining, but, compared to the old way of doing things, it is a real life saver. The issue in the past had to do with relative file paths, especially with .qmd files that are saved in sub-folders. The .qmd file recognizes where it is saved as the root file path, which is okay with a one-off .qmd file. But when working in projects (recommended) and striving for reproducible R code (highly recommended), the here package save a lot of headache.\nFor further reading: + Why should I use the here package when I’m already using projects? by Malcolm Barrett. + how to use the here package by Jenny Richmond. + here package vignette + Using here with rmarkdown\nProject-oriented workflows are recommended. Here package solves some old headaches. It gets easier with practice.\n\nQuestion about using here\n\n… how [here] can be used in certain instances where one may not remember if they switched to a new qmd file? In that case, would you suggest to use the “here” command each time you work on a project where there’s a chance that you’ll switch between qmd files and would like to use the same data file throughout? Is there any other way to better use this function or tips on how you deal with it?\n\nThere is a difference between working interactively in RStudio where data are loaded to the Environment. In this case, loading a data set once means that it can be used in any other code while working in the environment.\nIssues will com up when you go to render a .qmd that doesn’t have the data loaded within that .qmd. It won’t look to the environment for the data; it looks to the filepath that you specify in the .qmd. Best practice is to write the code to load the data in each .qmd or .R script so that R knows where to look for the data that you want it to operate on / analyze.\n\n\n\nThe ! function. It seems like sometimes we use ! and sometimes we use -. Are they interchangeable, or each with different types of functions?\n\n! – the exclamation point can be read as “not” it is primarily used in logical statements\n- – the minus sign can be used in more instances\n\nto do actual arithmetic (i.e. subtraction)\nto indicate a negative number\nwith dplyr::select() to remove or not select a column, or exclusion\n\n\n\n# Subtraction\n5 - 3\n\n[1] 2\n\n# Negation\nx &lt;- 10\n-x\n\n[1] -10\n\n# Selection/exclusion\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nselect(starwars, -height) |&gt; dplyr::glimpse()\n\nRows: 87\nColumns: 13\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"A New Hope\", \"The Empire Strikes Back\", \"Return of the J…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n\nUsing the fill command\nWe didn’t cover it in the lecture notes, but then it appeared in the example. I suggest to read/work through the fill vignette; the examples there are good ones to show what the function does. Then look back a the smoke_messy data set in Part 3 and think about why this command would be useful to clean up the data and for filling in missing values.\n\n\nLoading data into R\nIt gets easier and hopefully you get to see more example in the notes and practice with the homework. This tutorial is pretty good. So is the readxl vignette and the readr vignette.\n\n\nReasonable width, height, and dpi values when using ggsave\nThis takes some trial and error and depends on the purpose. For draft figures, dpi = 70 might be okay, but a journal might require dpi above 300 for publication. In Quarto, rendering an html, the figure defaults are 7x5 inches (Link). We talked about in class how you can use the plot panes to size your figures by trial and error.\n\n\nThe tidyselect section\nThere were pretty good resources in the notes\n\nSee some more examples in this slide\nFor more info and learning about tidyselect, please run this code in your console:\n\n\n# install remotes package\ninstall.packages(\"remotes\")\n# use remotes to install this package from github\nremotes::install_github(\"laderast/tidyowl\")\n\n# load tidyowl package\nlibrary(tidyowl)\n\n# interactive tutorial\ntidyowl::learn_tidyselect()\n\nHere is also a link with a list of the selectors and links to each one. For example, there is a link to starts_with and a bunch of examples."
  },
  {
    "objectID": "weeks/week_01.html",
    "href": "weeks/week_01.html",
    "title": "Week 1",
    "section": "",
    "text": "Introduction to course/expectations (syllabus)\nIntro to R & RStudio\n\nHandout with directions on installing R & RStudio\n\nIntroduction to Quarto\nFunctions, Vectors, Data Types"
  },
  {
    "objectID": "weeks/week_01.html#topics",
    "href": "weeks/week_01.html#topics",
    "title": "Week 1",
    "section": "",
    "text": "Introduction to course/expectations (syllabus)\nIntro to R & RStudio\n\nHandout with directions on installing R & RStudio\n\nIntroduction to Quarto\nFunctions, Vectors, Data Types"
  },
  {
    "objectID": "weeks/week_01.html#announcements",
    "href": "weeks/week_01.html#announcements",
    "title": "Week 1",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared Dropbox folder BSTA_526_W25_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_01, and then open RStudio by double-clicking on the file called part_01.Rproj.\nPlease join the BSTA 526 Slack channel and introduce yourself by posting in the #random channel."
  },
  {
    "objectID": "weeks/week_01.html#class-materials",
    "href": "weeks/week_01.html#class-materials",
    "title": "Week 1",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nDropbox part_01 Project folder"
  },
  {
    "objectID": "weeks/week_01.html#post-class-survey",
    "href": "weeks/week_01.html#post-class-survey",
    "title": "Week 1",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_01.html#homework",
    "href": "weeks/week_01.html#homework",
    "title": "Week 1",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment.\nHW 1 due on 1/16."
  },
  {
    "objectID": "weeks/week_01.html#recording",
    "href": "weeks/week_01.html#recording",
    "title": "Week 1",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_01.html#muddiest-points",
    "href": "weeks/week_01.html#muddiest-points",
    "title": "Week 1",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nClass logistics\n\nWill there be presentation slides in future classes, or is everything embedded into the quarto/html files for all lectures?\n\nThe material will primarily be in quarto/html files and not slides.\n\nSpecifics of what topics will be covered exactly. * I don’t have a list of all the specific functions we will be covering, but you are welcome to peruse the BSTA 504 webpage from Winter 2023 to get more details on topics we will be covering. We will be closely following the same class materials.\nIdentifying which section of the code we were discussing during the lecture\n\nThanks for letting me know. I will try to be clearer in the future, and also jump around less. Please let me know in class if you’re not sure where we are at.\n\nThe material covered towards the end of the class felt a bit difficult to keep up with. I wish we would have been told to read the materials from Week 1 (or at least skim them) ahead of Day 1, because I quickly lost track of the conversation when shortcuts were used super quickly, for example, or when we jumped from chunks of code to another topic without reflecting on them. I still had 70% of the material down and I wrote great notes during the discussion (which I later filled in with the script that was on the class website), but I think it the beginner/intermediate programming lingo that was used to explain ideas here confused me at times. Thus, I struggled to keep up with discussions around packages / best coding practices, especially when they were not mentioned directly on the script (where I could follow along!).\n\nThanks for the feedback. In future years, we will reach out to students before the term to let them know about the readings to prepare for class. Please let us know if there is lingo we are using that you are not familiar with. Learning R and coding is a whole new language!\n\n\n\n\nRStudio\n\nI have trouble thinking through where things are automatically downloaded, saved, and running from. I can attend office hours for this!\n\nOffice hours are always a great idea. I do recommend paying close attention to where files are being saved when downloading and preferably specifying their location instead using the default location. Having organized files will make working on complex analyses much easier.\n\nHow to read the course material in R. While it made sense in real time it may be difficult when going back over the material.\n\nGetting used to reading code and navigating the rendered html files takes a while, and is a part of learning R. Figuring out how to take notes for yourself that works for you is also a learning curve. I recommend taking notes in the qmd files as we go through them in class. After class you can summarize and transfer key points to other file formats that you are more used to using. I personally have a folder in my Google drive filled with documents on different R programming topics. It started with one file, and then eventually expanded to multiple files on different topics in an attempt to organize my notes better. Whenever I learn something new (such as an R function or handy R package) that I want to keep for future reference, I add to them with links to relevant webpages and/or filenames and locations of where I used them.\n\n\n\n\nCode\n\nWhat does the pacman package do? I have it installed but I’m not sure what it is actually used for.\n\nI didn’t go into pacman in Day 1. The p_load() function from the pacman package (usually run as pacman::p_load()) lets you load many packages at once without separately using the library() function for each individually.\nAn added bonus is that by default it will install packages you don’t already have, unless you specify install = FALSE.\nAnother option is to set update = TRUE so that it will automatically update packages. I do not use this option though since sometimes updating packages causes conflicts with other packages or older code.\nYou can read more about the different options in the documentation. This Medium article also has some tips on using pacman.\n\nThe part on when to load in packages once they’ve already been loaded in - like for example would it be good to put that as a step in our homework 1 .qmd at the top? Or not necessary since they’re already loaded in to R Studio from the work we did in class yesterday? What would happen if we try to load them in and they were already loaded in, would the .qmd file not render and show an error?\n\nI always load my packages at the very top of the .qmd files, usually in the first code chunk (with the setup label). If you still have a previous R session open, then yes you don’t need to load the packages again to run code within RStudio. However, when a file is rendered it starts with an empty workspace, which is why our qmd file must include code that loads the packages (either using library() or pacman::p_load(). We don’t have to load packages at the beginning of the file, just before we have code that depends on the packages being used.\n\nI didn’t understand the part where we talked about num, char, logical combinations (line 503).\n\nThe content of the objects char_logical, num_char, num_logical, and tricky were designed specifically to be confusing and thus make us aware of how R will decide to assign the data type when a vector is a mix of data types. Some key takeaways are below. Let me know if you sitll have questions about this.\n\nNumbers and logical/boolean (TRUE, FALSE) do not have double quotes around them, but character strings do. If you add double quotes to a number or logical, then R will treat it as a character string.\nIf a vector is a mix of numbers and character strings, then the data type of the vector is character.\nIf a vector is a mix of numbers and logical, then the data type of the vector is numeric and the logical value is converted to a numeric value (TRUE=1, FALSE=0).\nIf a vector is a mix of character strings and logical, then the data type of the vector is character and the logical value is converted to a character string and no longer operates as a logical (i.e. no longer equal to 1 or 0).\n\n\nLines 614-619, confused what the ratio means there. Could you go over the correct code (or options of the correct code) for challenge 5?\n\nThe code 1:4 or 6:9 creates sequences of integers starting with the first specified digit and ending at the last specified digit. For example, 1:4 is the vector with the digits 1 2 3 4. You can also create decreasing sequences by making the first number the bigger one. For example, 9:7 is the vector 9 8 7.\nChallenge 5:\n\nmore_heights_complete &lt;- na.omit(more_heights)\nmedian(more_heights_complete)\nYou could also get the median of more_heights without first removing the missing values with median(more_heights, na.rm = TRUE).\n\n\nhow to count the TRUE values in a logical vector\n\nTRUE is equal to 1 in R (and FALSE is equal to 0), and the function sum() adds up the values in a vector. Thus, sum(TRUE, FALSE, TRUE) is equal to 2. Similarly, sum(TRUE, FALSE, 5) is equal to 6.\nThe way I used it in class though is by counting how many values in the vector z (which was 7 9 11 13) are equal to 9. To do that I used the code sum(z == 9). Breaking that down, the code inside the parentheses z == 9 is equal to FALSE TRUE FALSE FALSE since the == means “equals to” in R.\nYou can read up more on boolean and logical operators at the R-bloggers post."
  },
  {
    "objectID": "weeks/week_01.html#clearest-points",
    "href": "weeks/week_01.html#clearest-points",
    "title": "Week 1",
    "section": "Clearest Points",
    "text": "Clearest Points\nThank you for the feedback!\n\nClass logistics\n\nSyllabus/course structure\nThe syllabus review.\nOverall expectations and course flow\nIntroduction to the class (first half of the class); conversation around syllabus; and the Quarto introduction\n\n\n\nQuarto\n\nHow to create and edit a Quarto document in RStudio.\nThe differences between quarto and markdown\nrmarkdown is no more, quarto it is!\n\n\n\nCoding\n\nHaving code missing and fixing it in front of the class was helpful in troubleshooting.\nJust running through all the commands was very clear and easy to follow\nBasic R set up for quarto and introduction to R objects, vectors, etc.\nIntroduction, functions, and explanations was the clearest for me.\nClassification of the objects in logical, character, and numeric\nNot necessarily a point, but I really liked when we were encouraged to use the shortcut keys for various commands on R and other little things like switching code between console vs inline , I have used R before for a class briefly but I never knew all these ways by which I can save time and be efficient while writing a code."
  },
  {
    "objectID": "readings.html",
    "href": "readings.html",
    "title": "Readings",
    "section": "",
    "text": "Links to weekly readings\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n1/9/25\n\n\nWeek 1 Readings\n\n\nIntroduction to R/RStudio/Vectors\n\n\n\n\n1/16/25\n\n\nWeek 2 Readings\n\n\nLoading data, data.frames, and ggplot2\n\n\n\n\n1/23/25\n\n\nWeek 3 Readings\n\n\nggplot2, factors, boxplots, dplyr: subsetting using filter()/select()\n\n\n\n\n1/30/25\n\n\nWeek 4 Readings\n\n\nmutate(), across(), summarize(), group_by(), ggplot: faceting, scales\n\n\n\n\n2/6/25\n\n\nWeek 5 Readings\n\n\njoining multiple tables (left_join() etc), reshaping data (i.e. pivot_longer())\n\n\n\n\n2/13/25\n\n\nWeek 6 Readings\n\n\nMore practice with data wrangling\n\n\n\n\n2/20/25\n\n\nWeek 7 Readings\n\n\nFinish part 6 + part 7 functions and lists\n\n\n\n\n2/27/25\n\n\nWeek 8 Readings\n\n\nLists and Functions\n\n\n\n\n3/6/25\n\n\nWeek 9 Readings\n\n\nIteration (part 8)\n\n\n\n\n3/13/25\n\n\nWeek 10 Readings\n\n\nMore stats, broom, and tables (gt, gtsummary)\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Readings"
    ]
  },
  {
    "objectID": "weeks/week_02.html",
    "href": "weeks/week_02.html",
    "title": "Week 2",
    "section": "",
    "text": "Links to pre-recorded videos are posted on Sakai, in the table with the links to live class recordings."
  },
  {
    "objectID": "weeks/week_02.html#pre-recorded-videos",
    "href": "weeks/week_02.html#pre-recorded-videos",
    "title": "Week 2",
    "section": "",
    "text": "Links to pre-recorded videos are posted on Sakai, in the table with the links to live class recordings."
  },
  {
    "objectID": "weeks/week_02.html#topics",
    "href": "weeks/week_02.html#topics",
    "title": "Week 2",
    "section": "Topics",
    "text": "Topics\n\nProjects\nData frames\nTidy data\nReading in data\nGetting to know a dataset\nVisualizing data with ggplot2 (intro)"
  },
  {
    "objectID": "weeks/week_02.html#announcements",
    "href": "weeks/week_02.html#announcements",
    "title": "Week 2",
    "section": "Announcements",
    "text": "Announcements\n\nClass materials for BSTA 526 will be provided in the shared Dropbox folder BSTA_526_W25_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_02, and then open RStudio by double-clicking on the file called part_02.Rproj.\nIf you have not already done so, please join the BSTA 526 Slack channel and introduce yourself by posting in the #random channel."
  },
  {
    "objectID": "weeks/week_02.html#class-materials",
    "href": "weeks/week_02.html#class-materials",
    "title": "Week 2",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\nDropbox part_02 Project folder"
  },
  {
    "objectID": "weeks/week_02.html#post-class-survey",
    "href": "weeks/week_02.html#post-class-survey",
    "title": "Week 2",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_02.html#homework",
    "href": "weeks/week_02.html#homework",
    "title": "Week 2",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment."
  },
  {
    "objectID": "weeks/week_02.html#recording",
    "href": "weeks/week_02.html#recording",
    "title": "Week 2",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_02.html#muddiest-points",
    "href": "weeks/week_02.html#muddiest-points",
    "title": "Week 2",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nWhen discussing untidy data, the difference between long data and wide data was unclear.\n\nWe’ll be discussing the difference between long and wide data in more detail later in the course when we convert a dataset between the two. For now, you can take a look at an example I created for our BERD R workshops. The wide data in that example are not “tidy” since each cell contains two pieces of information: both the SBP and the visit number. In contrast, the long data have a separate column indicating which visit number the data in a given row are from.\n\nfor the “summary()” function, is there a way to summarize all but one variable in a dataset?\n\nYes! I sometimes restrict a dataset to a couple of variables for which I want to see the summary. I usually use the select() function for this, which we will be covering later in the course. For now, you can take a look at some select() examples from the BERD R workshops (see slides 29-32).\n\nDifferences between a tibble and a data.frame\n\nI’m not surprised to see this show up as a muddiest point! Depending on your level of experience with R, at this point in the class some of the differences are difficult to explain since we haven’t done much coding yet. The tibble vignette lists some of the differences though if you are interested. For our purposes, they are almost the same thing. When some differences come up later in the course, I will point them out."
  },
  {
    "objectID": "weeks/week_02.html#clearest-points",
    "href": "weeks/week_02.html#clearest-points",
    "title": "Week 2",
    "section": "Clearest Points",
    "text": "Clearest Points\nThanks for the feedback!\n\nI enjoyed going through the code and viewing the functions. I haven’t really used skimr before and that was nice to see.\n\nI like using skmir, but have recently been using get_summary_stats() from the rstatix package when teaching. It is only for numeric variables though. See a get_summary_stats() example from my BSTA 511 class.\n\nLoading data.\nHow to load data into R was clearest.\n\nGood to know that loading data was clear. This part can be tricky sometimes!\n\nggplot\n\nHopefully this will still be clear when we cover more advanced options in ggplot!"
  },
  {
    "objectID": "weeks/week_07.html",
    "href": "weeks/week_07.html",
    "title": "Week 7",
    "section": "",
    "text": "If you haven’t already, please sign up for your function of the week presentation.\n\nPlease limit presentations to 3 per week.\nLink to sign-up sheet is posted on Sakai.\n\nThe Midterm is now posted in Dropbox. It is due Sunday 2/23/25.\n\nPlease start early on this since finding a suitable dataset might take some time.\nWe encourage you to meet with either of us to discuss your research question and data to make sure you are on the right track.\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_07.html#announcements",
    "href": "weeks/week_07.html#announcements",
    "title": "Week 7",
    "section": "",
    "text": "If you haven’t already, please sign up for your function of the week presentation.\n\nPlease limit presentations to 3 per week.\nLink to sign-up sheet is posted on Sakai.\n\nThe Midterm is now posted in Dropbox. It is due Sunday 2/23/25.\n\nPlease start early on this since finding a suitable dataset might take some time.\nWe encourage you to meet with either of us to discuss your research question and data to make sure you are on the right track.\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_07.html#topics",
    "href": "weeks/week_07.html#topics",
    "title": "Week 7",
    "section": "Topics",
    "text": "Topics\n\nPart 6 ctd.\n\nPractice working with real data\nPractice joining and pivoting\nPractice ggplot and learn more geometries\nLearn how to deal with missing data"
  },
  {
    "objectID": "weeks/week_07.html#class-materials",
    "href": "weeks/week_07.html#class-materials",
    "title": "Week 7",
    "section": "Class materials",
    "text": "Class materials\n\nWeek 6 Readings\nDropbox part_06 Project folder"
  },
  {
    "objectID": "weeks/week_07.html#post-class-survey",
    "href": "weeks/week_07.html#post-class-survey",
    "title": "Week 7",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_07.html#homework",
    "href": "weeks/week_07.html#homework",
    "title": "Week 7",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder part06 for homework assignment 7."
  },
  {
    "objectID": "weeks/week_07.html#recording",
    "href": "weeks/week_07.html#recording",
    "title": "Week 7",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_07.html#clearest-points",
    "href": "weeks/week_07.html#clearest-points",
    "title": "Week 7",
    "section": "Clearest points",
    "text": "Clearest points\n\nThis class was all really clear. It was helpful to be reviewing some of the things we learned last week.\n\n\nI appreciate the new codes on how to clean/reshape/combine messy data. I think that was the hardest parts to do in the other Biostatistics courses during projects.\n\n\nData cleaning\n\n\nMost of the data cleaning exercises.\n\n\ndifferent strategies to clean data sets\n\n\nThe data cleaning made a lot of sense but I think I will struggle with solving problems in a really inefficient way.\n\n\nEverything before Challenge 3\n\n\nmethods to merge datasets to create a table\n\n\ninner join and full join are the same if all vectors are the same.\n\n\nPivot\n\n\nggplot and how to code data in to display what we want to display"
  },
  {
    "objectID": "weeks/week_07.html#other-comments",
    "href": "weeks/week_07.html#other-comments",
    "title": "Week 7",
    "section": "Other comments",
    "text": "Other comments\n\nIs there a difference between summarize (with z) and summarise (with s)?\n\nGreat question!\n\nIn English, summarize is American English and summarise is British English. * In R they work the same way. The reference page for summarise() lists them as synonyms.\nIn R code I see summarise more, and now keep mixing up which is American and which is British.\nIn general, R accepts both American and British English, such as both color and colour.\n\n\nThank you for the survey reminders! The pace of the class feels much better compared to the pace at the beginning of the term\n\nThanks for the feedback!\n\nI really enjoyed the walk through from start to finish of how to clean the data sheet and it really helped clear up many of the commands I was previously confused about\n\nThanks for the feedback! Glad the data wrangling walk through was helpful."
  },
  {
    "objectID": "weeks/week_10.html",
    "href": "weeks/week_10.html",
    "title": "Week 10",
    "section": "",
    "text": "Please fill out the course evaluations for the class.\n\nCourse evaluations are very helpful for making improvements to our classes.\nIf too few students fill out the evaluations, they are not released to us.\nYou might have two evaluations since there are two instructors.\n\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_10.html#announcements",
    "href": "weeks/week_10.html#announcements",
    "title": "Week 10",
    "section": "",
    "text": "Please fill out the course evaluations for the class.\n\nCourse evaluations are very helpful for making improvements to our classes.\nIf too few students fill out the evaluations, they are not released to us.\nYou might have two evaluations since there are two instructors.\n\n\n\n\n\n\nThis is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_10.html#topics",
    "href": "weeks/week_10.html#topics",
    "title": "Week 10",
    "section": "Topics",
    "text": "Topics\n\nPart 8\n\nIntroduce simple statistical modelling\nLearn about the useful broom package\nMore iteration with purrr\nSlitting up data for iteration\nOther useful purrr"
  },
  {
    "objectID": "weeks/week_10.html#class-materials",
    "href": "weeks/week_10.html#class-materials",
    "title": "Week 10",
    "section": "Class materials",
    "text": "Class materials\nReadings are linked below, and we are using the part_08 material on Dropbox\n\nWeek 10 Readings\nDropbox part_08 Project folder"
  },
  {
    "objectID": "weeks/week_10.html#post-class-survey",
    "href": "weeks/week_10.html#post-class-survey",
    "title": "Week 10",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_10.html#homework",
    "href": "weeks/week_10.html#homework",
    "title": "Week 10",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment."
  },
  {
    "objectID": "weeks/week_10.html#recording",
    "href": "weeks/week_10.html#recording",
    "title": "Week 10",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_10.html#muddiest-points-from-week-10",
    "href": "weeks/week_10.html#muddiest-points-from-week-10",
    "title": "Week 10",
    "section": "Muddiest points from Week 10",
    "text": "Muddiest points from Week 10\n\nSee Week 9 page for Week 9 feedback."
  },
  {
    "objectID": "weeks/week_10.html#confusion-on-details-of-purrrmap",
    "href": "weeks/week_10.html#confusion-on-details-of-purrrmap",
    "title": "Week 10",
    "section": "Confusion on details of purrr::map()",
    "text": "Confusion on details of purrr::map()\npurrr::map() applies a function to each element of a vector or list and returns a new list where each element is the result of applying that function to the corresponding element of the original vector or list.\n\nmap(.x, .f, ..., .progress = FALSE)\n\n\n.x the vector or list that you operate on\n.f the function you want to apply to each element of the input vector or list. This function can be a built-in R function, a user-defined function, or an anonymous function defined on the fly.\n\n\nSimple example\n\nlibrary(tidyverse)\n\n# Example list\nnumbers &lt;- list(1, 2, 3, 4, 5)\nnumbers\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] 5\n\n# Using map to square each element of the list\nsquared_numbers &lt;- purrr::map(.x = numbers, \n                              .f = ~ .x ^ 2)\n\nIn this example: - numbers is a list containing numbers from 1 to 5. - ~ .x ^ 2 is an anonymous function that squares its input. - map() applies this anonymous function to each element of the numbers list, resulting in a new list where each element is the square of the corresponding element in the original list.\nAfter executing this code, the squared_numbers variable will contain the squared values of the original list:\n\nsquared_numbers\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\n\n\n\n\nExample with a list of data frames\nSuppose we have a list of data frames where each data frame represents the sales data for different products. We want to calculate the total sales for each product across all the data frames in the list.\n\n# Sample list of data frames\nsales_data &lt;- list(\n  product1 = data.frame(month = 1:3, sales = c(100, 150, 200)),\n  product2 = data.frame(month = 1:3, sales = c(120, 180, 220)),\n  product3 = data.frame(month = 1:3, sales = c(90, 130, 170))\n)\n\nsales_data\n\n$product1\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n$product2\n  month sales\n1     1   120\n2     2   180\n3     3   220\n\n$product3\n  month sales\n1     1    90\n2     2   130\n3     3   170\n\n\nCreate a function `and apply it to each slot insales_data` list:\n\n# Function to calculate total sales for each data frame\ncalculate_total_sales &lt;- function(df) {\n  total_sales &lt;- sum(df$sales)\n  return(total_sales)\n}\n\n# Applying the function to each data frame in the list\ntotal_sales_per_product &lt;- purrr::map(.x = sales_data, \n                                      .f = calculate_total_sales)\n\nIn this example: - sales_data is a list containing three data frames, each representing the sales data for a different product. - calculate_total_sales() is a function that takes a data frame as input and calculates the total sales for that product. - map() applies the calculate_total_sales() function to each data frame in the sales_data list, resulting in a new list total_sales_per_product, where each element is the total sales for a specific product across all months.\nAfter executing this code, the total_sales_per_product variable will contain the total sales for each product:\n\ntotal_sales_per_product\n\n$product1\n[1] 450\n\n$product2\n[1] 520\n\n$product3\n[1] 390\n\n\nSo, total_sales_per_product is a named list where each element represents the total sales for a specific product across all the data frames in the original list."
  },
  {
    "objectID": "weeks/week_10.html#purrrreduce",
    "href": "weeks/week_10.html#purrrreduce",
    "title": "Week 10",
    "section": "purrr::reduce()",
    "text": "purrr::reduce()\n\nHow does it compare to purrr::map()?\nThe big difference between map() and reduce() has to do with what it returns:\n\nmap() usually returns a list or data structure with the same number as its input; The goal of reduce() is to take a list of items and return a single object.\n\nSee the purrr cheatsheet.\n\n\nSimple example\n\n# Example vector\nnumbers &lt;- c(1, 2, 3, 4, 5)\nnumbers\n\n[1] 1 2 3 4 5\n\n# Using reduce to calculate cumulative sum\ncumulative_sum &lt;- purrr::reduce(.x = numbers, \n                                .f = `+`)\n\nIn this example: - numbers is the vector we want to operate on. - The function + is used as the operation to perform at each step of reduction, which in this case is addition. - reduce() will start by adding the first two elements (1 and 2), then add the result to the third element (3), and so on, until all elements have been processed.\nAfter executing this code, the cumulative_sum variable will contain the cumulative sum of the numbers:\n\ncumulative_sum\n\n[1] 15\n\n\nThe steps are as follows:\n\n(cum_numbers &lt;- numbers[1])\n\n[1] 1\n\n(cum_numbers &lt;- cum_numbers + numbers[2])\n\n[1] 3\n\n(cum_numbers &lt;- cum_numbers + numbers[3])\n\n[1] 6\n\n(cum_numbers &lt;- cum_numbers + numbers[4])\n\n[1] 10\n\n(cum_numbers &lt;- cum_numbers + numbers[5])\n\n[1] 15\n\n\n\n\nWith data frames\nUsing our sales data list from above\n\nsales_data\n\n$product1\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n$product2\n  month sales\n1     1   120\n2     2   180\n3     3   220\n\n$product3\n  month sales\n1     1    90\n2     2   130\n3     3   170\n\n\nWe can combined the data sets in the list with reduce() and bind_rows()\n\n# Using an anonymous function, note bind_rows takes 2 arguments.\ncombined_sales_data &lt;- purrr::reduce(.x = sales_data, \n                                     .f = function(x, y) bind_rows(x, y))\n\n\n# Using a named function\ncombined_sales_data &lt;- purrr::reduce(.x = sales_data, \n                                     .f = dplyr::bind_rows)\n\nIn this example: - We use an anonymous function within reduce() that takes two arguments x and y, representing the accumulated result and the next element in the list, respectively. - Inside the anonymous function, we use bind_rows() to combine the accumulated result x with the next element y, effectively stacking them on top of each other. - reduce() applies this anonymous function iteratively to the list of data frames, resulting in a single data frame combined_sales_data that contains the combined sales data for all products.\n\ncombined_sales_data\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n7     1    90\n8     2   130\n9     3   170\n\n\nDoing this in steps:\n\n(cum_sales_data &lt;- dplyr::bind_rows(sales_data[[1]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n(cum_sales_data &lt;- dplyr::bind_rows(cum_sales_data, \n                                    sales_data[[2]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n\n(cum_sales_data &lt;- dplyr::bind_rows(cum_sales_data, \n                                    sales_data[[3]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n7     1    90\n8     2   130\n9     3   170\n\n\n\n\nExamples of reduce\n\nPretty involved example from Maelle Salmon, but good practice\nTidyverse reference with examples\nR for Data Science, First Edition\nAnother exmple blog post"
  },
  {
    "objectID": "weeks/week_10.html#list.files-function",
    "href": "weeks/week_10.html#list.files-function",
    "title": "Week 10",
    "section": "List.files function",
    "text": "List.files function\nthe list.files() function is used to obtain a character vector of file names in a specified directory. Here’s a breakdown of how it works and its common parameters:\n\nDirectory Path: The primary argument of list.files() is the path to the directory you want to list files from. If not specified, it defaults to the current working directory.\nPattern Matching: pattern is an optional argument that allows you to specify a pattern for file names. Only file names matching this pattern will be returned. This can be useful for filtering specific types of files.\nRecursive Listing: If recursive = TRUE, the function will list files recursively, i.e., it will include files from subdirectories as well. By default, recursive is set to FALSE.\nFile Type: The full.names argument controls whether the returned file names should include the full path (if TRUE) or just the file names (if FALSE, the default).\nCharacter Encoding: You can specify the encoding argument to handle file names with non-ASCII characters. This argument is especially useful on Windows systems where file names may use a different character encoding.\n\nHere’s a simple example demonstrating the basic usage of list.files():\n\n# List files in the current directory\nfiles &lt;- list.files()\n\n# Print the file names\nprint(files)\n\n [1] \"_extensions\"                        \"_quarto.yml\"                       \n [3] \"about.qmd\"                          \"BSTA_526_W25.Rproj\"                \n [5] \"data\"                               \"docs\"                              \n [7] \"function_week.qmd\"                  \"images\"                            \n [9] \"index.qmd\"                          \"minty_adapt.scss\"                  \n[11] \"readings\"                           \"readings.qmd\"                      \n[13] \"resources\"                          \"schedule.qmd\"                      \n[15] \"styles.css\"                         \"survey_feedback_previous_years.qmd\"\n[17] \"syllabus.qmd\"                       \"weeks\"                             \n[19] \"weeks.qmd\"                         \n\n\nThis will print the names of all files in the current working directory.\n\n#| eval: false\n\n# List CSV files in a specific directory\ncsv_files &lt;- list.files(path = \"path/to/directory\", pattern = \"\\\\.csv$\")\n\n# Print the CSV file names\nprint(csv_files)\n\ncharacter(0)\n\n\nThis will print the names of all CSV files in the specified directory.\nOverall, list.files() is a handy function for obtaining file names within a directory, providing flexibility through various parameters for customization according to specific needs, such as filtering by pattern or handling file names with non-standard characters.\nNOTE You need to pay attention to your working directory and your relative file paths. See Week 2 or 3 (?) about here package and the discussion about files paths. Best to always use Rprojects and the here package."
  },
  {
    "objectID": "weeks/week_05.html",
    "href": "weeks/week_05.html",
    "title": "Week 5",
    "section": "",
    "text": "Practice using here() to load data in a subfolder of the project\nLearn and apply bind_rows() to combine rows from two or more datasets\nPractice working with and cleaning real data using forcats, stringr, separate()\nLearn about the different kinds of joins and how they merge data\n\nApply inner_join() and left_join() to join tables on columns\n\nWill cover Week 6: Utilize pivot_longer() to make a wide dataset long"
  },
  {
    "objectID": "weeks/week_05.html#post-class-updates",
    "href": "weeks/week_05.html#post-class-updates",
    "title": "Week 5",
    "section": "",
    "text": "Updates made on 2/9/24\n\nHW 5: see the updated HW 5 assignment on OneDrive called hw_05_b526_v2.qmd\nMidterm: due date extended to 2/25/24.\n\nSee the updated midterm file on OneDrive with new yaml, due date, and links to previous midterm projects.\n\nMaterial covered in class on 2/7/24\n\nPart 5 Sections 1-4.4\nSolutions to Challenge 1 from section 4.3 of the Part 5 notes are in OneDrive (Challenge_1_solutions_Part5.html)"
  },
  {
    "objectID": "weeks/week_05.html#topics",
    "href": "weeks/week_05.html#topics",
    "title": "Week 5",
    "section": "",
    "text": "Practice using here() to load data in a subfolder of the project\nLearn and apply bind_rows() to combine rows from two or more datasets\nPractice working with and cleaning real data using forcats, stringr, separate()\nLearn about the different kinds of joins and how they merge data\n\nApply inner_join() and left_join() to join tables on columns\n\nWill cover Week 6: Utilize pivot_longer() to make a wide dataset long"
  },
  {
    "objectID": "weeks/week_05.html#announcements",
    "href": "weeks/week_05.html#announcements",
    "title": "Week 5",
    "section": "Announcements",
    "text": "Announcements\n\nIf you haven’t already, please sign up for your function of the week presentation.\n\nPlease limit presentations to 3 per week.\nLink to sign-up sheet is posted on Sakai.\n\nThe Midterm is now posted in Dropbox. It is due Sunday 2/23/25.\n\nPlease start early on this since finding a suitable dataset might take some time.\nWe encourage you to meet with either of us to discuss your research question and data to make sure you are on the right track.\n\nClass materials for BSTA 526 will be provided in the shared Dropbox folder BSTA_526_W25_class_materials_public.\nFor today’s class, make sure to download to your computer the folder called part_05, and then open RStudio by double-clicking on the file called part_05.Rproj."
  },
  {
    "objectID": "weeks/week_05.html#class-materials",
    "href": "weeks/week_05.html#class-materials",
    "title": "Week 5",
    "section": "Class materials",
    "text": "Class materials\n\nReadings\n\nNote: I updated the Week 4 Readings to include topics that we had moved from part 5 to 4 this year.\n\nDropbox part_05 Project folder\n\nWe got through Section 12 of the html file (joining data) and will cover Section 13 (Reshaping data) during Week 6."
  },
  {
    "objectID": "weeks/week_05.html#post-class-survey",
    "href": "weeks/week_05.html#post-class-survey",
    "title": "Week 5",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_05.html#homework",
    "href": "weeks/week_05.html#homework",
    "title": "Week 5",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox part 5 folder for homework assignment.\n\nHW 5 was updated after class to remove questions 4 & 5, which will be on HW 6 instead. Make sure to use the file hw_05_b526_v2.qmd on Dropbox.\n\nHW 5 due on 2/13."
  },
  {
    "objectID": "weeks/week_05.html#recording",
    "href": "weeks/week_05.html#recording",
    "title": "Week 5",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_05.html#case_when-vs-ifelse",
    "href": "weeks/week_05.html#case_when-vs-ifelse",
    "title": "Week 5",
    "section": "case_when() vs ifelse()",
    "text": "case_when() vs ifelse()\nThe difference between case_when and ifelse\n\nifelse() is the base R version of tidyverse’s case_when()\nI prefer using case_when() since it’s easier to follow the logic.\ncase_when() is especially useful when there are more than two logical conditions being used.\n\nThe example below creates a binary variable for bill length (long vs not long) using both case_when() and ifelse() as a comparison.\n\nCompare the crosstabs of the two variables!\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(palmerpenguins)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill1 = case_when(\n      bill_length_mm &gt;= 45 ~ \"long\",\n      bill_length_mm &lt; 45 ~ \"not long\",\n    ),\n    long_bill2 = ifelse(bill_length_mm &gt;= 45, \"long\", \"not long\")\n  )\n\npenguins %&gt;% tabyl(long_bill1, long_bill2) %&gt;% \n  adorn_title()\n\n            long_bill2             \n long_bill1       long not long NA_\n       long        166        0   0\n   not long          0      176   0\n       &lt;NA&gt;          0        0   2\n\n\nBelow is an example using case_when() to create a categorical variable with 3 groups:\n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill3 = case_when(\n      bill_length_mm &gt;= 50 ~ \"long\",\n      bill_length_mm &lt;= 40 ~ \"short\",\n      TRUE ~ \"medium\"\n    ))\n\npenguins %&gt;% tabyl(long_bill3, long_bill1) %&gt;% \n  adorn_title()\n\n            long_bill1             \n long_bill3       long not long NA_\n       long         57        0   0\n     medium        109       76   2\n      short          0      100   0\n\n\n\nCreating a categorical variable with 3 groups can be done with ifelse(), but it’s harder to follow the logic:\n\n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill4 = ifelse(\n      bill_length_mm &gt;= 50, \"long\",\n      ifelse(bill_length_mm &lt;= 40, \"short\", \"medium\")\n      ))\n\npenguins %&gt;% tabyl(long_bill3, long_bill4) %&gt;% \n  adorn_title()\n\n            long_bill4                 \n long_bill3       long medium short NA_\n       long         57      0     0   0\n     medium          0    185     0   2\n      short          0      0   100   0"
  },
  {
    "objectID": "weeks/week_05.html#separate",
    "href": "weeks/week_05.html#separate",
    "title": "Week 5",
    "section": "separate()",
    "text": "separate()\nDifferent ways of using the function separate, it was a bit unclear that when to use one or the other or examples of my research data where it’ll be most relevant to use.\n\nChoosing the “best” way of using separate() is overwhelming at first.\nI recommend starting with the simplest use case with a string being specified in sep = \" \":\n\n\nseparate(data, col, into, sep = \" \")\n\n\nWhich of the various versions we showed to use depends on how the data being separated are structured.\nMost of the time I have a simple character, such as a space (sep = \" \") or a comma (sep = \",\") that I want to separate by.\nIf the data are structured in a more complex way, then one of the stringr package options might come in handy."
  },
  {
    "objectID": "weeks/week_05.html#herehere",
    "href": "weeks/week_05.html#herehere",
    "title": "Week 5",
    "section": "here::here()",
    "text": "here::here()\nTSV files, very neat… But also, I got a bit confused when you did the render process around 22:00-23:00 minutes. Also, “here: and also”here” Directories/root directories. I was a bit confused about in what situations we would tangibly utilize this/if it is beneficial.\n\nGreat question! This is definitely not intuitive, which is why I wanted to demonstrate it in class.\nThe key is that\n\nwhen rendering a qmd file the current working directory is the folder the file is sitting in,\nwhile when running code in a file within RStudio the working directory is the folder where the .Rproj file is located.\n\n\nThis distinction is important when loading other files from our computer during our workflow, and why here::here() makes our workflow so much easier!"
  },
  {
    "objectID": "weeks/week_05.html#what-functions-will-only-work-within-another-function-generally",
    "href": "weeks/week_05.html#what-functions-will-only-work-within-another-function-generally",
    "title": "Week 5",
    "section": "what functions will only work within another function (generally)",
    "text": "what functions will only work within another function (generally)\n\nI’m not aware of functions that only work standalone within other functions. For example, the mean() function works on its own, but can also be used within a summarise().\n\n\nmean(penguins$bill_length_mm, na.rm = TRUE)\n\n[1] 43.92193\n\npenguins %&gt;% summarise(\n  m = mean(bill_length_mm, na.rm = TRUE)\n)\n\n# A tibble: 1 × 1\n      m\n  &lt;dbl&gt;\n1  43.9\n\n\n\nThat being said, a function has a set of parameters to be specified that are specific to that function."
  },
  {
    "objectID": "weeks/week_08.html",
    "href": "weeks/week_08.html",
    "title": "Week 8",
    "section": "",
    "text": "Writing functions\nlists()"
  },
  {
    "objectID": "weeks/week_08.html#announcements",
    "href": "weeks/week_08.html#announcements",
    "title": "Week 8",
    "section": "",
    "text": "This is a reminder that 5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by 8 pm on Sunday evenings to guarantee that they will be counted. We usually download them some time on Sunday evening or Monday. If you turn it in before we download the responses, it will get counted.\n\nSee syllabus section on Post-class surveys"
  },
  {
    "objectID": "weeks/week_08.html#topics",
    "href": "weeks/week_08.html#topics",
    "title": "Week 8",
    "section": "",
    "text": "Writing functions\nlists()"
  },
  {
    "objectID": "weeks/week_08.html#class-materials",
    "href": "weeks/week_08.html#class-materials",
    "title": "Week 8",
    "section": "Class materials",
    "text": "Class materials\n\nWeek 7 Readings\nWeek 8 Readings\nDropbox part_07 Project folder"
  },
  {
    "objectID": "weeks/week_08.html#post-class-survey",
    "href": "weeks/week_08.html#post-class-survey",
    "title": "Week 8",
    "section": "Post-class survey",
    "text": "Post-class survey\n\nPlease fill out the post-class survey to provide feedback. Thank you!\nPrevious muddiest points and clearest points with responses are collected here: https://niederhausen.github.io/BSTA_526_W25/survey_feedback_previous_years"
  },
  {
    "objectID": "weeks/week_08.html#homework",
    "href": "weeks/week_08.html#homework",
    "title": "Week 8",
    "section": "Homework",
    "text": "Homework\n\nSee Dropbox folder for homework assignment."
  },
  {
    "objectID": "weeks/week_08.html#recording",
    "href": "weeks/week_08.html#recording",
    "title": "Week 8",
    "section": "Recording",
    "text": "Recording\n\nIn-class recording links are on Sakai. Navigate to Course Materials -&gt; Schedule with links to in-class recordings. Note that the password to the recordings is at the top of the page."
  },
  {
    "objectID": "weeks/week_08.html#muddiest-points-from-week-8",
    "href": "weeks/week_08.html#muddiest-points-from-week-8",
    "title": "Week 8",
    "section": "Muddiest points from Week 8",
    "text": "Muddiest points from Week 8\n\nSee Week 7 page for Week 7 feedback.\n\n\nWhen loading a dataset, what does  mean?\nThis occurs when you use the data() function to load a data set from a package. Per the help on this function (?data):\n\ndata() was originally intended to allow users to load datasets from packages for use in their examples, and as such it loaded the datasets into the workspace .GlobalEnv. This avoided having large datasets in memory when not in use: that need has been almost entirely superseded by lazy-loading of datasets.\n\n\ndata(\"iris\")  # this doesn't actually load the data set, but makes it available for use\nhead(iris)    # Once it's used it will appear in the Environment as an object.\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\n\nChallenge # 2\nThis was where we created a function to load 3 data sets, clean them, and convert them to long format. These are tasks we’ve seen in previous classes. In this challenge, the main takeaway was to see the DRY (Don’t repeat yourself) concept at play. Instead of writing the code 3 times for each data set, we can create a function where we only write the cleaning code once, then use that function 3 times.\nReviewing the challenge solutions and taking more time to work through it on your own is a good idea. We went through it pretty quick in class. You won’t usually be limited on time to get a function like that to work. In practice, if it’s taking more time and too complicated, then it’s fine to duplicate code so that you know it’s working correctly. But, with very repetitive tasks, functions can make your code less prone to errors from copying and pasting.\nIf you have trouble getting your code to work for the challenges, office hours are great for helping to debug code. Else, sharing full code in an email or on Slack.\n\n\npurrr::pluck\nThere was a specific question:\n\npurrr::pluck seems really useful, I wonder if you can tell it to pluck a specific record_ID?\n\nThe short answer is no. Not a specific ID. But if you know the position of the specific ID then you could.\n\n# Load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Create sample data\ndf &lt;- tibble::tibble(\n  id = c(\"0001\", \"0002\", \"0003\", \"0004\", \"0005\", \"0006\", \"0007\", \"0008\", \"0009\", \"0010\"), \n  sex = sample(x = c(\"M\", \"F\"), size = 10, replace = TRUE), \n  age = sample(x = 18:65, size = 10, replace = TRUE)\n  \n)\n\ndf\n\n# A tibble: 10 × 3\n   id    sex     age\n   &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n 1 0001  F        41\n 2 0002  M        61\n 3 0003  M        43\n 4 0004  F        60\n 5 0005  F        63\n 6 0006  M        61\n 7 0007  F        29\n 8 0008  M        52\n 9 0009  F        65\n10 0010  M        25\n\n# Say we want to extract ID 0003.\n\n# With purrr::pluck we need to know that it's in the 3rd row of the ID column\n\npurrr::pluck(df, \n             \"id\", \n             3)\n\n[1] \"0003\"\n\n# Gives an error\npurrr::pluck(df, \n             \"id\", \n             \"0003\")\n\nNULL\n\n# More than likely in this scenario, you would use a filter:\ndf |&gt; \n  dplyr::filter(id == \"0003\")\n\n# A tibble: 1 × 3\n  id    sex     age\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 0003  M        43\n\n\npurrr::pluck was created to work with deeply nested data structures. Not necessarily data frames; there’s probably a more appropriate function out there for the task.\n\n\nLists – general confusion\n\nWhat do we do with lists?\nUsing lists\n\nWe will get to work more with lists in Week 9 and get more opportunities to see how they are used.\nLists are more flexible and have the ability to handle various data structures which make them a powerful tool for organizing, manipulating, and representing complex data in R.\n\n\nLists – One bracket versus two brackets.\nOne bracket [ ] and two brackets [[ ]] serves different purposes, primarily when accessing elements in a data structure like vectors, lists, or data frames.\n\nOne Bracket [ ]:\n\nVectors:\nWhen used with a single bracket, you can use it to subset or extract elements from a vector.\n\n# Example with a vector\nmy_vector &lt;- c(1, 2, 3, 4, 5)\nmy_vector[3]  # Extracts the element at index 3\n\n[1] 3\n\n\n\n\nData Frames:\nWhen used with a data frame, it can be used to extract columns or rows.\n\n# Example with a data frame\n\ndf &lt;- tibble::tibble(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"), \n  age = c(25, 30, 22)\n  )\n\n# Extract the age column\ndf[\"age\"]\n\n# A tibble: 3 × 1\n    age\n  &lt;dbl&gt;\n1    25\n2    30\n3    22\n\n\n\n\n\nTwo Brackets [[ ]]:\n\nLists:\nWhen working with lists, double brackets are used to extract elements from the list. The result is the actual element, not a list containing the element.\n\n# Example with a list\nmy_list &lt;- list(1, \n                c(2, 3), \n                \"four\")\n\nmy_list[[2]]  # Extracts the second element (a vector) from the list\n\n[1] 2 3\n\n\nCompare to using []\n\nmy_list[2]\n\n[[1]]\n[1] 2 3\n\n\n[[]] returned the vector contained in that slot. [] returned a list containing the vector.\n\n\nNested Data Structures:\nFor accessing elements in nested data structures like lists within lists.\n\n# Example with a nested list\nnested_list &lt;- list(first = list(a = 1, b = 2), \n                    second = list(c = 3, d = 4))\n\nnested_list\n\n$first\n$first$a\n[1] 1\n\n$first$b\n[1] 2\n\n\n$second\n$second$c\n[1] 3\n\n$second$d\n[1] 4\n\nnested_list[[1]] # Extract the list contained in the first slot\n\n$a\n[1] 1\n\n$b\n[1] 2\n\nnested_list[[1]][[\"b\"]]  # Extracts the value associated with \"b\" in the first list\n\n[1] 2\n\n\nIn summary, one bracket [ ] is used for general subsetting, whether it’s extracting elements from vectors, columns from data frames, or specific elements from lists. On the other hand, two brackets [[ ]] are specifically used for extracting elements from lists and accessing elements in nested structures.\n\n\n\n\nHow and when to use curly curly within a function\n{ } will be covered in upcoming class lectures. We talked about it in Week 8 as a quick aside because a specific question came up. Not much detail was given intentionally as it is a separate topic for another day."
  },
  {
    "objectID": "function_week.html",
    "href": "function_week.html",
    "title": "Functions of the Week",
    "section": "",
    "text": "Links to function of the week presentations\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n1/13/21\n\n\ndplyr::slice\n\n\nSelect rows of dataset using row number\n\n\n\n\n1/25/25\n\n\nggplot2::geom_rug()\n\n\nBuild rug plots in ggplot()\n\n\n\n\n1/30/25\n\n\nggridges::geom_density_ridges\n\n\nOverlays several density plots and fills in the area under the curve.\n\n\n\n\n2/6/25\n\n\nforcats::fct_collapse\n\n\nCollapse factor levels into manually defined groups\n\n\n\n\n2/11/25\n\n\ndplyr::between()\n\n\nDetect where values fall in a specified range\n\n\n\n\n2/13/25\n\n\nggplot2::geom_errorbar()\n\n\nAdding error bars to plots\n\n\n\n\n2/19/25\n\n\ndplyr::na_if\n\n\n\n\n\n\n\n3/6/25\n\n\nggplot2::coord_cartesian\n\n\n\n\n\n\n\n3/6/25\n\n\nggplot2::geom_tile\n\n\n\n\n\n\n\n3/6/25\n\n\ndplyr::slice_max, slice_min\n\n\nTwo of several different slice functions, all of which allow you to select specific rows in order to view, delete, mutate, or otherwise interact with them\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Assistant Professor of Biostatistics in the OHSU-PSU School of Public Health\nFaculty Biostatistician for OHSU’s Biostatistics & Design Program\nAffiliate Investigator for the HSR&D Center to Improve Veteran Involvement in Care (CIVIC) at the Portland VA\n\n\n\n\n\nAssociate Professor of Biostatistics\nFaculty Biostatistician in the Biostatistics Shared Resource of OHSU’s Knight Cancer Institute.\njessicaminnier.com"
  },
  {
    "objectID": "about.html#instructors",
    "href": "about.html#instructors",
    "title": "About",
    "section": "",
    "text": "Assistant Professor of Biostatistics in the OHSU-PSU School of Public Health\nFaculty Biostatistician for OHSU’s Biostatistics & Design Program\nAffiliate Investigator for the HSR&D Center to Improve Veteran Involvement in Care (CIVIC) at the Portland VA\n\n\n\n\n\nAssociate Professor of Biostatistics\nFaculty Biostatistician in the Biostatistics Shared Resource of OHSU’s Knight Cancer Institute.\njessicaminnier.com"
  },
  {
    "objectID": "about.html#course-info",
    "href": "about.html#course-info",
    "title": "About",
    "section": "Course info",
    "text": "Course info\nThis webpage was created for BSTA 526 (R Programming for Health Data Science) in the OHSU-PSU School of Public Health."
  },
  {
    "objectID": "about.html#acknowledgements",
    "href": "about.html#acknowledgements",
    "title": "About",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\nBSTA 526 class materials\n\nBSTA 526 was taught in previous years as BSTA 504 by Ted Laderas (2021) and Jessica Minnier (2022, 2023).\nAlmost all course materials were created by Ted and Jessica with minor changes for BSTA 526 (such as updating from RMarkdown to Quarto). Their work is licensed under a Creative Commons Attribution 4.0 International License. See previous class websites linked to above for links to their source code on GitHub.\n\nIn 2024, Meike Niederhausen and Emile Latour taught the first BSTA 526 using these materials, https://niederhausen.github.io/BSTA_526_W24/\n\n\nQuarto webpage\n\nThank you to Nicky Wakim for creating her amazing webpage for BSTA 550, and sharing her code on GitHub. Having her template made creating this website a much smoother process.\nThank you also to Andrew Bray for presenting the From R Markdown to Quarto ASA Travelling Workshop to the Oregon Chapter of the ASA in June 2023. This workshop was a great starting point in making the switch from RMarkdown to Quarto and also create Quarto webpages."
  },
  {
    "objectID": "readings/01-reading.html",
    "href": "readings/01-reading.html",
    "title": "Week 1 Readings",
    "section": "",
    "text": "Remember, this reading is mostly supplemental and will help you if there are concepts that are unclear in class.\n\nR and RStudio Basics (Chapter 3) - make sure to watch the videos.\n\nSkip the following sections in Chapter 3:\n\n3.3.1, 3.3.3,\n\n\nIntro to R & Rstudio, and Quarto from Day 1 of BSTA 511/611 in Fall 2023 (taught by Meike Niederhausen)\nVectors and Data Frames (Section 3.3)\nWorkflow: scripts and projects\n\nSection 6.1: Scripts\nSection 6.2: Projects"
  },
  {
    "objectID": "readings/01-reading.html#required",
    "href": "readings/01-reading.html#required",
    "title": "Week 1 Readings",
    "section": "",
    "text": "Remember, this reading is mostly supplemental and will help you if there are concepts that are unclear in class.\n\nR and RStudio Basics (Chapter 3) - make sure to watch the videos.\n\nSkip the following sections in Chapter 3:\n\n3.3.1, 3.3.3,\n\n\nIntro to R & Rstudio, and Quarto from Day 1 of BSTA 511/611 in Fall 2023 (taught by Meike Niederhausen)\nVectors and Data Frames (Section 3.3)\nWorkflow: scripts and projects\n\nSection 6.1: Scripts\nSection 6.2: Projects"
  },
  {
    "objectID": "readings/01-reading.html#optional",
    "href": "readings/01-reading.html#optional",
    "title": "Week 1 Readings",
    "section": "Optional",
    "text": "Optional\n\nPosit/R Cheatsheets\n\nMany useful information and tips can be found in the list of cheatsheets on the Posit website\n\n\n\nMarkdown Basics\n\nThis is a short reference on how to do formatting in Markdown. This is optional, but may be a helpful reference as you continue on and work with Markdown and Quarto.\n\nhttps://sph-r-programming-2023.netlify.app/reference/markdown.html\nMost of these topics are covered above in the Day 1 notes of BSTA 511/611.\nSkip the last two sections on Front matter and Citations, since these are different for Quarto.\n\nA similar resource for Quarto specifically\nQuarto YAML for html\nQuarto front matter\n\n\n\n\n\nSwirl Basics\nI’m going to highlight another resource for learning basic R concepts: swirl. This is a software package for R.\nTo start it, run the following code in the console in RStudio Cloud:\n\nlibrary(swirl)\nswirl()\n\nYou’ll want to take a look at the R Programming course, especially the following sections:\n\nBasic Building Blocks\nSequences of Numbers\nVectors\nMissing values"
  },
  {
    "objectID": "readings/04-reading.html",
    "href": "readings/04-reading.html",
    "title": "Week 4 Readings",
    "section": "",
    "text": "Data Transformation (3.1-3.3) from R for Data Science\ngroup_by() Data Transformation (3.5-3.6) from R for Data Science (2e)\n\nThe 1st edition’s Section 5.6 on Grouped summaries with summarise() is more detailed (wordier) and worth looking at as well.\nThe 1st edition also has Section 5.7 on Grouped mutates (and filters) that I did not see in the 2nd edition. Please let me know if you find this content in the 2nd edition!\n\nAggregating data with summarize and map - we will cover map() and rowwise() later, but summarize and mutate with across are described here. You may want to re-visit this when we get to purrr.\nggplot2: Elegant Graphics for Data Analysis, Scales & Guides\nR for Data Science: Factors - we will continue to work with factors in the next few classes with forcats examples like provided here."
  },
  {
    "objectID": "readings/04-reading.html#required",
    "href": "readings/04-reading.html#required",
    "title": "Week 4 Readings",
    "section": "",
    "text": "Data Transformation (3.1-3.3) from R for Data Science\ngroup_by() Data Transformation (3.5-3.6) from R for Data Science (2e)\n\nThe 1st edition’s Section 5.6 on Grouped summaries with summarise() is more detailed (wordier) and worth looking at as well.\nThe 1st edition also has Section 5.7 on Grouped mutates (and filters) that I did not see in the 2nd edition. Please let me know if you find this content in the 2nd edition!\n\nAggregating data with summarize and map - we will cover map() and rowwise() later, but summarize and mutate with across are described here. You may want to re-visit this when we get to purrr.\nggplot2: Elegant Graphics for Data Analysis, Scales & Guides\nR for Data Science: Factors - we will continue to work with factors in the next few classes with forcats examples like provided here."
  },
  {
    "objectID": "readings/04-reading.html#optional",
    "href": "readings/04-reading.html#optional",
    "title": "Week 4 Readings",
    "section": "Optional",
    "text": "Optional\n\nTidyverse style guide\nAdvanced R: style guide\nacross(): This column-wise operations vignette will be useful for the next couple classes."
  },
  {
    "objectID": "readings/02-reading.html",
    "href": "readings/02-reading.html",
    "title": "Week 2 Readings",
    "section": "",
    "text": "Data Organization in Spreadsheets by Kara Woo and Karl Broman - if there is one paper that I think is useful for everyone, it’s this one.\nAbsolute and Relative File Paths - sometimes understanding file paths can be difficult. This is a great follow up reading. The video is very helpful as well.\nWhat are R packages?"
  },
  {
    "objectID": "readings/02-reading.html#required",
    "href": "readings/02-reading.html#required",
    "title": "Week 2 Readings",
    "section": "",
    "text": "Data Organization in Spreadsheets by Kara Woo and Karl Broman - if there is one paper that I think is useful for everyone, it’s this one.\nAbsolute and Relative File Paths - sometimes understanding file paths can be difficult. This is a great follow up reading. The video is very helpful as well.\nWhat are R packages?"
  },
  {
    "objectID": "readings/02-reading.html#optional-meikes-suggestions-for-bsta-526-w24",
    "href": "readings/02-reading.html#optional-meikes-suggestions-for-bsta-526-w24",
    "title": "Week 2 Readings",
    "section": "Optional (Meike’s suggestions for BSTA 526 W24)",
    "text": "Optional (Meike’s suggestions for BSTA 526 W24)\n\nProjects in RStudio resources list Meike created for BSTA 511.\nExploring missing values in naniar . The notes for week 2 refer to the visdat package for visualizing missing values in your data. I also recommend the naniar package, and the link above is a great tutorial with an introduction to some really useful visualizations for missingness."
  },
  {
    "objectID": "readings/10-reading.html",
    "href": "readings/10-reading.html",
    "title": "Week 10 Readings",
    "section": "",
    "text": "Introduction to map() - Jenny Bryan\nPurrr Tips and Tricks by Emil Hvitfeldt.\nIntroduction to broom"
  },
  {
    "objectID": "readings/10-reading.html#required",
    "href": "readings/10-reading.html#required",
    "title": "Week 10 Readings",
    "section": "",
    "text": "Introduction to map() - Jenny Bryan\nPurrr Tips and Tricks by Emil Hvitfeldt.\nIntroduction to broom"
  },
  {
    "objectID": "readings/10-reading.html#suggested",
    "href": "readings/10-reading.html#suggested",
    "title": "Week 10 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nMore on using map and nested data with modeling: R for Data Science: Many Models, First edition\nbroom and dplyr\nJoy of Functional programming talk by Hadley Wickham - more on nesting/iteration\n\nFor learning more about statistics with R:\n\nModern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.com/v2/\nDanielle Navarro’s Learning Statistics with R is excellent and talks much more about statistics: https://learningstatisticswithr.com/\nModel Basics from R for Data Science\nMore on survival analysis in R\n\nSurvival Analysis in R Tutorial by Dr. Emily C Zabor\nSurvminer survival plot vignette\nUVA’s Survival Workshop materials\nRview’s Survival Analysis\n\nProgramming with dplyr - in case I can’t get to tidyeval use for functions with tidyverse\nggplot2 in packages - examples how to use ggplot inside functions\nResources for learning more statistics:\n\nModern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.com/v2/\nDanielle Navarro’s Learning Statistics with R is excellent and talks much more about statistics: https://learningstatisticswithr.com/\n\nMore on using map and nested data with modeling: R for Data Science: Many Models\nbroom and dplyr\nUseful vignettes on table output: gtsummary intro to tbl_summary\nTed Laderas’s interactive workbook on learning rowwise and nested data: learning rowwise\nWe might not get to dates but in case you want to learn more: Dates and times in R for Data Science\nIf you want to learn about tidymodels: Introduction to Machine Learning with the Tidyverse\nJoy of Functional programming talk by Hadley Wickham - more on nesting/iteration\nMore on model building and machine learning\n\nModel Building from R for Data Science\nMany Models - from R for Data science. Covers group_by()/nest() and list-columns\nTidymodels with R: Recipes\nTidymodels with R: Fitting Models with Parsnip\nTidymodels with R: Judging Model Effectiveness\nUMAP and Cocktail Recipes\nTidymodels: K-means\nPCA and Penguins"
  },
  {
    "objectID": "readings/03-reading.html",
    "href": "readings/03-reading.html",
    "title": "Week 3 Readings",
    "section": "",
    "text": "ggplot2 BERD workshop slides - lots more on different geoms and how to customize plots\n\n\n\n\n\ndplyr cheatsheet - one of the best references.\nCombining functions using the pipe operator, |&gt; which is mostly equivalent to %&gt;%; if you’re confused about |&gt; or %&gt;%, please read this."
  },
  {
    "objectID": "readings/03-reading.html#required",
    "href": "readings/03-reading.html#required",
    "title": "Week 3 Readings",
    "section": "",
    "text": "ggplot2 BERD workshop slides - lots more on different geoms and how to customize plots\n\n\n\n\n\ndplyr cheatsheet - one of the best references.\nCombining functions using the pipe operator, |&gt; which is mostly equivalent to %&gt;%; if you’re confused about |&gt; or %&gt;%, please read this."
  },
  {
    "objectID": "readings/03-reading.html#optional",
    "href": "readings/03-reading.html#optional",
    "title": "Week 3 Readings",
    "section": "Optional",
    "text": "Optional\n\nCustomizing ggplot2\nIf you are interested in learning more about ggplot:\n\nThemes to improve your ggplot figures by David Keyes is really helpful for learning how to do more styling.\nRStudio also publishes a ggplot cheat sheet that is really handy!\nCustomizing ggplot2 Cheatsheet is also handy, because it organizes ggplot2 commands by task.\nDocumentation for all ggplot features is available here.\n\n\n\nUsing tidyselect (Intermediate Level)\nRemember, select() works on columns.\ntidyselect lets you select columns by matching names. In conjunction with the across() command, you can apply the same operation to multiple columns at once. This is especially handy when you need to produce a summary on all numeric columns.\nYou can run the tidyselect tutorial by first installing the tidyowl package by Ted Laderas:\ninstall.packages(\"remotes\")\nremotes::install_github(\"laderast/tidyowl\")\nand then running this code in your Rstudio console window:\nlibrary(tidyowl)\nlearn_tidyselect()"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course aims to develop programming skills in R, a powerful statistical programming language. This course assumes some prior familiarity with R and ranges from advanced beginner topics to intermediate topics. It will cover practical data science skills in R that are useful for a career in statistics, epidemiology, or data science, including loading data, data wrangling, visualization, automation, machine learning, and running statistical models. A laptop is required for class to participate in coding exercises."
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "",
    "text": "This course aims to develop programming skills in R, a powerful statistical programming language. This course assumes some prior familiarity with R and ranges from advanced beginner topics to intermediate topics. It will cover practical data science skills in R that are useful for a career in statistics, epidemiology, or data science, including loading data, data wrangling, visualization, automation, machine learning, and running statistical models. A laptop is required for class to participate in coding exercises."
  },
  {
    "objectID": "syllabus.html#credit-hours",
    "href": "syllabus.html#credit-hours",
    "title": "Syllabus",
    "section": "Credit Hours",
    "text": "Credit Hours\n3 credit hours."
  },
  {
    "objectID": "syllabus.html#learning-objectives",
    "href": "syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand and utilize R/RStudio, including using Quarto to create reproducible documents of statistical analyses.\nUnderstand basic data types and data structures in R.\nFamiliarize and load data files (Excel, Comma Separated Value files) into R/Rstudio, with tips on formatting.\nVisualize datasets using ggplot2 and understand how to build basic plots using ggplot2 syntax.\nFilter and format data in R for use with various routines.\nRun and Interpret some basic statistics in R.\nAutomate repetitive tasks in R, such as loading a folder of files.\n\nIf time allows:\n\nCreate nice tables in our R markdown reports with gt, gtsummary, and/or kableExtra."
  },
  {
    "objectID": "syllabus.html#course-website",
    "href": "syllabus.html#course-website",
    "title": "Syllabus",
    "section": "Course Website",
    "text": "Course Website\nAll course information will be available here:\nhttps://niederhausen.github.io/BSTA_526_W25/\nInformation will also be available on Sakai.\nSlack will be used for course discussions. Link to join Slack is posted on Sakai."
  },
  {
    "objectID": "syllabus.html#office-hours",
    "href": "syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "Office Hours",
    "text": "Office Hours\n\nSee Sakai for Webex links to office hours\nIn addition to times below, office hours can be set up by appointment at other times. Please email or message on Slack whom who would like to set up an office hour with.\nTA Kellen Stark’s office hours Mondays 12-2pm on webex. See Sakai for the link.\nDr. Niederhausen and Dr. Minnier have office hours by appointment or after class. Don’t hesitate to ask for a meeting!"
  },
  {
    "objectID": "syllabus.html#prerequisites-or-concurrent-enrollment-requirements",
    "href": "syllabus.html#prerequisites-or-concurrent-enrollment-requirements",
    "title": "Syllabus",
    "section": "Prerequisites or Concurrent Enrollment Requirements",
    "text": "Prerequisites or Concurrent Enrollment Requirements\n\nBSTA 511 or permission by instructor."
  },
  {
    "objectID": "syllabus.html#instructor-information",
    "href": "syllabus.html#instructor-information",
    "title": "Syllabus",
    "section": "Instructor Information",
    "text": "Instructor Information\n\nInstructors\n\nPreferred Method of Contact: Email or Slack. When emailing, please include BSTA 526 in the subject line.\n\nExpected Response Time: 1 business day\nMeike Niederhausen, PhD\n\nniederha@ohsu.edu\n\nJessica Minnier, PhD\n\nminnier@ohsu.edu\n\n\n\n\nTeaching Assistant\n\nKellen Stark\n\nstarkke@ohsu.edu"
  },
  {
    "objectID": "syllabus.html#attendance",
    "href": "syllabus.html#attendance",
    "title": "Syllabus",
    "section": "Attendance",
    "text": "Attendance\n\nThis class will meet in-person and you are expected to attend class regularly. However, we understand that it is not always possible to attend class and daily attendance will not be monitored.\nClasses will be recorded, but we cannot guarantee the in-person format will lend itself to effective recordings. If you miss class, please reach out to a classmate for missed material.\n\n\nPost-class surveys\n\n5% of your grade is based on filling out post-class surveys as a way of telling us that you came to class and engaged with the material for that week.\nYou only need to fill out 5 surveys (of the 10 class sessions) for the full 5%. We encourage you to fill out as many surveys as possible to provide feedback on the class though.\nPlease fill out surveys by the following class period.\nThe questions on the survey are:\n\nRating the pace of the lecture and lab\nClearest Point: What point of the class was clearest for you?\nMuddiest Point: What point of class was the muddiest (unclear) for you?\nAnything Else: Anything else you’d like me to know?"
  },
  {
    "objectID": "syllabus.html#homework",
    "href": "syllabus.html#homework",
    "title": "Syllabus",
    "section": "Homework",
    "text": "Homework\nHomework will be assigned weekly using Quarto in RStudio. It will be due via Sakai upload Thursdays at 11:55pm the night of the following week’s class (unless otherwise noted). Please turn in both your .qmd and rendered .html file.\nThe homework with the lowest score will be dropped from your homework average.\n\nLate Policy\nStudents get 1 free homework assignment to submit late within 3 days without penalties. Please email the instructors and the TA that you need more time. If you need an accommodation, please email us so we can figure out a way to help you."
  },
  {
    "objectID": "syllabus.html#function-of-the-week",
    "href": "syllabus.html#function-of-the-week",
    "title": "Syllabus",
    "section": "Function of the Week",
    "text": "Function of the Week\nPlease choose a function from the Function of the Week sign-up sheet (link is posted on Sakai). A Quarto template to format your Function of the Week and presentation will be provided. Function of the Week presentations will start in week 4. On the sign-up sheet you will choose a week to present your function to the class, as well as the function. The presentation should be short, around 5 minutes. If presenting to the class feels prohibitive, you may submit a 5-10 minute screen recording with your voice narrating the presentation, and this will be distributed to the class.\nPrevious years’ Functions of the Week can be found on the previous class websites:\n\nhttps://niederhausen.github.io/BSTA_526_W24/function_week.html\nhttps://sph-r-programming-2023.netlify.app/functions/\nhttps://sph-r-programming-2022.netlify.app/functions/\nhttps://sph-r-programming.netlify.app/functions/ (2021)\n\nWe will create a similar website for this year’s Functions of the Week. If you do not wish yours to be on the public facing website, just let us know. Alternatively, we can also post it anonymously. See submitted Functions of the Week for this quarter at this link."
  },
  {
    "objectID": "syllabus.html#midterm-and-final-projects",
    "href": "syllabus.html#midterm-and-final-projects",
    "title": "Syllabus",
    "section": "Midterm and Final Projects",
    "text": "Midterm and Final Projects\n\nMidterm and final projects/tests will be take home.\n\nThe midterm will be a project based on a dataset of your choosing.\n\nThe final will be based on an assigned dataset.\n\nPrevious years’ midterms can be found on the class websites:\n\nhttps://sph-r-programming-2023-midterms.netlify.app/\nhttps://sph-r-programming-2022-midterms.netlify.app/\nhttps://sph-midterm-projects.netlify.app/ (2021)\nWe will create a similar website for this year’s midterm projects.\n\nIf you do not wish your project to be on the public facing website, just let us know. Alternatively, we can also post it anonymously."
  },
  {
    "objectID": "syllabus.html#grading-policy",
    "href": "syllabus.html#grading-policy",
    "title": "Syllabus",
    "section": "Grading Policy",
    "text": "Grading Policy\n\nAttendance (based on post-class surveys) 5%\nMidterm Project 20%\nFunction of the Week 10%\nHomework Assignments 45%\nFinal Project 20%\n\n\nGrading Scale\n\nAssessments will be graded on a 10 pt scale (0-10 points).\nA weighted average of the grade will be calculated using the percentages listed above, and final grades will be assigned based on the table below. Scores will be rounded up; for example an average of 7.5 will be assigned an A-.\n\n\n\n\n\nPoints\nLetter Grade\n\n\n\n\n10\nA\n\n\n9\nA\n\n\n8\nA-\n\n\n7\nB+\n\n\n6\nB\n\n\n5\nB-\n\n\n4\nC+\n\n\n3\nC\n\n\n2\nC-\n\n\n1\nD\n\n\n0\nF\n\n\n\nIn assigning points 0-10, the following general guidelines will be applied:\n\n\n\n\nA\nExceeds the standard\n\n\nB\nMeets the standard\n\n\nC\nKey gaps in understanding of the standard\n\n\nD\nUnable to demonstrate B or C without assistance\n\n\nF\nNo evidence\n\n\n\nThis rubric was adapted from Chapter 12 of Grading for Equity by Joe Feldman.\n\n\nGrading Rubric\n\nAssessments will be graded on a 10 pt scale (0-10 points) using the rubric below.\nThe 10 pts for each assessment will be based on:\n\nAnswers: 4 pts\nDemonstrating process: 3 pts\nProviding context and relevance: 3 pts\n\n\nThe table below will be used to determine points for each of the three categories.\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 points\n3 points\n2 points\n1 point\n0 points\n\n\nAnswers\n(4 pts max)\nAnswers are correct at least 90% of the time\nAnswers are usually correct (75-90%)\nAnswers are sometimes correct (50-74%)\nAnswers are generally incorrect (&lt;50%)\nAnswers are incorrect and no work was shown (demonstrating process has 0 pts)\n\n\nDemonstrating process\n(3 pts max)\n\nAll relevant work is shown, including all steps for figuring out answers.\nR code and output are provided for every question for which R was used.\nRelevant work and steps for figuring out answers are generally provided but incomplete.\nR code and output are generally provided but incomplete for questions that use R.\nRelevant work and steps for figuring out answers are generally missing.\nR code and output are generally missing for questions that use R.\nNo relevant work is shown, including steps for figuring out answers.\nR code and output are not provided for questions for which R was used.\n\n\nProviding context and relevance\n(3 pts max)\n\nAnswers are given in complete sentences with all relevant information for the question as appropriate (context of research question, units, descriptive statistics, explanation of what data visualization is showing, confidence intervals, p-values, test- statistics, etc.), and interpretation of results.\nAnswers are given in complete sentences. Some relevant information may be provided, but much is missing. Context of research question only sometimes provided.\nAnswers are rarely given in complete sentences. Relevant information is not provided. Little to no context is provided.\nAnswers are not in complete sentences. Relevant information and context are not provided."
  },
  {
    "objectID": "syllabus.html#code-of-conduct",
    "href": "syllabus.html#code-of-conduct",
    "title": "Syllabus",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nAnd as students of an OHSU course, we must abide by the OHSU Code of Conduct: https://www.ohsu.edu/integrity-department/code-conduct\nThis class is meant to be a psychologically safe space where it’s ok to ask questions. We want to normalize your own curiosity and fuel your desire to learn more.\nThere is a link on Sakai to a form to anonymously report to us any possible code of conduct violations, based on the OHSU Code of Conduct or the OHSU Biodata Code of Conduct."
  },
  {
    "objectID": "syllabus.html#required-texts-and-readings",
    "href": "syllabus.html#required-texts-and-readings",
    "title": "Syllabus",
    "section": "Required Texts and Readings",
    "text": "Required Texts and Readings\nWe will be drawing on the following online textbooks during class and labs. These books are online and free, though you can order them as textbooks if you prefer that format.\n\nR for Data Science. Hadley Wickham, Mine Çetinkaya-Rundel, Garrett Grolemund. 2nd Edition. https://r4ds.hadley.nz/\nGetting Used to R, RStudio, and RMarkdown. Chester Ismay. https://ismayc.github.io/rbasics-book/\nData Science: A First Introduction. Tiffany Timbers, Trevor Campbell, Melissa Lee. https://datasciencebook.ca/\nRMarkdown for Scientists. Nick Tierney. https://rmd4sci.njtierney.com/\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse. Chester Ismay and Albert Y. Kim. https://moderndive.com/v2/\nAdvanced R. Hadley Wickham. https://adv-r.hadley.nz/\nQuarto webpage https://quarto.org/\n\nThe Guide and Reference tabs have very helpful documentation.\n\n\n\nNote on RMarkdown vs. Quarto\n\nWe will be using the newer Quarto instead of RMarkdown for creating reproducible documents. Some of the links above are for RMarkdown, which is very similar.\n\nThe main differences are in setting up the yaml and code chunk options.\nMany of the RMarkdown code chunk options work with Quarto though.\nWith Quarto you will see a Render button instead of a Knit button to create the html output of the file."
  },
  {
    "objectID": "syllabus.html#words-of-encouragement",
    "href": "syllabus.html#words-of-encouragement",
    "title": "Syllabus",
    "section": "Words of Encouragement",
    "text": "Words of Encouragement\n\nThis was adopted from Andrew Heiss. Thanks!\n\nI promise you can succeed in this class.\nLearning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like ggplot2—made this wise observation:\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\nEven experienced programmers find themselves bashing their heads against seemingly intractable errors. If you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, e-mail us, etc.\n\n\n\nAlison Horst Jan 3, 2020 tweet\n\n\n\n\n\nAlison Horst: Gator error"
  },
  {
    "objectID": "syllabus.html#learning-is-social",
    "href": "syllabus.html#learning-is-social",
    "title": "Syllabus",
    "section": "LeaRning is Social",
    "text": "LeaRning is Social\nStudents who struggle in courses often are ones who don’t work with each other to learn. We are a learning community, and we should help each other to learn.\nIf you understand something and know someone is struggling with it, try and help them. If you are struggling, take a breath, and try to pinpoint what you are struggling with.\nOur goal is to be better programmers each day, not to be the perfect programmer. There’s no such thing as a perfect programmer. We’ve been learning new things almost every day."
  },
  {
    "objectID": "syllabus.html#copyright-information",
    "href": "syllabus.html#copyright-information",
    "title": "Syllabus",
    "section": "Copyright Information",
    "text": "Copyright Information\nEvery reasonable effort has been made to protect the copyright requirements of materials used in this course. Class participants are warned not to copy, audio, or videotape in violation of copyright laws.\nJournal articles will be kept on reserve at the library or online for student access. Copyright law does allow for making one personal copy of each article from the original article. This limit also applies to electronic sources.\nTo comply with the fair use fair use doctrine of the US copyright law, Sakai course sites close three weeks after grades are posted with the Registrar. Please be sure to download all course material you wish to keep before this time as you will have no further access to your courses."
  },
  {
    "objectID": "syllabus.html#school-of-public-health-handbook",
    "href": "syllabus.html#school-of-public-health-handbook",
    "title": "Syllabus",
    "section": "School of Public Health Handbook",
    "text": "School of Public Health Handbook\nAll students are responsible for following the policies and expectations outlined in the student handbook for their program of study. Students are responsible for their own academic work and are expected to have read and practice principles of academic honesty, as presented in the handbook: https://ohsu-psu-sph.org/current-graduate-students/policies-procedures/#academic-dishonesty."
  },
  {
    "objectID": "syllabus.html#syllabus-changes-and-retention",
    "href": "syllabus.html#syllabus-changes-and-retention",
    "title": "Syllabus",
    "section": "Syllabus Changes and Retention",
    "text": "Syllabus Changes and Retention\nThis syllabus is not to be considered a contract between the student and the School of Public Health. It is recognized that changes may be made as the need arises. Students are responsible for keeping a copy of the course syllabus for their records.\nSyllabi are considered to be a learning agreement between students and the faculty of record. Information contained in syllabi, other than the minimum requirements, may be subject to change as deemed appropriate by the faculty of record in concurrence with the academic program and the Office of the Provost. Refer to the Course Syllabi Policy, 02-50-050."
  },
  {
    "objectID": "syllabus.html#syllabus-statement-regarding-disability-services",
    "href": "syllabus.html#syllabus-statement-regarding-disability-services",
    "title": "Syllabus",
    "section": "Syllabus Statement Regarding Disability Services",
    "text": "Syllabus Statement Regarding Disability Services\nOHSU is committed to providing equal access to qualified students who experience a disability in compliance with Section 504 of the Rehabilitation Act of 1973, the Americans with Disabilities Act (ADA) of 1990, and the ADA Amendments Act (ADA-AA) of 2008. If you have a disability or think you may have a disability (physical, sensory, chronic health, psychological or learning) please contact the Office for Student Access at (503) 494-0082 or studentaccess@ohsu.edu to discuss eligibility for academic accommodations. Information is also available at www.ohsu.edu/student-access. Because accommodations may take time to implement and cannot be applied retroactively, it is important to have this discussion as soon as possible. All information regarding a student’s disability is kept in accordance with relevant state and federal laws.\nPlease see Student Access & Accomodations section for more details on the Sakai version of this Syllabus."
  },
  {
    "objectID": "syllabus.html#commitment-of-equity-and-inclusion",
    "href": "syllabus.html#commitment-of-equity-and-inclusion",
    "title": "Syllabus",
    "section": "Commitment of Equity and Inclusion",
    "text": "Commitment of Equity and Inclusion\nThe School of Public Health is committed to providing an environment free of all forms of prohibited discrimination and discriminatory harassment. The School of Public Health students who have questions about an incident related to Title IX are welcome to contact either the OHSU or PSU’s Title IX Coordinator and they will direct you to the appropriate resource or office. Title IX pertains to any form of sex/gender discrimination, discriminatory harassment, sexual harassment or sexual violence.\nPSU’s Title IX Coordinator is Julie Caron, she may be reached at titleixccordinator@pdx.edu or 503-725-4410. Julie’s office is located at 1600 SW 4th Ave, In the Richard and Maureen Neuberger Center RMNC - Suite 830.\nThe OHSU Title IX Coordinator’s may be reached at 503-494-0258 or titleix@ohsu.edu and is located at 2525 SW 3rd St.\nPlease note that faculty and the Title IX Coordinators will keep the information you disclose private but are not confidential. If you would like to speak with a confidential advocate, who will not disclose the information to a university official without your written consent, you may contact an advocate at PSU or OHSU.\nPSU’s confidential advocates are available in Women’s Resource Center (serving all genders) in Smith Student Memorial Union 479. You may schedule an appointment by (503-725-5672) or schedule on line at https://psuwrc.youcanbook.me. For more information about resources at PSU, please see PSU’s Response to Sexual Misconduct website.\nOHSU’s advocates are available through the Confidential Advocacy Program (CAP) at 833-495-CAPS (2277) or by email CAPsupport@ohsu.edu, but please note, email is not a secure form of communication. Also visit www.ohsu.edu/CAP.\nAt OHSU, if you encounter any harassment, or discrimination based on race, color, religion, age, national origin or ancestry, veteran or military status, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity or expression, disability or any other protected status, please contact the Affirmative Action and Equal Opportunity (AAEO) Department at 503- 494-5148 or aaeo@ohsu.edu.\nAt PSU, you may contact the Office of Equity and Compliance if you experience any form of discrimination or discriminatory harassment as listed above at equityandcompliance@pdx.edu or by calling 503-725-5919."
  },
  {
    "objectID": "syllabus.html#academic-honesty",
    "href": "syllabus.html#academic-honesty",
    "title": "Syllabus",
    "section": "Academic Honesty",
    "text": "Academic Honesty\n\nCourse participants are expected to maintain academic honesty in their course work. Participants should refrain from seeking past published solutions to any assignments. Literature and resources (including internet resources and generative AI) employed in fulfilling assignments must be cited.\n\nSee Purdue University’s Online Writing Lab for resources on plagiarism and importantly avoiding plagiarism (thanks to Steve Bedrick for this link!).\nAssignments suspected of plagiarism (including copying past solutions or another student’s assignment) will receive 0 points for the assignment and the dean of the student’s academic program will be notified.\n\nIn an effort to uphold the principles and practice of academic honesty, faculty members at OHSU may use originality checking systems such as Turnitin to compare a student’s submitted work against multiple sources.\n\nTo protect student privacy in this process, it will be necessary to remove all personal information, i.e. student name, email address, student u-number, or any other personal information, from documents BEFORE submission.*\n\n\n\nUse of ChatGPT or other generative AI for assignments\nChatGPT and other generative AI tools can be great resources for learning how to code and/or troubleshoot code that does not work. However, the work you turn in must be your own. Thus it is inappropriate to directly ask AI to provide you with solutions to homework questions or write text that you are submitting in your assignment. If you do use AI tools to help you with an assignment, these must be cited along with how they were used.\nPlease see the Plagiarism & Attribution section (Code Snippets and AI Tools subsection) of Dr. Steve Bedrick’s BMI 525: Principles and Practice of DataVisualization webpage for examples of appropriate and inappropriate uses generative AI."
  },
  {
    "objectID": "syllabus.html#use-of-sakai",
    "href": "syllabus.html#use-of-sakai",
    "title": "Syllabus",
    "section": "Use of Sakai",
    "text": "Use of Sakai\nSakai is OHSU’s online course management system. Some course information will only be available on Sakai, and you will be turning in assignments using Sakai. For any technical questions or if you need help logging in, please contact the Sakai Help Desk. See also the Sakai Student Guide for more information.\n\nHours: Sakai Help Desk is available Mon – Fri, 8 am – 5 pm, Pacific Time.\nContact Information:\n\n(Toll-free) 877-972-5249\n(Web) http://atech.ohsu.edu/help\n(Email) sakai@ohsu.edu"
  },
  {
    "objectID": "survey_feedback_previous_years.html",
    "href": "survey_feedback_previous_years.html",
    "title": "Survey Feedback",
    "section": "",
    "text": "Please fill out the post-class survey here.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-1",
    "href": "survey_feedback_previous_years.html#week-1",
    "title": "Survey Feedback Previous Years",
    "section": "",
    "text": "Will there be presentation slides in future classes, or is everything embedded into the quarto/html files for all lectures?\n\nThe material will primarily be in quarto/html files and not slides.\n\nSpecifics of what topics will be covered exactly. * I don’t have a list of all the specific functions we will be covering, but you are welcome to peruse the BSTA 504 webpage from Winter 2023 to get more details on topics we will be covering. We will be closely following the same class materials.\nIdentifying which section of the code we were discussing during the lecture\n\nThanks for letting me know. I will try to be clearer in the future, and also jump around less. Please let me know in class if you’re not sure where we are at.\n\nThe material covered towards the end of the class felt a bit difficult to keep up with. I wish we would have been told to read the materials from Week 1 (or at least skim them) ahead of Day 1, because I quickly lost track of the conversation when shortcuts were used super quickly, for example, or when we jumped from chunks of code to another topic without reflecting on them. I still had 70% of the material down and I wrote great notes during the discussion (which I later filled in with the script that was on the class website), but I think it the beginner/intermediate programming lingo that was used to explain ideas here confused me at times. Thus, I struggled to keep up with discussions around packages / best coding practices, especially when they were not mentioned directly on the script (where I could follow along!).\n\nThanks for the feedback. In future years, we will reach out to students before the term to let them know about the readings to prepare for class. Please let us know if there is lingo we are using that you are not familiar with. Learning R and coding is a whole new language!\n\n\n\n\n\n\nI have trouble thinking through where things are automatically downloaded, saved, and running from. I can attend office hours for this!\n\nOffice hours are always a great idea. I do recommend paying close attention to where files are being saved when downloading and preferably specifying their location instead using the default location. Having organized files will make working on complex analyses much easier.\n\nHow to read the course material in R. While it made sense in real time it may be difficult when going back over the material.\n\nGetting used to reading code and navigating the rendered html files takes a while, and is a part of learning R. Figuring out how to take notes for yourself that works for you is also a learning curve. I recommend taking notes in the qmd files as we go through them in class. After class you can summarize and transfer key points to other file formats that you are more used to using. I personally have a folder in my Google drive filled with documents on different R programming topics. It started with one file, and then eventually expanded to multiple files on different topics in an attempt to organize my notes better. Whenever I learn something new (such as an R function or handy R package) that I want to keep for future reference, I add to them with links to relevant webpages and/or filenames and locations of where I used them.\n\n\n\n\n\n\nWhat does the pacman package do? I have it installed but I’m not sure what it is actually used for.\n\nI didn’t go into pacman in Day 1. The p_load() function from the pacman package (usually run as pacman::p_load()) lets you load many packages at once without separately using the library() function for each individually.\nAn added bonus is that by default it will install packages you don’t already have, unless you specify install = FALSE.\nAnother option is to set update = TRUE so that it will automatically update packages. I do not use this option though since sometimes updating packages causes conflicts with other packages or older code.\nYou can read more about the different options in the documentation. This Medium article also has some tips on using pacman.\n\nThe part on when to load in packages once they’ve already been loaded in - like for example would it be good to put that as a step in our homework 1 .qmd at the top? Or not necessary since they’re already loaded in to R Studio from the work we did in class yesterday? What would happen if we try to load them in and they were already loaded in, would the .qmd file not render and show an error?\n\nI always load my packages at the very top of the .qmd files, usually in the first code chunk (with the setup label). If you still have a previous R session open, then yes you don’t need to load the packages again to run code within RStudio. However, when a file is rendered it starts with an empty workspace, which is why our qmd file must include code that loads the packages (either using library() or pacman::p_load(). We don’t have to load packages at the beginning of the file, just before we have code that depends on the packages being used.\n\nI didn’t understand the part where we talked about num, char, logical combinations (line 503).\n\nThe content of the objects char_logical, num_char, num_logical, and tricky were designed specifically to be confusing and thus make us aware of how R will decide to assign the data type when a vector is a mix of data types. Some key takeaways are below. Let me know if you sitll have questions about this.\n\nNumbers and logical/boolean (TRUE, FALSE) do not have double quotes around them, but character strings do. If you add double quotes to a number or logical, then R will treat it as a character string.\nIf a vector is a mix of numbers and character strings, then the data type of the vector is character.\nIf a vector is a mix of numbers and logical, then the data type of the vector is numeric and the logical value is converted to a numeric value (TRUE=1, FALSE=0).\nIf a vector is a mix of character strings and logical, then the data type of the vector is character and the logical value is converted to a character string and no longer operates as a logical (i.e. no longer equal to 1 or 0).\n\n\nLines 614-619, confused what the ratio means there. Could you go over the correct code (or options of the correct code) for challenge 5?\n\nThe code 1:4 or 6:9 creates sequences of integers starting with the first specified digit and ending at the last specified digit. For example, 1:4 is the vector with the digits 1 2 3 4. You can also create decreasing sequences by making the first number the bigger one. For example, 9:7 is the vector 9 8 7.\nChallenge 5:\n\nmore_heights_complete &lt;- na.omit(more_heights)\nmedian(more_heights_complete)\nYou could also get the median of more_heights without first removing the missing values with median(more_heights, na.rm = TRUE).\n\n\nhow to count the TRUE values in a logical vector\n\nTRUE is equal to 1 in R (and FALSE is equal to 0), and the function sum() adds up the values in a vector. Thus, sum(TRUE, FALSE, TRUE) is equal to 2. Similarly, sum(TRUE, FALSE, 5) is equal to 6.\nThe way I used it in class though is by counting how many values in the vector z (which was 7 9 11 13) are equal to 9. To do that I used the code sum(z == 9). Breaking that down, the code inside the parentheses z == 9 is equal to FALSE TRUE FALSE FALSE since the == means “equals to” in R.\nYou can read up more on boolean and logical operators at the R-bloggers post.\n\n\n\n\n\n\nThank you for the feedback!\n\n\n\nSyllabus/course structure\nThe syllabus review.\nOverall expectations and course flow\nIntroduction to the class (first half of the class); conversation around syllabus; and the Quarto introduction\n\n\n\n\n\nHow to create and edit a Quarto document in RStudio.\nThe differences between quarto and markdown\nrmarkdown is no more, quarto it is!\n\n\n\n\n\nHaving code missing and fixing it in front of the class was helpful in troubleshooting.\nJust running through all the commands was very clear and easy to follow\nBasic R set up for quarto and introduction to R objects, vectors, etc.\nIntroduction, functions, and explanations was the clearest for me.\nClassification of the objects in logical, character, and numeric\nNot necessarily a point, but I really liked when we were encouraged to use the shortcut keys for various commands on R and other little things like switching code between console vs inline , I have used R before for a class briefly but I never knew all these ways by which I can save time and be efficient while writing a code.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-2",
    "href": "survey_feedback_previous_years.html#week-2",
    "title": "Survey Feedback",
    "section": "Week 2",
    "text": "Week 2\n\nMuddiest points\n\nWhen discussing untidy data, the difference between long data and wide data was unclear.\n\nWe’ll be discussing the difference between long and wide data in more detail later in the course when we convert a dataset between the two. For now, you can take a look at an example I created for our BERD R workshops. The wide data in that example are not “tidy” since each cell contains two pieces of information: both the SBP and the visit number. In contrast, the long data have a separate column indicating which visit number the data in a given row are from.\n\nfor the “summary()” function, is there a way to summarize all but one variable in a dataset?\n\nYes! I sometimes restrict a dataset to a couple of variables for which I want to see the summary. I usually use the select() function for this, which we will be covering later in the course. For now, you can take a look at some select() examples from the BERD R workshops (see slides 29-32).\n\nDifferences between a tibble and a data.frame\n\nI’m not surprised to see this show up as a muddiest point! Depending on your level of experience with R, at this point in the class some of the differences are difficult to explain since we haven’t done much coding yet. The tibble vignette lists some of the differences though if you are interested. For our purposes, they are almost the same thing. When some differences come up later in the course, I will point them out.\n\n\n\n\nClearest Points\nThanks for the feedback!\n\nI enjoyed going through the code and viewing the functions. I haven’t really used skimr before and that was nice to see.\n\nI like using skmir, but have recently been using get_summary_stats() from the rstatix package when teaching. It is only for numeric variables though. See a get_summary_stats() example from my BSTA 511 class.\n\nLoading data.\nHow to load data into R was clearest.\n\nGood to know that loading data was clear. This part can be tricky sometimes!\n\nggplot\n\nHopefully this will still be clear when we cover more advanced options in ggplot!",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "weeks/week_05.html#week-5",
    "href": "weeks/week_05.html#week-5",
    "title": "Week 5",
    "section": "Week 5",
    "text": "Week 5\n\ncase_when() vs ifelse()\nThe difference between case_when and ifelse\n\nifelse() is the base R version of tidyverse’s case_when()\nI prefer using case_when() since it’s easier to follow the logic.\ncase_when() is especially useful when there are more than two logical conditions being used.\n\nThe example below creates a binary variable for bill length (long vs not long) using both case_when() and ifelse() as a comparison.\n\nCompare the crosstabs of the two variables!\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(palmerpenguins)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill1 = case_when(\n      bill_length_mm &gt;= 45 ~ \"long\",\n      bill_length_mm &lt; 45 ~ \"not long\",\n    ),\n    long_bill2 = ifelse(bill_length_mm &gt;= 45, \"long\", \"not long\")\n  )\n\npenguins %&gt;% tabyl(long_bill1, long_bill2) %&gt;% \n  adorn_title()\n\n            long_bill2             \n long_bill1       long not long NA_\n       long        166        0   0\n   not long          0      176   0\n       &lt;NA&gt;          0        0   2\n\n\nBelow is an example using case_when() to create a categorical variable with 3 groups:\n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill3 = case_when(\n      bill_length_mm &gt;= 50 ~ \"long\",\n      bill_length_mm &lt;= 40 ~ \"short\",\n      TRUE ~ \"medium\"\n    ))\n\npenguins %&gt;% tabyl(long_bill3, long_bill1) %&gt;% \n  adorn_title()\n\n            long_bill1             \n long_bill3       long not long NA_\n       long         57        0   0\n     medium        109       76   2\n      short          0      100   0\n\n\n\nCreating a categorical variable with 3 groups can be done with ifelse(), but it’s harder to follow the logic:\n\n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill4 = ifelse(\n      bill_length_mm &gt;= 50, \"long\",\n      ifelse(bill_length_mm &lt;= 40, \"short\", \"medium\")\n      ))\n\npenguins %&gt;% tabyl(long_bill3, long_bill4) %&gt;% \n  adorn_title()\n\n            long_bill4                 \n long_bill3       long medium short NA_\n       long         57      0     0   0\n     medium          0    185     0   2\n      short          0      0   100   0\n\n\n\n\nseparate()\nDifferent ways of using the function separate, it was a bit unclear that when to use one or the other or examples of my research data where it’ll be most relevant to use.\n\nChoosing the “best” way of using separate() is overwhelming at first.\nI recommend starting with the simplest use case with a string being specified in sep = \" \":\n\n\nseparate(data, col, into, sep = \" \")\n\n\nWhich of the various versions we showed to use depends on how the data being separated are structured.\nMost of the time I have a simple character, such as a space (sep = \" \") or a comma (sep = \",\") that I want to separate by.\nIf the data are structured in a more complex way, then one of the stringr package options might come in handy.\n\n\n\nhere::here()\nTSV files, very neat… But also, I got a bit confused when you did the render process around 22:00-23:00 minutes. Also, “here: and also”here” Directories/root directories. I was a bit confused about in what situations we would tangibly utilize this/if it is beneficial.\n\nGreat question! This is definitely not intuitive, which is why I wanted to demonstrate it in class.\nThe key is that\n\nwhen rendering a qmd file the current working directory is the folder the file is sitting in,\nwhile when running code in a file within RStudio the working directory is the folder where the .Rproj file is located.\n\n\nThis distinction is important when loading other files from our computer during our workflow, and why here::here() makes our workflow so much easier!\n\n\n\nwhat functions will only work within another function (generally)\n\nI’m not aware of functions that only work standalone within other functions. For example, the mean() function works on its own, but can also be used within a summarise().\n\n\nmean(penguins$bill_length_mm, na.rm = TRUE)\n\n[1] 43.92193\n\npenguins %&gt;% summarise(\n  m = mean(bill_length_mm, na.rm = TRUE)\n)\n\n# A tibble: 1 × 1\n      m\n  &lt;dbl&gt;\n1  43.9\n\n\n\nThat being said, a function has a set of parameters to be specified that are specific to that function."
  },
  {
    "objectID": "weeks/week_11.html#muddiest-points-1",
    "href": "weeks/week_11.html#muddiest-points-1",
    "title": "Week 11",
    "section": "Muddiest points",
    "text": "Muddiest points\n\nSee Week 10 page for Week 10 feedback."
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-3",
    "href": "survey_feedback_previous_years.html#week-3",
    "title": "Survey Feedback",
    "section": "Week 3",
    "text": "Week 3\n\nMuddiest points\n\nhere package\nThe here package takes a bit to explaining, but, compared to the old way of doing things, it is a real life saver. The issue in the past had to do with relative file paths, especially with .qmd files that are saved in sub-folders. The .qmd file recognizes where it is saved as the root file path, which is okay with a one-off .qmd file. But when working in projects (recommended) and striving for reproducible R code (highly recommended), the here package save a lot of headache.\nFor further reading: + Why should I use the here package when I’m already using projects? by Malcolm Barrett. + how to use the here package by Jenny Richmond. + here package vignette + Using here with rmarkdown\nProject-oriented workflows are recommended. Here package solves some old headaches. It gets easier with practice.\n\nQuestion about using here\n\n… how [here] can be used in certain instances where one may not remember if they switched to a new qmd file? In that case, would you suggest to use the “here” command each time you work on a project where there’s a chance that you’ll switch between qmd files and would like to use the same data file throughout? Is there any other way to better use this function or tips on how you deal with it?\n\nThere is a difference between working interactively in RStudio where data are loaded to the Environment. In this case, loading a data set once means that it can be used in any other code while working in the environment.\nIssues will com up when you go to render a .qmd that doesn’t have the data loaded within that .qmd. It won’t look to the environment for the data; it looks to the filepath that you specify in the .qmd. Best practice is to write the code to load the data in each .qmd or .R script so that R knows where to look for the data that you want it to operate on / analyze.\n\n\n\nThe ! function. It seems like sometimes we use ! and sometimes we use -. Are they interchangeable, or each with different types of functions?\n\n! – the exclamation point can be read as “not” it is primarily used in logical statements\n- – the minus sign can be used in more instances\n\nto do actual arithmetic (i.e. subtraction)\nto indicate a negative number\nwith dplyr::select() to remove or not select a column, or exclusion\n\n\n\n# Subtraction\n5 - 3\n\n[1] 2\n\n# Negation\nx &lt;- 10\n-x\n\n[1] -10\n\n# Selection/exclusion\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nselect(starwars, -height) |&gt; dplyr::glimpse()\n\nRows: 87\nColumns: 13\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"A New Hope\", \"The Empire Strikes Back\", \"Return of the J…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n\nUsing the fill command\nWe didn’t cover it in the lecture notes, but then it appeared in the example. I suggest to read/work through the fill vignette; the examples there are good ones to show what the function does. Then look back a the smoke_messy data set in Part 3 and think about why this command would be useful to clean up the data and for filling in missing values.\n\n\nLoading data into R\nIt gets easier and hopefully you get to see more example in the notes and practice with the homework. This tutorial is pretty good. So is the readxl vignette and the readr vignette.\n\n\nReasonable width, height, and dpi values when using ggsave\nThis takes some trial and error and depends on the purpose. For draft figures, dpi = 70 might be okay, but a journal might require dpi above 300 for publication. In Quarto, rendering an html, the figure defaults are 7x5 inches (Link). We talked about in class how you can use the plot panes to size your figures by trial and error.\n\n\nThe tidyselect section\nThere were pretty good resources in the notes\n\nSee some more examples in this slide\nFor more info and learning about tidyselect, please run this code in your console:\n\n\n# install remotes package\ninstall.packages(\"remotes\")\n# use remotes to install this package from github\nremotes::install_github(\"laderast/tidyowl\")\n\n# load tidyowl package\nlibrary(tidyowl)\n\n# interactive tutorial\ntidyowl::learn_tidyselect()\n\nHere is also a link with a list of the selectors and links to each one. For example, there is a link to starts_with and a bunch of examples.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-4",
    "href": "survey_feedback_previous_years.html#week-4",
    "title": "Survey Feedback",
    "section": "Week 4",
    "text": "Week 4\n\n# Load packages\npacman::p_load(tidyverse, \n               readxl, \n               janitor,\n               here)\n\n\n# Load data\nsmoke_complete &lt;- readxl::read_excel(here(\"data\", \"smoke_complete.xlsx\"), \n                                     sheet = 1, \n                                     na = \"NA\")\n                                     \n# dplyr::glimpse(smoke_complete)\n\n\nKeyboard shortcut for the pipe (%&gt;% or |&gt;)\nIn office hours, someone didn’t know about this fact and wanted to make sure everyone knows about it.\n\n\n\n\n\n\nImportant keyboard shortcut\n\n\n\nIn RStudio the keyboard shortcut for the pipe operator %&gt;% (or native pipe |&gt;) is Ctrl + Shift + M (Windows) or Cmd + Shift + M (Mac).\nNote: Ctrl + Shift + M also works on a Mac.\n\n\n\n\nThe difference between NA value and 0\n\nNA (Not Available)\n\nNA is a special value in R that represents missing or undefined data.\n0 is a numeric value representing the number zero. It is a valid and well-defined numerical value in R.\nIt’s important to handle NA values appropriately in data analysis and to consider their impact on calculations, as operations involving NA may result in NA.\n\n\nNA + 5  # The result is NA\n\n[1] NA\n\n0 + 5  # The results is 5\n\n[1] 5\n\nx &lt;- c(1, 2, NA, 4)\n\nsum(x)  # The result is NA\n\n[1] NA\n\n# Using the argument na.rm = TRUE, means to ignore the NAs\nsum(x, na.rm = TRUE) # The results is 7\n\n[1] 7\n\nx &lt;- c(1, 2, 0, 4)\n\nsum(x) # The result is 7\n\n[1] 7\n\n\n\n\n\nacross() and it’s usage\nThe biggest advantage that across brings is the ability to perform the same data manipulation task to multiple columns.\nBelow the values in three columns are all set to the mean value using the mean(). I had to write out the function and the variable names three times.\n\nsmoke_complete |&gt; \n  mutate(days_to_death = mean(days_to_death, na.rm = TRUE), \n         days_to_birth = mean(days_to_birth, na.rm = TRUE), \n         days_to_last_follow_up = mean(days_to_last_follow_up, na.rm = TRUE)) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\nThe same thing is accomplished using across() but we only have to call the mean() function once.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = ~ mean(.x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\nLinks to check out\n\nacross() vignette\nWhy I love dplyr’s across\n\n\n\n\n~ and .x\nWe’ve seen the ~ and .x used with dplyr::across(). We will see them again later when we get to the package purrr.\nIn the tidyverse, ~ and .x are used to create what they call lambda functions which are part of the purrr syntax. We have not talked about functions yet, but purrr package and the dplyr::across() function allow you to specify functions to apply in a few different ways:\n\nA named function, e.g. mean.\n\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = mean)) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbove, just using the function name, we are not able to provide the additional argument na.rm = TRUE to the mean() function, so the columns are now all NA values because there were missing (NA) values in those columns.\n\n\n\nAn anonymous function, e.g. \\(x) x + 1 or function(x) x + 1.\n\nThis has not been covered yet. R lets you specify your own functions and there are two basic ways to do it.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = \\(x) mean(x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\nor\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = function(x) mean(x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we are able to use the additional argument na.rm = TRUE and the columns are now the means of the valid values in those columns.\n\n\n\nA purrr-style lambda function, e.g. ~ mean(.x, na.rm = TRUE)\n\nWe use ~ to indicate that we are supplying a lambda function and we use .x as a placeholder for the argument within our lambda function to indicate where to use the variable.\n\nsmoke_complete |&gt; \n  mutate(dplyr::across(.cols = c(days_to_death, \n                                 days_to_birth, \n                                 days_to_last_follow_up), \n                       .fns = ~ mean(.x, na.rm = TRUE))) |&gt; \n  dplyr::glimpse()\n\nRows: 1,152\nColumns: 20\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;dbl&gt; 852.5637, 852.5637, 852.5637, 852.5637, 85…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24175.38, -24175.38, -24175.38, -24175.38…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;dbl&gt; 944.8547, 944.8547, 944.8547, 944.8547, 94…\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 26, NA…\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;dbl&gt; 1936, 1931, 1927, 1930, 1942, 1953, 1932, …\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;dbl&gt; 2004, 2003, NA, NA, NA, 2005, 2006, NA, NA…\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n\n\n\nLinks to check out\nSome of these are purrr focused which we have not covered yet. Others use dplyr::across() withing the dplyr::summarize() function which we will be covering soon\n\nMeaning of tilde and dot notation in dplyr\nWhat is the meaning of ‘~’ and ‘.’ inside the function map?\nacross() vignette\nWhy I love dplyr’s across\n\n\n\n\nExceptions where we have seen the ~ used\nIn class, we have seen three instances where the ~ is used that is not for a lambda function.\n\ncase_when\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = case_when(\n      cigarettes_per_day &lt; 6 ~ \"0-5\", \n      cigarettes_per_day &gt;= 6 ~ \"6+\"\n    )) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category    n    percent\n                 0-5 1100 0.95486111\n                  6+   52 0.04513889\n\n\n\n\nfacet_wrap\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_wrap(~ disease)\n\n\n\n\n\n\n\n\nPer the facet_wrap vignettte:\n\nFor compatibility with the classic interface, can also be a formula or character vector. Use either a one sided formula, ~a + b, or a character vector, c(\"a\", \"b\").\n\nHere it is being used to specify a formula.\nThough per the vignette, the vars() function is preferred syntax:\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_wrap(ggplot2::vars(disease))\n\n\n\n\n\n\n\n\n\n\nfacet_grid\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_grid(disease ~ vital_status)\n\n\n\n\n\n\n\n\nPer the facet_grid vignettte:\n\nFor compatibility with the classic interface, rows can also be a formula with the rows (of the tabular display) on the LHS and the columns (of the tabular display) on the RHS; the dot in the formula is used to indicate there should be no faceting on this dimension (either row or column).\n\nAgain, it is being used to specify a formula.\nThough per the vignette, the ggplot2::vars() function with the arguments rows and cols seems to be preferred:\n\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  facet_grid(rows = ggplot2::vars(disease), \n             cols = ggplot2::vars(vital_status))\n\n\n\n\n\n\n\n\nNote: dplyr::vars() and dplyr::ggplot2() are the same function in different packages and can be used interchangeably.\n\n\n\ncase_when vs. if_else\nIn dplyr, both if_else() and case_when() are used for conditional transformations, but they have different use cases and behaviors.\n\nif_else function\n\n\nif_else() is designed for simple vectorized conditions and is particularly useful when you have a binary condition (i.e., two possible outcomes).\nIt evaluates a condition for each element of a vector and returns one of two values based on whether the condition is TRUE or FALSE.\n\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = dplyr::if_else(cigarettes_per_day &lt; 6, \"0-5\", \"6+\")) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category    n    percent\n                 0-5 1100 0.95486111\n                  6+   52 0.04513889\n\n\nIn this example, the column cigarettes_category is assigned the value “0-5” if cigarettes_per_day is less than 6 and “6+” otherwise.\n\ncase_when() function\n\n\ncase_when() is more versatile and is suitable for handling multiple conditions with multiple possible outcomes. It is essentially a vectorized form of a switch or if_else chain.\nIt allows you to specify multiple conditions and their corresponding values.\n\n\nsmoke_complete |&gt; \n  mutate(cigarettes_category = case_when(\n      cigarettes_per_day &lt; 2 ~ \"0 to 2\", \n      cigarettes_per_day &lt; 4 ~ \"2 to 4\", \n      cigarettes_per_day &lt; 6 ~ \"4 to 6\", \n      cigarettes_per_day &gt;= 6 ~ \"6+\"\n    )) |&gt; \n  mutate(cigarettes_category = factor(cigarettes_category)) |&gt; \n  janitor::tabyl(cigarettes_category)\n\n cigarettes_category   n    percent\n              0 to 2 455 0.39496528\n              2 to 4 493 0.42795139\n              4 to 6 152 0.13194444\n                  6+  52 0.04513889\n\n\nIn this example, the column cigarettes_category is assigned the value “0 to 2” if cigarettes_per_day is less than 2, “2 to 4” if less than 4 (but greater than 2), “4 to 6” if less than 6 (but greater than 4), and “6+” otherwise.\nUse if_else() when you have a simple binary condition, and use case_when() when you need to handle multiple conditions with different outcomes. case_when() is more flexible and expressive when dealing with complex conditional transformations.\n\n\nThe difference between a theme and and a palette.\nIn ggplot2, a theme and a palette serve different purposes and are used in different contexts. In summary, a theme controls the overall appearance of the plot, while a palette is specifically related to the colors used to represent different groups or levels within the data. Both themes and palettes contribute to visual appeal and readability of your plot.\n\nTheme:\n\n\nA theme in ggplot2 refers to the overall visual appearance of the plot. It includes elements such as fonts, colors, grid lines, background, and other visual attributes that define the look and feel of the entire plot.\nThemes are set using functions like theme_minimal(), theme_classic(), or custom themes created with the theme() function. Themes control the global appearance of the plot.\n\n\nlibrary(ggplot2)\n\n# Example using theme_minimal()\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day)) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\nPalette:\n\n\nA palette, on the other hand, refers to a set of colors used to represent different levels or categories in the data. It is particularly relevant when working with categorical or discrete data where you want to distinguish between different groups.\nPalettes are set using functions like scale_fill_manual() or scale_color_manual(). You can specify a vector of colors or use pre-defined palettes from packages like RColorBrewer or viridis (we looked at the viridis package in class).\n\n\n# Example using a color palette\nggplot(data = smoke_complete, \n       aes(x = age_at_diagnosis, \n           y = cigarettes_per_day, \n           color = disease)) + \n  geom_point() +\n  scale_color_manual(values = c(\"red\", \n                                \"blue\", \n                                \"green\"))\n\n\n\n\n\n\n\n\n\n\nBe careful what you pipe to and from\nAn error came up where a data frame was being piped to a function that did not accept a data frame as an argument (it accepted a vector)\n\n# starwars data frame was loaded earlier with the ggplot2 package\n\nstarwars |&gt;  \n  dplyr::n_distinct(species) \n\nError in eval(expr, envir, enclos): object 'species' not found\n\n\n\nstarwars is a data frame.\ndplyr::n_distinct() only accepts a vector as an argument (check the help ?dplyr::n_distinct)\n\nSo we need to pipe a vector to the dplyr::n_distinct() function:\n\nstarwars |&gt; \n  dplyr::select(species) |&gt; \n  dplyr::n_distinct() \n\n[1] 38\n\n\ndplyr::select() accepts a data frame as its first argument and it return a vector (see the help ?dplyr::select) which we can then pipe to dplyr::n_distinct().\nThe %&gt;% or |&gt; takes the output of the expression on its left and passes it as the first argument to the function on its right. The class / type of output on the left needs to agree or be acceptable as the first argument to the function on the right.\n\n\nOther muddy points\n\nRemembering applicable functions. Troubleshooting.\n\n\nThis gets better with experience. You are all still very new to R so be patient with yourself.\n\n\nHow to organize all of the material to understand the structure of how the R language works, rather than to keep track of all of the commands in an anecdotal way.\n\n\nAgain, I think that this gets better with experience. Though the R language, being open source, a lot of syntax is package dependent. So you need to be careful that some of the syntax we use with dplyr and the tidyverse will be different in base R or in other packages. This is something that comes with open source software (compared to Stata or SAS). The good news is that learning to use packages sets you up to better learn newer (to you) packages down the road.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-5",
    "href": "survey_feedback_previous_years.html#week-5",
    "title": "Survey Feedback",
    "section": "Week 5",
    "text": "Week 5\n\ncase_when() vs ifelse()\nThe difference between case_when and ifelse\n\nifelse() is the base R version of tidyverse’s case_when()\nI prefer using case_when() since it’s easier to follow the logic.\ncase_when() is especially useful when there are more than two logical conditions being used.\n\nThe example below creates a binary variable for bill length (long vs not long) using both case_when() and ifelse() as a comparison.\n\nCompare the crosstabs of the two variables!\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(palmerpenguins)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill1 = case_when(\n      bill_length_mm &gt;= 45 ~ \"long\",\n      bill_length_mm &lt; 45 ~ \"not long\",\n    ),\n    long_bill2 = ifelse(bill_length_mm &gt;= 45, \"long\", \"not long\")\n  )\n\npenguins %&gt;% tabyl(long_bill1, long_bill2) %&gt;% \n  adorn_title()\n\n            long_bill2             \n long_bill1       long not long NA_\n       long        166        0   0\n   not long          0      176   0\n       &lt;NA&gt;          0        0   2\n\n\nBelow is an example using case_when() to create a categorical variable with 3 groups:\n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill3 = case_when(\n      bill_length_mm &gt;= 50 ~ \"long\",\n      bill_length_mm &lt;= 40 ~ \"short\",\n      TRUE ~ \"medium\"\n    ))\n\npenguins %&gt;% tabyl(long_bill3, long_bill1) %&gt;% \n  adorn_title()\n\n            long_bill1             \n long_bill3       long not long NA_\n       long         57        0   0\n     medium        109       76   2\n      short          0      100   0\n\n\n\nCreating a categorical variable with 3 groups can be done with ifelse(), but it’s harder to follow the logic:\n\n\npenguins &lt;- penguins %&gt;% \n  mutate(\n    long_bill4 = ifelse(\n      bill_length_mm &gt;= 50, \"long\",\n      ifelse(bill_length_mm &lt;= 40, \"short\", \"medium\")\n      ))\n\npenguins %&gt;% tabyl(long_bill3, long_bill4) %&gt;% \n  adorn_title()\n\n            long_bill4                 \n long_bill3       long medium short NA_\n       long         57      0     0   0\n     medium          0    185     0   2\n      short          0      0   100   0\n\n\n\n\nseparate()\nDifferent ways of using the function separate, it was a bit unclear that when to use one or the other or examples of my research data where it’ll be most relevant to use.\n\nChoosing the “best” way of using separate() is overwhelming at first.\nI recommend starting with the simplest use case with a string being specified in sep = \" \":\n\n\nseparate(data, col, into, sep = \" \")\n\n\nWhich of the various versions we showed to use depends on how the data being separated are structured.\nMost of the time I have a simple character, such as a space (sep = \" \") or a comma (sep = \",\") that I want to separate by.\nIf the data are structured in a more complex way, then one of the stringr package options might come in handy.\n\n\n\nhere::here()\nTSV files, very neat… But also, I got a bit confused when you did the render process around 22:00-23:00 minutes. Also, “here: and also”here” Directories/root directories. I was a bit confused about in what situations we would tangibly utilize this/if it is beneficial.\n\nGreat question! This is definitely not intuitive, which is why I wanted to demonstrate it in class.\nThe key is that\n\nwhen rendering a qmd file the current working directory is the folder the file is sitting in,\nwhile when running code in a file within RStudio the working directory is the folder where the .Rproj file is located.\n\n\nThis distinction is important when loading other files from our computer during our workflow, and why here::here() makes our workflow so much easier!\n\n\n\nwhat functions will only work within another function (generally)\n\nI’m not aware of functions that only work standalone within other functions. For example, the mean() function works on its own, but can also be used within a summarise().\n\n\nmean(penguins$bill_length_mm, na.rm = TRUE)\n\n[1] 43.92193\n\npenguins %&gt;% summarise(\n  m = mean(bill_length_mm, na.rm = TRUE)\n)\n\n# A tibble: 1 × 1\n      m\n  &lt;dbl&gt;\n1  43.9\n\n\n\nThat being said, a function has a set of parameters to be specified that are specific to that function.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-6-part-5-contd.",
    "href": "survey_feedback_previous_years.html#week-6-part-5-contd.",
    "title": "Survey Feedback",
    "section": "Week 6 (Part 5 contd.)",
    "text": "Week 6 (Part 5 contd.)\n\nacross()\nwhat exactly the across function does\n.fns, i.e. .fns=list, etc… I wasn’t really sure what that was achieving within across.\n\nThe across() function lets us apply a function to many columns at once.\nFor example, let’s say we want the mean value for every continuous variable in a dataset.\n\nThe code below calculates the mean for one variable in the penguins dataset using both base R and summarize().\nOne option to calculate the mean value for every continuous variable in the dataset is to repeat this code for the 4 other continuous variables.\n\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(gt)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n  long_bill1         long_bill2         long_bill3         long_bill4       \n Length:344         Length:344         Length:344         Length:344        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n\n  # base R\nmean(penguins$bill_length_mm, na.rm = TRUE)\n\n[1] 43.92193\n\n# with summarize\npenguins %&gt;% \n  summarize(mean(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  `mean(bill_length_mm, na.rm = TRUE)`\n                                 &lt;dbl&gt;\n1                                 43.9\n\n\n\nIn this case across() lets us apply the mean function to all the columns of interest at once:\n\n\npenguins %&gt;%\n  summarize(across(.cols = where(is.numeric), \n                   .fns = ~ mean(.x, na.rm = TRUE)\n                   )) %&gt;% \n  gt()\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\n43.92193\n17.15117\n200.9152\n4201.754\n2008.029\n\n\n\n\n\n\n\n\nThe .fns=list part of the across code is where we specify the function(s) that we want to apply to the specified columns.\n\nAbove we only specified one function (mean()), but we can specify additional functions as well, which is when we need to create a list to list all the functions we want to apply.\nBelow I apply the mean and standard deviation functions:\n\n\n\npenguins %&gt;%\n  summarize(across(.cols = where(is.numeric), \n                   .fns = list(\n                     mean = ~ mean(.x, na.rm = TRUE),\n                     sd = ~ sd(.x, na.rm = TRUE)\n                     ))) %&gt;% \n  gt()\n\n\n\n\n\n\n\nbill_length_mm_mean\nbill_length_mm_sd\nbill_depth_mm_mean\nbill_depth_mm_sd\nflipper_length_mm_mean\nflipper_length_mm_sd\nbody_mass_g_mean\nbody_mass_g_sd\nyear_mean\nyear_sd\n\n\n\n\n43.92193\n5.459584\n17.15117\n1.974793\n200.9152\n14.06171\n4201.754\n801.9545\n2008.029\n0.8183559\n\n\n\n\n\n\n\n\nIn general, lists are another type of R object to store information, whether data, lists of functions, output from regression models, etc. While concatenate is just a vector of values, lists are multidimensional. We will be learning more about lists in parts 7 and 8.\nYou can learn more about across() at its help file.\n\n\n\ncase_when() vs ifelse()\nstill a little confused on the difference between ifelse and casewhen, understand they are very similar but still confused on when it is best to use one over another\n\nThe two functions can be used interchangeably. * ifelse() is the original function from base R\n\ncase_when() is the user-friendly version of ifelse() from the dplyr package\n\nI recommend using case_when(), and it is what I use almost exclusively in my own work. My guess is that ifelse() was included in the notes since you might run into the function when reading R code on the internet.\nJust be careful that you preserve missing values when using case_when() as we discussed last time.\n\n\n\nfactor levels\nworking with factor levels doesn’t feel totally intuitive yet. I think that’s because I tend to get confused with anything involving a concatenated list.\n\nWorking with factor variables takes a while to get used to, and in particular with their factor levels.\nWe will be looking at more examples with factor variables in the part 6 notes. See sections 2.8 and 4.\nYou can think of a concatenated list(c(...)) as a vector of values or a column of a dataset. Concatenating lets us create a set of values, which we typically create to use for some other purpose, such as specifying the levels of a factor variable.\nPlease submit a follow-up question in the post-class survey if this is still muddy after today’s class!\n\n\n\npivoting tables\n\nDefinitely a tricky topic, and over half of the muddiest points were about pivoting tables.\nWe will be looking at more examples in part 6.\n\n\nHow pivot_longer() would work on very large datasets with many rows/columns\n\nIt works the same way. However the resulting long table will end up being much much longer.\nExtra columns in the dataset just hang out and their values get repeated (such as an age variable that is not being made long by) over and over again.\n\nWe will be pivoting a dataset in part 6 that has extra variables that are not being pivoted.\n\n\n\n\nTrying to visualize the joins and pivot longer/wider\n\nI recommend trying them out with small datasets where you can actually see what is happening.\nJoins: Our BERD workshop slides have another example that might visualize joins.\n\nSlide 18 shows to datasets x and y, and what the resulting joins look like.\nSlide 19 shows Venn diagrams of how the different joins behave.\n\nPivoting: There’s an example with a very small dataset in my (supplemental) notes from BSTA 511. The graphic that goes along with this is on Slide 28 from the pdf.\n\n\n\npivot_longer makes plotting more understandable in an analysis sense, which situations would call for pivot_wider?\n\nI tend to use pivot_longer() much more frequently. However, there are times when pivot_wider() comes in handy. For example, below is a long table of summary statistics created with group_by() and summarize(). I would use pivot_wider() to reshape this table so that I have columns comparing species or columns comparing islands.\n\n\npenguins %&gt;% \n  group_by(species, island) %&gt;%\n  summarize(across(.cols = bill_length_mm, \n                   .fns = list(\n                     mean = ~ mean(.x, na.rm = TRUE),\n                     sd = ~ sd(.x, na.rm = TRUE)\n                     )))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 4\n# Groups:   species [3]\n  species   island    bill_length_mm_mean bill_length_mm_sd\n  &lt;fct&gt;     &lt;fct&gt;                   &lt;dbl&gt;             &lt;dbl&gt;\n1 Adelie    Biscoe                   39.0              2.48\n2 Adelie    Dream                    38.5              2.47\n3 Adelie    Torgersen                39.0              3.03\n4 Chinstrap Dream                    48.8              3.34\n5 Gentoo    Biscoe                   47.5              3.08\n\n\n\n\nHow to use arguments of pivot longer.\n\nThe arguments of the pivot functions take some practice to get used to. I sometimes still pull up an example to remind me what I need to specify for the various arguments, such as the one mentioned above that I have used in workshops and classes.\n\nWe have not covered all the different arguments, and I recommend reviewing the help file and in particular the examples at the end of the page.\n\n\n\n\ngt::gt()\nThe gt::gt package does make the tables look fancier, how do we add labels to those to have them look nice as well?\n\nI highly recommend the gt webpage to learn more about all the different options to create pretty tables. Note the tabs at the top of the page for “Get started” and “Reference.”\nSee also section 3 of part 6 on “Side note about gt::gt()” for more on creating pretty tables.\n\n\n\nhere::here\nwould also love more examples of here() I am starting to understand it better but still am a little confused\nI am still having trouble getting here() to work consistently. I was going to ask during class, but I think I am just not understanding how to manually nest my files correctly so that “here” works. I am struggling to get that set up correct, and thus, struggling to use it.\n\nWe’ll have some more examples in class, but I recommend reaching out to one of us (instructors or TA) to help you troubleshoot here::here.\nHere are also some resources that might help\n\nhttps://here.r-lib.org/articles/here.html\nhttp://jenrichmond.rbind.io/post/how-to-use-the-here-package/\nhttps://github.com/jennybc/here_here\n\n\n\n\nClearest points\n\ngroup_by() function (n=3)\nsummarize() (n=2)\nacross() (n=1)\ncase_when() (n=1)\ndrop_na( ) (n=2)\nJoining tables (n=6)",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-7-part-6",
    "href": "survey_feedback_previous_years.html#week-7-part-6",
    "title": "Survey Feedback",
    "section": "Week 7 (Part 6)",
    "text": "Week 7 (Part 6)\n\nWhy we used full_join()\n\nWhy we used full_join() in the class example instead of the other join options\n\n\nIn this case both datasets being joined had the same ID’s, and thus it did not matter whether we used left_join(), right_join(), full_join() or inner_join(). All of these would’ve given the same results.\n\n\n\nVisualizing pivots and joins\n\npivot-longer is still hard for me to mentally visualize how it alters the dataset.\n\n\nI always struggle to visualize pivots and joins.\n\n\nReshaping data take lots of practice to get the hang of, and something where I still pause while coding to think through how it will work and how to code it. Especially for pivoting, I often refer back to existing code I am familiar with. It’s normal at this point to still be muddy on these topics. Keep practicing though and read through some more examples.\nIn the week 6 muddiest points I listed some additional resources for visualizing these.\nSee also Tidy Animated Verbs for visualizing joins and pivoting. The page also includes visualizing union(), intersect(), and set_diff().\nAnother great resource is the R for Epidemiology website.\n\nIt has sections on joins and pivoting.\n\nJessica also addressed pivoting in last year’s muddiest points.\n\nPlease come to office hours or set up a time to meet if this is still muddy after looking at these resources!\n\n\nmutate(factor ( ))\n\nmutate(factor ( )) problem we ran into in class where Emile posted on Slack.\n\nBelow is the code Emile posted on Slack (commented out):\n\n# data &lt;- data |&gt;\n#   mutate(timepoint = factor(timepoint,\n#                             levels = c(1, 2, 3),\n#                             labels = c(“1 month”,\n#                                          “6 months”,\n#                                          “12 months”)))\n\n\nAt this point we were working through the code of Section 2.8 in the Part 6 notes.\n\nLoad the mouse_data dataset we were working with:\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\nmouse_data &lt;- read_csv(here(\"data\", \"mouse_data_longitudinal_clean.csv\"))\nglimpse(mouse_data)\n\nRows: 96\nColumns: 18\n$ sid                                &lt;dbl&gt; 137, 137, 137, 138, 138, 138, 139, …\n$ strain                             &lt;chr&gt; \"C3H\", \"C3H\", \"C3H\", \"C3H\", \"C3H\", …\n$ trt                                &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ sex                                &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", …\n$ time                               &lt;chr&gt; \"tp1\", \"tp2\", \"tp3\", \"tp1\", \"tp2\", …\n$ normalized_bdnf_amygdala_pg_mg     &lt;dbl&gt; 492.4831, 275.1623, NA, 453.6635, 4…\n$ normalized_bdnf_cortex_pg_mg       &lt;dbl&gt; 720.0173, NA, 871.8286, 884.5668, N…\n$ normalized_bdnf_hypothalamus_pg_mg &lt;dbl&gt; NA, 1169.2845, NA, 1215.8147, 1078.…\n$ normalized_cd68_amygdala_pg_mg     &lt;dbl&gt; 988.9628, 574.0655, NA, 775.5970, 4…\n$ normalized_cd68_cortex_pg_mg       &lt;dbl&gt; 8.393707, NA, NA, 7.901366, NA, 8.8…\n$ normalized_cd68_hypothalamus_pg_mg &lt;dbl&gt; NA, 6800.870, NA, 4373.811, 4461.62…\n$ normalized_map2_cortex_pg_mg       &lt;dbl&gt; 352.9653, NA, 2693.9386, 1007.4147,…\n$ mirna1                             &lt;dbl&gt; 5.2630200, -0.0491371, -0.7367310, …\n$ mirna2                             &lt;dbl&gt; 1.6536200, -0.0773419, 0.1479940, -…\n$ learning_outcome                   &lt;dbl&gt; 3.52, 19.81, 2.44, 1.56, 14.48, 1.1…\n$ preference_obj1                    &lt;dbl&gt; 41.72205, 37.51387, 55.96768, 74.11…\n$ preference_obj2                    &lt;dbl&gt; 58.27795, 62.48613, 44.03232, 25.88…\n$ time_month                         &lt;chr&gt; \"1 month\", \"6 months\", \"12 months\",…\n\nmouse_data %&gt;% tabyl(time)\n\n time  n   percent\n  tp1 32 0.3333333\n  tp2 32 0.3333333\n  tp3 32 0.3333333\n\n\n\nThe goal was to create a factor variable of the character time point column called time with the levels 1 month, 6 months, and 12 months, instead of time’s values tp1, tp2, and tp3.\nThe code presented in class to accomplish this is below:\n\n\n# create time_month factor\nmouse_data &lt;- mouse_data %&gt;%\n  mutate(time_month = case_when(\n    time==\"tp1\" ~ \"1 month\",\n    time==\"tp2\" ~ \"6 months\",\n    time==\"tp3\" ~ \"12 months\"\n  ),\n  time_month = factor(time_month,\n                      levels = c(\"1 month\", \"6 months\", \"12 months\")))\n\n\nCompare the old and new time variables:\n\n\nmouse_data %&gt;% tabyl(time, time_month)\n\n time 1 month 6 months 12 months\n  tp1      32        0         0\n  tp2       0       32         0\n  tp3       0        0        32\n\n\n\nThe question arose as to whether we could include factor() in the same step as case_when() when creating time_month above, instead of having to write it out as a second separate line in the mutate().\nWhen using case_when(), we can do this as follows by piping the factor after the case_when():\n\n\nmouse_data &lt;- mouse_data %&gt;%\n  mutate(time_month2 = case_when(\n    time==\"tp1\" ~ \"1 month\",\n    time==\"tp2\" ~ \"6 months\",\n    time==\"tp3\" ~ \"12 months\"\n  ) %&gt;% factor(., levels = c(\"1 month\", \"6 months\", \"12 months\"))\n  )\n\nmouse_data %&gt;% tabyl(time_month, time_month2)\n\n time_month 1 month 6 months 12 months\n    1 month      32        0         0\n   6 months       0       32         0\n  12 months       0        0        32\n\n\n\nAnother option that is similar, is to enclose the case_when() within the factor():\n\n\nmouse_data &lt;- mouse_data %&gt;%\n  mutate(time_month3 = factor(\n    case_when(\n      time==\"tp1\" ~ \"1 month\",\n      time==\"tp2\" ~ \"6 months\",\n      time==\"tp3\" ~ \"12 months\"\n      ), \n    levels = c(\"1 month\", \"6 months\", \"12 months\")\n    ))\n\nmouse_data %&gt;% tabyl(time_month, time_month3)\n\n time_month 1 month 6 months 12 months\n    1 month      32        0         0\n   6 months       0       32         0\n  12 months       0        0        32\n\n\n\nlevels vs. labels\n\nEmile suggested using factor() on the time variable directly, and creating the new values using the labels option within factor():\n\n\nmouse_data &lt;- mouse_data %&gt;% \n  mutate(time_month4 = factor(time,\n                             levels = c(\"tp1\", \"tp2\", \"tp3\"),\n                             labels = c(\"1 month\", \"6 months\", \"12 months\")\n                             ))\n\nmouse_data %&gt;% tabyl(time_month, time_month4)\n\n time_month 1 month 6 months 12 months\n    1 month      32        0         0\n   6 months       0       32         0\n  12 months       0        0        32\n\n\n\nWhat is new her is that we have not previously discussed labels.\nYou can think of the levels as the input for the factor() function.\n\nIt’s how we specify what the different levels are for the variable we are converting to factor, as well as the order we want the levels to be in.\nIf we do not specify the levels, then R will automatically use the different values of the variable being converted and arrange them in alphanumeric order. Example:\n\n\n\nmouse_data &lt;- mouse_data %&gt;% \n  mutate(time_month5 = factor(time))\n\nmouse_data %&gt;% tabyl(time_month, time_month5)\n\n time_month tp1 tp2 tp3\n    1 month  32   0   0\n   6 months   0  32   0\n  12 months   0   0  32\n\n\n\nWhile levels is an input for the factor() function, labels is an output for the factor() function.\nThe values specified in labels are the new values for the levels:\n\n\n# time_month4 added labels\n# time_month5 did not add labels\n\nmouse_data %&gt;% tabyl(time_month4, time_month5)\n\n time_month4 tp1 tp2 tp3\n     1 month  32   0   0\n    6 months   0  32   0\n   12 months   0   0  32\n\nlevels(mouse_data$time_month4)\n\n[1] \"1 month\"   \"6 months\"  \"12 months\"\n\nlevels(mouse_data$time_month5)\n\n[1] \"tp1\" \"tp2\" \"tp3\"\n\n\n\nNote that both time_month4 and time_month5 started with the same levels.\nInstead of using the labels option within factor() (the base R way), we can also accomplish this by using fct_recode() from the forcats package (loaded as a part of tidyverse):\n\n\n# original tp levels:\nlevels(mouse_data$time_month5)\n\n[1] \"tp1\" \"tp2\" \"tp3\"\n\nmouse_data &lt;- mouse_data %&gt;% \n  mutate(time_month6 = fct_recode(time_month5, \n                            # new_name = \"old_name\"\n                                 \"1 month\" = \"tp1\", \n                                 \"6 months\" = \"tp2\", \n                                 \"12 months\" = \"tp3\"))\n\nlevels(mouse_data$time_month6)\n\n[1] \"1 month\"   \"6 months\"  \"12 months\"\n\nmouse_data %&gt;% tabyl(time_month6, time_month5)\n\n time_month6 tp1 tp2 tp3\n     1 month  32   0   0\n    6 months   0  32   0\n   12 months   0   0  32\n\n\n\nLearn more about fct_recode() here.\n\n\n\n\n%in%\n\n%in% command, I feel like I understand but have some confusion and think it might just be one of those things I have to work with/apply to fully understand\n\n\nWe’ve used the %in% function in some examples, but I don’t think we’ve discussed it in detail.\nThe %in% function is used to test whether elements of one vector are contained in another vector. It returns a logical vector indicating whether each element of the first vector is found in the second vector.\nBelow are some examples that ChatGPT generated (and I slightly edited).\n\n\n# Example 1: Using %in% with two numeric vectors\nx &lt;- c(1, 2, 3, 4, 5)\ny &lt;- c(2, 4, 6)\n\nx %in% y\n\n[1] FALSE  TRUE FALSE  TRUE FALSE\n\n# Example 2: Using %in% with two character vectors\nfruits &lt;- c(\"apple\", \"banana\", \"orange\", \"grape\")\nselected_fruits &lt;- c(\"banana\", \"grape\", \"kiwi\")\n\nselected_fruits %in% fruits\n\n[1]  TRUE  TRUE FALSE\n\n# Example 3: Using %in% with dataframe columns\nlibrary(tidyverse)\n\n# Create a dataframe\ndf &lt;- tibble(\n  ID = c(1, 2, 3, 4, 5),\n  fruit = c(\"apple\", \"banana\", \"orange\", \"grape\", \"kiwi\")\n)\n\ndf\n\n# A tibble: 5 × 2\n     ID fruit \n  &lt;dbl&gt; &lt;chr&gt; \n1     1 apple \n2     2 banana\n3     3 orange\n4     4 grape \n5     5 kiwi  \n\n# Filter rows where 'fruit' column contains values from selected_fruits\nselected_fruits &lt;- c(\"banana\", \"grape\", \"kiwi\")\n\ndf_filtered &lt;- df %&gt;%\n  filter(fruit %in% selected_fruits)\n\ndf_filtered\n\n# A tibble: 3 × 2\n     ID fruit \n  &lt;dbl&gt; &lt;chr&gt; \n1     2 banana\n2     4 grape \n3     5 kiwi  \n\n\n\n\nClearest points\n\nThis class was all really clear. It was helpful to be reviewing some of the things we learned last week.\n\n\nI appreciate the new codes on how to clean/reshape/combine messy data. I think that was the hardest parts to do in the other Biostatistics courses during projects.\n\n\nData cleaning\n\n\nMost of the data cleaning exercises.\n\n\ndifferent strategies to clean data sets\n\n\nThe data cleaning made a lot of sense but I think I will struggle with solving problems in a really inefficient way.\n\n\nEverything before Challenge 3\n\n\nmethods to merge datasets to create a table\n\n\ninner join and full join are the same if all vectors are the same.\n\n\nPivot\n\n\nggplot and how to code data in to display what we want to display\n\n\n\nOther comments\n\nIs there a difference between summarize (with z) and summarise (with s)?\n\nGreat question!\n\nIn English, summarize is American English and summarise is British English. * In R they work the same way. The reference page for summarise() lists them as synonyms.\nIn R code I see summarise more, and now keep mixing up which is American and which is British.\nIn general, R accepts both American and British English, such as both color and colour.\n\n\nThank you for the survey reminders! The pace of the class feels much better compared to the pace at the beginning of the term\n\nThanks for the feedback!\n\nI really enjoyed the walk through from start to finish of how to clean the data sheet and it really helped clear up many of the commands I was previously confused about\n\nThanks for the feedback! Glad the data wrangling walk through was helpful.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-8-part-7",
    "href": "survey_feedback_previous_years.html#week-8-part-7",
    "title": "Survey Feedback",
    "section": "Week 8 (Part 7)",
    "text": "Week 8 (Part 7)\n\nWhen loading a dataset, what does  mean?\nThis occurs when you use the data() function to load a data set from a package. Per the help on this function (?data):\n\ndata() was originally intended to allow users to load datasets from packages for use in their examples, and as such it loaded the datasets into the workspace .GlobalEnv. This avoided having large datasets in memory when not in use: that need has been almost entirely superseded by lazy-loading of datasets.\n\n\ndata(\"iris\")  # this doesn't actually load the data set, but makes it available for use\nhead(iris)    # Once it's used it will appear in the Environment as an object.\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\n\nChallenge # 2\nThis was where we created a function to load 3 data sets, clean them, and convert them to long format. These are tasks we’ve seen in previous classes. In this challenge, the main takeaway was to see the DRY (Don’t repeat yourself) concept at play. Instead of writing the code 3 times for each data set, we can create a function where we only write the cleaning code once, then use that function 3 times.\nReviewing the challenge solutions and taking more time to work through it on your own is a good idea. We went through it pretty quick in class. You won’t usually be limited on time to get a function like that to work. In practice, if it’s taking more time and too complicated, then it’s fine to duplicate code so that you know it’s working correctly. But, with very repetitive tasks, functions can make your code less prone to errors from copying and pasting.\nIf you have trouble getting your code to work for the challenges, office hours are great for helping to debug code. Else, sharing full code in an email or on Slack.\n\n\npurrr::pluck\nThere was a specific question:\n\npurrr::pluck seems really useful, I wonder if you can tell it to pluck a specific record_ID?\n\nThe short answer is no. Not a specific ID. But if you know the position of the specific ID then you could.\n\n# Load packages\nlibrary(tidyverse)\n\n# Create sample data\ndf &lt;- tibble::tibble(\n  id = c(\"0001\", \"0002\", \"0003\", \"0004\", \"0005\", \"0006\", \"0007\", \"0008\", \"0009\", \"0010\"), \n  sex = sample(x = c(\"M\", \"F\"), size = 10, replace = TRUE), \n  age = sample(x = 18:65, size = 10, replace = TRUE)\n  \n)\n\ndf\n\n# A tibble: 10 × 3\n   id    sex     age\n   &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n 1 0001  F        65\n 2 0002  M        33\n 3 0003  F        65\n 4 0004  M        51\n 5 0005  F        32\n 6 0006  M        31\n 7 0007  M        64\n 8 0008  M        33\n 9 0009  F        18\n10 0010  M        40\n\n# Say we want to extract ID 0003.\n\n# With purrr::pluck we need to know that it's in the 3rd row of the ID column\n\npurrr::pluck(df, \n             \"id\", \n             3)\n\n[1] \"0003\"\n\n# Gives an error\npurrr::pluck(df, \n             \"id\", \n             \"0003\")\n\nNULL\n\n# More than likely in this scenario, you would use a filter:\ndf |&gt; \n  dplyr::filter(id == \"0003\")\n\n# A tibble: 1 × 3\n  id    sex     age\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 0003  F        65\n\n\npurrr::pluck was created to work with deeply nested data structures. Not necessarily data frames; there’s probably a more appropriate function out there for the task.\n\n\nLists – general confusion\n\nWhat do we do with lists?\nUsing lists\n\nWe will get to work more with lists in Week 9 and get more opportunities to see how they are used.\nLists are more flexible and have the ability to handle various data structures which make them a powerful tool for organizing, manipulating, and representing complex data in R.\n\n\nLists – One bracket versus two brackets.\nOne bracket [ ] and two brackets [[ ]] serves different purposes, primarily when accessing elements in a data structure like vectors, lists, or data frames.\n\nOne Bracket [ ]:\n\nVectors:\nWhen used with a single bracket, you can use it to subset or extract elements from a vector.\n\n# Example with a vector\nmy_vector &lt;- c(1, 2, 3, 4, 5)\nmy_vector[3]  # Extracts the element at index 3\n\n[1] 3\n\n\n\n\nData Frames:\nWhen used with a data frame, it can be used to extract columns or rows.\n\n# Example with a data frame\n\ndf &lt;- tibble::tibble(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"), \n  age = c(25, 30, 22)\n  )\n\n# Extract the age column\ndf[\"age\"]\n\n# A tibble: 3 × 1\n    age\n  &lt;dbl&gt;\n1    25\n2    30\n3    22\n\n\n\n\n\nTwo Brackets [[ ]]:\n\nLists:\nWhen working with lists, double brackets are used to extract elements from the list. The result is the actual element, not a list containing the element.\n\n# Example with a list\nmy_list &lt;- list(1, \n                c(2, 3), \n                \"four\")\n\nmy_list[[2]]  # Extracts the second element (a vector) from the list\n\n[1] 2 3\n\n\nCompare to using []\n\nmy_list[2]\n\n[[1]]\n[1] 2 3\n\n\n[[]] returned the vector contained in that slot. [] returned a list containing the vector.\n\n\nNested Data Structures:\nFor accessing elements in nested data structures like lists within lists.\n\n# Example with a nested list\nnested_list &lt;- list(first = list(a = 1, b = 2), \n                    second = list(c = 3, d = 4))\n\nnested_list\n\n$first\n$first$a\n[1] 1\n\n$first$b\n[1] 2\n\n\n$second\n$second$c\n[1] 3\n\n$second$d\n[1] 4\n\nnested_list[[1]] # Extract the list contained in the first slot\n\n$a\n[1] 1\n\n$b\n[1] 2\n\nnested_list[[1]][[\"b\"]]  # Extracts the value associated with \"b\" in the first list\n\n[1] 2\n\n\nIn summary, one bracket [ ] is used for general subsetting, whether it’s extracting elements from vectors, columns from data frames, or specific elements from lists. On the other hand, two brackets [[ ]] are specifically used for extracting elements from lists and accessing elements in nested structures.\n\n\n\n\nHow and when to use curly curly within a function\n{ } will be covered in upcoming class lectures. We talked about it in Week 8 as a quick aside because a specific question came up. Not much detail was given intentionally as it is a separate topic for another day.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-9-part-7",
    "href": "survey_feedback_previous_years.html#week-9-part-7",
    "title": "Survey Feedback",
    "section": "Week 9 (Part 7)",
    "text": "Week 9 (Part 7)\n\nMatrices\n\nNot entirely sure how to read or make sense of matrices yet (maybe I should have payed more attention in algebra), like when we saw the structure of a matrix here in the class script: str(output_model$coefficients)\n\nIn R, matrices are two-dimensional data structures that can store elements of the same data type. They are similar to vectors but have two dimensions (rows and columns). They are widely used in various statistical and mathematical operations, making them a fundamental data structure in the R.\n\nBasic way to create matrices\n\n# Create a matrix with values filled column-wise\n(mat1 &lt;- matrix(1:6, nrow = 2, ncol = 3, byrow = FALSE))\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n# Create a matrix with values filled row-wise\n(mat2 &lt;- matrix(1:6, nrow = 2, ncol = 3, byrow = TRUE))\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n\n\n\n\nAccessing elements of a matrix\n\n# Accessing individual elements\nelement &lt;- mat1[1, 2]  # Row 1, Column 2\nelement\n\n[1] 3\n\n\n\n# Accessing entire row or column\nrow_vector &lt;- mat1[1, ]  # Entire first row\nrow_vector\n\n[1] 1 3 5\n\ncol_vector &lt;- mat1[, 2]  # Entire second column\ncol_vector\n\n[1] 3 4\n\n\n\n\nConvert to data.frame\n\nas.data.frame(mat1)\n\n  V1 V2 V3\n1  1  3  5\n2  2  4  6\n\n\n\nlibrary(tibble)\ntibble::as_tibble(mat1)\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\n# A tibble: 2 × 3\n     V1    V2    V3\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n# You can also name the columns (and the rows)\n\ncolnames(mat1) &lt;- c(\"a\", \"b\", \"c\")\nmat1\n\n     a b c\n[1,] 1 3 5\n[2,] 2 4 6\n\ntibble::as_tibble(mat1)\n\n# A tibble: 2 × 3\n      a     b     c\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n\n\n\n\nfor() loops\n\nStill a little confused about the for() loops…\n\nFor loops are a staple in programming languages, not just R. They are used when we want to repeat the same operation (or a set of operations) several times.\nThe basis syntax in R looks like:\n\nfor (variable in sequence) {\n  # Statements to be executed for each iteration\n}\n\nHere’s a breakdown of the components:\n\nvariable: This is a loop variable that takes on each value in the specified sequence during each iteration of the loop.\nsequence: This is the sequence of values over which the loop iterates. It can be a vector, list, or any other iterable object.\nLoop Body: The statements enclosed within the curly braces {} constitute the body of the loop. These statements are executed for each iteration of the loop.\n\n\nBasic example\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nFirst iteration manually:\n\ni &lt;- 1\nprint(i)\n\n[1] 1\n\n\nSecond iteration manually:\n\ni &lt;- 2\nprint(i)\n\n[1] 2\n\n\nEtc.\n\n\nAdapted from 1st edition of R for Data Science\nHere’s a tibble for an example\n\npacman::p_load(tidyverse)\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf\n\n# A tibble: 10 × 4\n         a      b       c       d\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1  0.243   0.135 -0.0225 -0.506 \n 2 -1.53    1.78   1.61    0.0146\n 3 -0.596  -1.42   1.10   -1.09  \n 4 -0.0251  0.957 -1.67    0.315 \n 5  2.03   -0.295 -0.467  -0.798 \n 6  0.0255 -0.752 -0.0718  1.15  \n 7  0.328  -0.605 -0.844   1.05  \n 8 -0.666   1.15   0.854   0.389 \n 9 -0.250  -0.662  0.382   0.157 \n10 -0.0180  0.568 -0.744   0.399 \n\n\nUsing a copy and paste method to calculate the mean of each column would look something like this:\n\nmedian(df$a)\n\n[1] -0.02155139\n\nmedian(df$b)\n\n[1] -0.07991065\n\nmedian(df$c)\n\n[1] -0.04719299\n\nmedian(df$d)\n\n[1] 0.2357017\n\n\nBut this breaks the rule of DRY (“Don’t repeat yourself”)\n\noutput &lt;- c()  # vector to store the results of the for loop\n\nfor (i in seq_along(df)) {\n  \n  output[i] &lt;- median(df[[i]])\n  \n}\n\noutput\n\n[1] -0.02155139 -0.07991065 -0.04719299  0.23570170\n\n\nFor loops in R are commonly used when you know the number of iterations in advance or when you need to iterate over a specific sequence of values. While for loops are useful, R also provides other ways to perform iteration, such as using vectorized operations (example below) and functions from the apply family (not covered). It’s often recommended to explore these alternatives when working with R for better code efficiency and readability.\n\n# Creating two vectors\nvector1 &lt;- c(1, 2, 3, 4, 5)\nvector2 &lt;- c(6, 7, 8, 9, 10)\n\n# Vectorized addition\nresult_addition &lt;- vector1 + vector2\nresult_addition\n\n[1]  7  9 11 13 15\n\n# With a for loop\nresult_addition_for_loop &lt;- c()\n\nfor (i in 1:length(vector1)) {\n  \n  result_addition_for_loop[i] &lt;- vector1[i] + vector2[i]\n  \n}\n\nresult_addition_for_loop\n\n[1]  7  9 11 13 15\n\n\n\n\n\nna.rm vs na.omit\n\nIs there a difference between na.rm and na.omit?\n\nYes, there is a difference. In R, they are used in different context.\n\nna.rm (Remove)\n\nna.rm is an argument found in various functions (e.g. mean(), sum(), etc.) that allows you to specify whether missing values (NA or NaN) should be removed before performing the calculation.\nFrom the help for mean() (?mean): a logical evaluating to TRUE or FALSE indicating whether NA values should be stripped before the computation proceeds.\n\n# A vector with NA values\nvalues_with_na &lt;- c(1, 2, 3, NA, 5)\n\nmean(values_with_na, na.rm = FALSE)  # Result will be NA\n\n[1] NA\n\n# Excluding NA values\nmean(values_with_na, na.rm = TRUE)  # Result will be (1+2+3+5)/4 = 2.75\n\n[1] 2.75\n\n\n\nna.omit (Omit missing)\n\nna.omit is a function that can be used to remove rows with missing values (NA) from a data frame or matrix.\n\n# Creating a data frame with NA values\ndf &lt;- data.frame(A = c(1, 2, NA, 4), B = c(5, NA, 7, 8))\n\n# NAs in the columns of the data frame\ndf\n\n   A  B\n1  1  5\n2  2 NA\n3 NA  7\n4  4  8\n\n# Using na.omit to remove rows with NA values\ndf |&gt; \n  na.omit()\n\n  A B\n1 1 5\n4 4 8\n\n\n\n\npurrr::map()\n\nI am still a little foggy on the formatting of purrrmap and how to utilize it effectively.\n\nThe purrr::map function is used to apply a specified function to each element of a list or vector, returning the results in a new list.\n\nBasic Syntax:\n\npurrr::map(.x, .f, ...)\n\n\n.x: The input list or vector.\n.f: The function to apply to each element of .x.\n...: Additional arguments passed to the function specified in .f.\n\n\n\nKey Features:\n\nConsistent Output:\n\nmap returns a list, ensuring a consistent output format regardless of the input structure.\n\nFunction Application:\n\nThe primary purpose is to apply a specified function to each element of the input .x.\n\nFormula Interface:\n\nSupports a formula interface (~) for concise function specifications.\n\npurrr::map(.x, ~ function(.))\n\n\n\nExample:\n\n# Sample list\nmy_list &lt;- list(a = 1:3, \n                b = c(4, 5, 6), \n                c = rnorm(n = 3))\n\nmy_list\n\n$a\n[1] 1 2 3\n\n$b\n[1] 4 5 6\n\n$c\n[1]  0.09890692  0.99882353 -0.11133133\n\n# Using map to square each element in the list\nsquared_list &lt;- purrr::map(.x = my_list, \n                           .f = ~ .x ^ 2)\n\nsquared_list\n\n$a\n[1] 1 4 9\n\n$b\n[1] 16 25 36\n\n$c\n[1] 0.009782579 0.997648452 0.012394664\n\n\nIn this example, the map function applies the squaring function (~ .x ^ 2) to each element of the input list my_list. The resulting squared_list is a list where each element is the squared version of the corresponding element in my_list.\nThe purrr::map function is particularly useful when working with lists and helps to create cleaner and more readable code, especially in cases where you want to apply the same operation to each element of a collection.\n\n\n\nGeneral references\n\nIs there a good dictionary type document with “R language” or very basic function descriptions? … find it difficult to know what functions I need because it is hard to recall their name or confuse it with a different function.\n\n\nR Documentation (Built-in Help): R itself provides built-in documentation that you can access using the help() function or the ? operator. For example, to get help on the mean() function, you can type help(mean) or ?mean in the R console.\nR Manuals and Guides: The official R documentation, including manuals and guides, is available on the R Project website: R Manuals.\nR Packages Documentation: Many R packages come with detailed documentation. You can find documentation for a specific package by visiting the CRAN website (Comprehensive R Archive Network) and searching for the package of interest.\nOnline Resources: Websites like RDocumentation provide a searchable database of R functions along with their documentation. You can search for a specific function and find details on its usage and parameters.\nRStudio cheatsheets\nBase R cheatsheet\nR: A Language and Environment for Statistical Computing: Reference Index\nCRAN Task Views\nPart 3 section on getting help with errors.\nBooks like “R for Data Science” by Hadley Wickham\nWhen you use a function or learn to use it, make notes to yourself using Google Doc or OneNote or something similar.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-10-part-8",
    "href": "survey_feedback_previous_years.html#week-10-part-8",
    "title": "Survey Feedback",
    "section": "Week 10 (Part 8)",
    "text": "Week 10 (Part 8)\n\nConfusion on details of purrr::map()\npurrr::map() applies a function to each element of a vector or list and returns a new list where each element is the result of applying that function to the corresponding element of the original vector or list.\n\nmap(.x, .f, ..., .progress = FALSE)\n\n\n.x the vector or list that you operate on\n.f the function you want to apply to each element of the input vector or list. This function can be a built-in R function, a user-defined function, or an anonymous function defined on the fly.\n\n\nSimple example\n\nlibrary(tidyverse)\n\n# Example list\nnumbers &lt;- list(1, 2, 3, 4, 5)\nnumbers\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] 5\n\n# Using map to square each element of the list\nsquared_numbers &lt;- purrr::map(.x = numbers, \n                              .f = ~ .x ^ 2)\n\nIn this example: - numbers is a list containing numbers from 1 to 5. - ~ .x ^ 2 is an anonymous function that squares its input. - map() applies this anonymous function to each element of the numbers list, resulting in a new list where each element is the square of the corresponding element in the original list.\nAfter executing this code, the squared_numbers variable will contain the squared values of the original list:\n\nsquared_numbers\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\n\n\n\n\nExample with a list of data frames\nSuppose we have a list of data frames where each data frame represents the sales data for different products. We want to calculate the total sales for each product across all the data frames in the list.\n\n# Sample list of data frames\nsales_data &lt;- list(\n  product1 = data.frame(month = 1:3, sales = c(100, 150, 200)),\n  product2 = data.frame(month = 1:3, sales = c(120, 180, 220)),\n  product3 = data.frame(month = 1:3, sales = c(90, 130, 170))\n)\n\nsales_data\n\n$product1\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n$product2\n  month sales\n1     1   120\n2     2   180\n3     3   220\n\n$product3\n  month sales\n1     1    90\n2     2   130\n3     3   170\n\n\nCreate a function `and apply it to each slot insales_data` list:\n\n# Function to calculate total sales for each data frame\ncalculate_total_sales &lt;- function(df) {\n  total_sales &lt;- sum(df$sales)\n  return(total_sales)\n}\n\n# Applying the function to each data frame in the list\ntotal_sales_per_product &lt;- purrr::map(.x = sales_data, \n                                      .f = calculate_total_sales)\n\nIn this example: - sales_data is a list containing three data frames, each representing the sales data for a different product. - calculate_total_sales() is a function that takes a data frame as input and calculates the total sales for that product. - map() applies the calculate_total_sales() function to each data frame in the sales_data list, resulting in a new list total_sales_per_product, where each element is the total sales for a specific product across all months.\nAfter executing this code, the total_sales_per_product variable will contain the total sales for each product:\n\ntotal_sales_per_product\n\n$product1\n[1] 450\n\n$product2\n[1] 520\n\n$product3\n[1] 390\n\n\nSo, total_sales_per_product is a named list where each element represents the total sales for a specific product across all the data frames in the original list.\n\n\n\npurrr::reduce()\n\nHow does it compare to purrr::map()?\nThe big difference between map() and reduce() has to do with what it returns:\n\nmap() usually returns a list or data structure with the same number as its input; The goal of reduce() is to take a list of items and return a single object.\n\nSee the purrr cheatsheet.\n\n\nSimple example\n\n# Example vector\nnumbers &lt;- c(1, 2, 3, 4, 5)\nnumbers\n\n[1] 1 2 3 4 5\n\n# Using reduce to calculate cumulative sum\ncumulative_sum &lt;- purrr::reduce(.x = numbers, \n                                .f = `+`)\n\nIn this example: - numbers is the vector we want to operate on. - The function + is used as the operation to perform at each step of reduction, which in this case is addition. - reduce() will start by adding the first two elements (1 and 2), then add the result to the third element (3), and so on, until all elements have been processed.\nAfter executing this code, the cumulative_sum variable will contain the cumulative sum of the numbers:\n\ncumulative_sum\n\n[1] 15\n\n\nThe steps are as follows:\n\n(cum_numbers &lt;- numbers[1])\n\n[1] 1\n\n(cum_numbers &lt;- cum_numbers + numbers[2])\n\n[1] 3\n\n(cum_numbers &lt;- cum_numbers + numbers[3])\n\n[1] 6\n\n(cum_numbers &lt;- cum_numbers + numbers[4])\n\n[1] 10\n\n(cum_numbers &lt;- cum_numbers + numbers[5])\n\n[1] 15\n\n\n\n\nWith data frames\nUsing our sales data list from above\n\nsales_data\n\n$product1\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n$product2\n  month sales\n1     1   120\n2     2   180\n3     3   220\n\n$product3\n  month sales\n1     1    90\n2     2   130\n3     3   170\n\n\nWe can combined the data sets in the list with reduce() and bind_rows()\n\n# Using an anonymous function, note bind_rows takes 2 arguments.\ncombined_sales_data &lt;- purrr::reduce(.x = sales_data, \n                                     .f = function(x, y) bind_rows(x, y))\n\n\n# Using a named function\ncombined_sales_data &lt;- purrr::reduce(.x = sales_data, \n                                     .f = dplyr::bind_rows)\n\nIn this example: - We use an anonymous function within reduce() that takes two arguments x and y, representing the accumulated result and the next element in the list, respectively. - Inside the anonymous function, we use bind_rows() to combine the accumulated result x with the next element y, effectively stacking them on top of each other. - reduce() applies this anonymous function iteratively to the list of data frames, resulting in a single data frame combined_sales_data that contains the combined sales data for all products.\n\ncombined_sales_data\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n7     1    90\n8     2   130\n9     3   170\n\n\nDoing this in steps:\n\n(cum_sales_data &lt;- dplyr::bind_rows(sales_data[[1]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n\n(cum_sales_data &lt;- dplyr::bind_rows(cum_sales_data, \n                                    sales_data[[2]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n\n(cum_sales_data &lt;- dplyr::bind_rows(cum_sales_data, \n                                    sales_data[[3]]))\n\n  month sales\n1     1   100\n2     2   150\n3     3   200\n4     1   120\n5     2   180\n6     3   220\n7     1    90\n8     2   130\n9     3   170\n\n\n\n\nExamples of reduce\n\nPretty involved example from Maelle Salmon, but good practice\nTidyverse reference with examples\nR for Data Science, First Edition\nAnother exmple blog post\n\n\n\n\nList.files function\nthe list.files() function is used to obtain a character vector of file names in a specified directory. Here’s a breakdown of how it works and its common parameters:\n\nDirectory Path: The primary argument of list.files() is the path to the directory you want to list files from. If not specified, it defaults to the current working directory.\nPattern Matching: pattern is an optional argument that allows you to specify a pattern for file names. Only file names matching this pattern will be returned. This can be useful for filtering specific types of files.\nRecursive Listing: If recursive = TRUE, the function will list files recursively, i.e., it will include files from subdirectories as well. By default, recursive is set to FALSE.\nFile Type: The full.names argument controls whether the returned file names should include the full path (if TRUE) or just the file names (if FALSE, the default).\nCharacter Encoding: You can specify the encoding argument to handle file names with non-ASCII characters. This argument is especially useful on Windows systems where file names may use a different character encoding.\n\nHere’s a simple example demonstrating the basic usage of list.files():\n\n# List files in the current directory\nfiles &lt;- list.files()\n\n# Print the file names\nprint(files)\n\n [1] \"_extensions\"                             \n [2] \"_quarto.yml\"                             \n [3] \"about.qmd\"                               \n [4] \"BSTA_526_W25.Rproj\"                      \n [5] \"data\"                                    \n [6] \"docs\"                                    \n [7] \"function_week\"                           \n [8] \"function_week.qmd\"                       \n [9] \"function_week0.qmd\"                      \n[10] \"images\"                                  \n[11] \"index.qmd\"                               \n[12] \"minty_adapt.scss\"                        \n[13] \"readings\"                                \n[14] \"readings.qmd\"                            \n[15] \"resources\"                               \n[16] \"schedule.qmd\"                            \n[17] \"styles.css\"                              \n[18] \"survey_feedback_previous_years_files\"    \n[19] \"survey_feedback_previous_years.qmd\"      \n[20] \"survey_feedback_previous_years.rmarkdown\"\n[21] \"syllabus.qmd\"                            \n[22] \"weeks\"                                   \n[23] \"weeks.qmd\"                               \n\n\nThis will print the names of all files in the current working directory.\n\n#| eval: false\n\n# List CSV files in a specific directory\ncsv_files &lt;- list.files(path = \"path/to/directory\", pattern = \"\\\\.csv$\")\n\n# Print the CSV file names\nprint(csv_files)\n\ncharacter(0)\n\n\nThis will print the names of all CSV files in the specified directory.\nOverall, list.files() is a handy function for obtaining file names within a directory, providing flexibility through various parameters for customization according to specific needs, such as filtering by pattern or handling file names with non-standard characters.\nNOTE You need to pay attention to your working directory and your relative file paths. See Week 2 or 3 (?) about here package and the discussion about files paths. Best to always use Rprojects and the here package.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "weeks/week_06.html#topics-part-6",
    "href": "weeks/week_06.html#topics-part-6",
    "title": "Week 6",
    "section": "Topics (Part 6)",
    "text": "Topics (Part 6)\n\nPractice working with real data\nPractice joining and pivoting\nPractice ggplot and Learn more geometries\nPractice modifying factor levels\nLearn new options for personalizing tables"
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-1-1",
    "href": "survey_feedback_previous_years.html#week-1-1",
    "title": "Survey Feedback",
    "section": "Week 1",
    "text": "Week 1\n\nMuddiest points\n\nClass logistics\n\nWill there be presentation slides in future classes, or is everything embedded into the quarto/html files for all lectures?\n\nThe material will primarily be in quarto/html files and not slides.\n\nSpecifics of what topics will be covered exactly. * I don’t have a list of all the specific functions we will be covering, but you are welcome to peruse the BSTA 504 webpage from Winter 2023 to get more details on topics we will be covering. We will be closely following the same class materials.\nIdentifying which section of the code we were discussing during the lecture\n\nThanks for letting me know. I will try to be clearer in the future, and also jump around less. Please let me know in class if you’re not sure where we are at.\n\nThe material covered towards the end of the class felt a bit difficult to keep up with. I wish we would have been told to read the materials from Week 1 (or at least skim them) ahead of Day 1, because I quickly lost track of the conversation when shortcuts were used super quickly, for example, or when we jumped from chunks of code to another topic without reflecting on them. I still had 70% of the material down and I wrote great notes during the discussion (which I later filled in with the script that was on the class website), but I think it the beginner/intermediate programming lingo that was used to explain ideas here confused me at times. Thus, I struggled to keep up with discussions around packages / best coding practices, especially when they were not mentioned directly on the script (where I could follow along!).\n\nThanks for the feedback. In future years, we will reach out to students before the term to let them know about the readings to prepare for class. Please let us know if there is lingo we are using that you are not familiar with. Learning R and coding is a whole new language!\n\n\n\n\nRStudio\n\nI have trouble thinking through where things are automatically downloaded, saved, and running from. I can attend office hours for this!\n\nOffice hours are always a great idea. I do recommend paying close attention to where files are being saved when downloading and preferably specifying their location instead using the default location. Having organized files will make working on complex analyses much easier.\n\nHow to read the course material in R. While it made sense in real time it may be difficult when going back over the material.\n\nGetting used to reading code and navigating the rendered html files takes a while, and is a part of learning R. Figuring out how to take notes for yourself that works for you is also a learning curve. I recommend taking notes in the qmd files as we go through them in class. After class you can summarize and transfer key points to other file formats that you are more used to using. I personally have a folder in my Google drive filled with documents on different R programming topics. It started with one file, and then eventually expanded to multiple files on different topics in an attempt to organize my notes better. Whenever I learn something new (such as an R function or handy R package) that I want to keep for future reference, I add to them with links to relevant webpages and/or filenames and locations of where I used them.\n\n\n\n\nCode\n\nWhat does the pacman package do? I have it installed but I’m not sure what it is actually used for.\n\nI didn’t go into pacman in Day 1. The p_load() function from the pacman package (usually run as pacman::p_load()) lets you load many packages at once without separately using the library() function for each individually.\nAn added bonus is that by default it will install packages you don’t already have, unless you specify install = FALSE.\nAnother option is to set update = TRUE so that it will automatically update packages. I do not use this option though since sometimes updating packages causes conflicts with other packages or older code.\nYou can read more about the different options in the documentation. This Medium article also has some tips on using pacman.\n\nThe part on when to load in packages once they’ve already been loaded in - like for example would it be good to put that as a step in our homework 1 .qmd at the top? Or not necessary since they’re already loaded in to R Studio from the work we did in class yesterday? What would happen if we try to load them in and they were already loaded in, would the .qmd file not render and show an error?\n\nI always load my packages at the very top of the .qmd files, usually in the first code chunk (with the setup label). If you still have a previous R session open, then yes you don’t need to load the packages again to run code within RStudio. However, when a file is rendered it starts with an empty workspace, which is why our qmd file must include code that loads the packages (either using library() or pacman::p_load(). We don’t have to load packages at the beginning of the file, just before we have code that depends on the packages being used.\n\nI didn’t understand the part where we talked about num, char, logical combinations (line 503).\n\nThe content of the objects char_logical, num_char, num_logical, and tricky were designed specifically to be confusing and thus make us aware of how R will decide to assign the data type when a vector is a mix of data types. Some key takeaways are below. Let me know if you sitll have questions about this.\n\nNumbers and logical/boolean (TRUE, FALSE) do not have double quotes around them, but character strings do. If you add double quotes to a number or logical, then R will treat it as a character string.\nIf a vector is a mix of numbers and character strings, then the data type of the vector is character.\nIf a vector is a mix of numbers and logical, then the data type of the vector is numeric and the logical value is converted to a numeric value (TRUE=1, FALSE=0).\nIf a vector is a mix of character strings and logical, then the data type of the vector is character and the logical value is converted to a character string and no longer operates as a logical (i.e. no longer equal to 1 or 0).\n\n\nLines 614-619, confused what the ratio means there. Could you go over the correct code (or options of the correct code) for challenge 5?\n\nThe code 1:4 or 6:9 creates sequences of integers starting with the first specified digit and ending at the last specified digit. For example, 1:4 is the vector with the digits 1 2 3 4. You can also create decreasing sequences by making the first number the bigger one. For example, 9:7 is the vector 9 8 7.\nChallenge 5:\n\nmore_heights_complete &lt;- na.omit(more_heights)\nmedian(more_heights_complete)\nYou could also get the median of more_heights without first removing the missing values with median(more_heights, na.rm = TRUE).\n\n\nhow to count the TRUE values in a logical vector\n\nTRUE is equal to 1 in R (and FALSE is equal to 0), and the function sum() adds up the values in a vector. Thus, sum(TRUE, FALSE, TRUE) is equal to 2. Similarly, sum(TRUE, FALSE, 5) is equal to 6.\nThe way I used it in class though is by counting how many values in the vector z (which was 7 9 11 13) are equal to 9. To do that I used the code sum(z == 9). Breaking that down, the code inside the parentheses z == 9 is equal to FALSE TRUE FALSE FALSE since the == means “equals to” in R.\nYou can read up more on boolean and logical operators at the R-bloggers post.\n\n\n\n\n\nClearest Points\nThank you for the feedback!\n\nClass logistics\n\nSyllabus/course structure\nThe syllabus review.\nOverall expectations and course flow\nIntroduction to the class (first half of the class); conversation around syllabus; and the Quarto introduction\n\n\n\nQuarto\n\nHow to create and edit a Quarto document in RStudio.\nThe differences between quarto and markdown\nrmarkdown is no more, quarto it is!\n\n\n\nCoding\n\nHaving code missing and fixing it in front of the class was helpful in troubleshooting.\nJust running through all the commands was very clear and easy to follow\nBasic R set up for quarto and introduction to R objects, vectors, etc.\nIntroduction, functions, and explanations was the clearest for me.\nClassification of the objects in logical, character, and numeric\nNot necessarily a point, but I really liked when we were encouraged to use the shortcut keys for various commands on R and other little things like switching code between console vs inline , I have used R before for a class briefly but I never knew all these ways by which I can save time and be efficient while writing a code.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "function_week/01-func.html",
    "href": "function_week/01-func.html",
    "title": "Function of the Week: EXAMPLE",
    "section": "",
    "text": "In this document, I will introduce the slice() function and show what it’s for.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(penguins)\n\n\n\nSay you want the first 7 rows of a table. Well, slice() is an easy way to do that. The slice() function accepts two arguments: The first is the dataset, and the second is the range of values you want to extract.\n\nslice(penguins, 1:7)\n\n# A tibble: 7 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n7 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nslice() is much more helpful in a tidy workflow, so you can see the first few rows of the data when you’re processing. This is really helpful when you’re building up a pipeline and need to show intermediate output without showing the entire table.\n\npenguins %&gt;%\n  slice(1:7)\n\n# A tibble: 7 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n7 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\nYes, when you need to just show part of a table as an example, slice() can come in handy. I don’t use it everyday, but it can come in handy."
  },
  {
    "objectID": "function_week/01-func.html#what-is-it-for",
    "href": "function_week/01-func.html#what-is-it-for",
    "title": "Function of the Week: EXAMPLE",
    "section": "",
    "text": "Say you want the first 7 rows of a table. Well, slice() is an easy way to do that. The slice() function accepts two arguments: The first is the dataset, and the second is the range of values you want to extract.\n\nslice(penguins, 1:7)\n\n# A tibble: 7 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n7 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nslice() is much more helpful in a tidy workflow, so you can see the first few rows of the data when you’re processing. This is really helpful when you’re building up a pipeline and need to show intermediate output without showing the entire table.\n\npenguins %&gt;%\n  slice(1:7)\n\n# A tibble: 7 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n7 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "function_week/01-func.html#is-it-helpful",
    "href": "function_week/01-func.html#is-it-helpful",
    "title": "Function of the Week: EXAMPLE",
    "section": "",
    "text": "Yes, when you need to just show part of a table as an example, slice() can come in handy. I don’t use it everyday, but it can come in handy."
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-1-2",
    "href": "survey_feedback_previous_years.html#week-1-2",
    "title": "Survey Feedback",
    "section": "Week 1",
    "text": "Week 1\n\nPacing\nMean 3.18, IQR [3,3] so, that’s a good sign, though there was one comment it went a little fast. I admittedly was trying to cram in a lot of basics all at once, so I’ll try to go a touch slower with the hard things.\n\n\nMuddiest Points\nRemember, all of this is anonymous. I don’t post everything everyone says on here, but I do read them all and think about how to improve the class based on what everyone says.\n\nBoolean data, until you explained it\n\nWe will talk more about boolean data in class 2, I kind of rushed the intro to that but we’ll definitely see more examples!\n\ndefault arguments\n\nI added this one, I want to make sure to show you the help in R and how we know what the “default” arguments are, that we don’t need to specify.\n\nremoving missing values\n\nYes this is a confusing thing in R, one point to remember is the difference between a function like na.omit() and an argument like na.rm = TRUE which sets the missing data behavior within a specific function like mean().\n\nmyvec &lt;- c(1, NA, 3)\n# removes missing values, does not save your work!\nna.omit(myvec)\n\n[1] 1 3\nattr(,\"na.action\")\n[1] 2\nattr(,\"class\")\n[1] \"omit\"\n\n# removes missing values, overwrites the object/variable myvec after removing them\nmyvec &lt;- na.omit(myvec)\n\n\nmyvec &lt;- c(1, NA, 3)\n# default behavior is to include NA in the computation\nmean(myvec)\n\n[1] NA\n\n# specifies that we want to get rid of NA first\nmean(myvec, na.rm = TRUE)\n\n[1] 2\n\n# different functions have different arguments to handle missing data\n# see ?cor for help and the explanation of the use argument\nvec1 &lt;- c(1, NA, 2, 3)\nvec2 &lt;- c(2, 3, NA, 4)\ncor(vec1, vec2)\n\n[1] NA\n\ncor(vec1, vec2, use = \"pairwise.complete.obs\")\n\n[1] 1\n\n# cor(vec1, vec2, use = \"all.obs\") # this throws an error, why?\n\n\nData types and vectors. It was clear, however, when I watched the class recording.\n\nWe will go over this again in class 2 when we talk about data!\n\nWhile I was reading the materials about vectors and variables, I’m still not very clear on the differences between vectors and variables. For instance, when we concatenate a list of regions (example from book) and create a vector named “region.” It sounds similar to how we assign values or characters to create a variable\n\nThis is a great point, and I tend to be a little lax with the definitions of some of these terms so apologies if it is confusing.\nI would say a variable is the same as an object in R. It is the name of something that we save and that we can see in our environment tab. That means it could be a vector, a data set, a list, a unique object type – all data types we will talk about in the coming classes.\nI also use the word “variable” when talking about columns of a data set or data frame, though. Therefore, it’s not a precise word and I’m sorry I use it so much!\nA vector is a specific type of object in R. It has a length and a class/type. It does not have a “width” like a data frame does (we will talk about these in class 2). We will also talk about types or classes of vectors (character, numeric, boolean) a bit more in these classes.\nFor a more thorough introduction, read R for Data Science Vector. If you want a rather advanced treatment of data types, see Advanced R.\nAs far as naming vectors or data, we often call them something that we can easily remember or make sense of. I think that also can cause confusion though, in the regions example.\nThis all make more sense once we talk about data frames, which contain vectors as columns!\n\npackages - why did my R crash?\n\nUgh I’m so sorry and I don’t have a clear idea. My best guess is that there were older packages installed and for some reason pacman::p_load tried to install packages without installing their dependencies first packages that the installed package relies on to work, and often need at least a certain version. Perhaps if you don’t update your packages all that often, install.packages() is the safer option?\n\nThe options for code blocks in r markdown\n\nI didn’t talk about this much yet, but I will keep showing examples of this. In the meantime, here are some good references, that I often have to go back to because I forget most of them most of the time:\nChunk options long list\nR markdown book, chunk options chapter\nI will also try to mention global options in class 2 as well.\n\nhow to also have an output below my code chuck as well\n\nI’ll talk about this again/more as well. This is a YAML option, and can be set using the “gear” icon next to the “Knit” button at the top of an Rmd (Chunk Output Inline vs Chunk Output Console). I think we can’t have it both ways. Also note that table output will look different from interactive R markdown and knitted R markdown sometimes. That can be a point of confusion. You can also change how that looks in “Output Options” from that gear dropdown menu (General -&gt; print data frames as:)\n\nR markdown in general, also R studio projects\n\nUnderstandable, I threw a lot of new stuff at most of you, and I’ll focus more on these things in class 2! I haven’t shown you the full benefits of using Rstudio projects yet because we haven’t started working with data. But hopefully class 2 and 3 it will become a bit more clear.\n\n\nClearest Points\nLots of things here I’m not including, but, thank you for all of it!\n\nConcatenate! I have never known what c() stood for!\n\nIt’s a weird one, for sure!\n\nFirst time real exposure to R, so I REALLY was amazed by knitting the Rmd and how the class content was all “interactively” set in the Rmd.\n\nIt’s one of the main reasons why I just start using Rmd right away, because it’s pretty neat. It might cause more headaches later because it takes time getting used to, but it’s worth it to me.\n\n\nOther messages, just a selection\nLots of you liked having challenges. Sometimes I get carried away adding too much instruction because there is so much I want to show you, so I hope I provide enough time for challenges this year.\n\ni’ve had R experience but it’s difficult for me to quickly learn and adapt to it. I understand how to use it but have difficulty creating things like tables or organizing data. I’m hoping by the end of this course, i’ll be able to gain more knowledge to allow me to do those types of task.\n\nYou are my perfect audience, these are my goals, too!\n\nAfter 2 years of just sort of flinging myself at R willy-nilly, the first class showed me a lot of tips for using R that have already made my life easier.\n\nSo happy to hear it!",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-2-1",
    "href": "survey_feedback_previous_years.html#week-2-1",
    "title": "Survey Feedback",
    "section": "Week 2",
    "text": "Week 2\n\nMuddiest Points\n\nthe benefits of tibble vs data frame and when to use which?\n\nIn this class we will always use tibble. Just remember that an object can be multiple types. A tibble is a data frame, but not vice versa. A tibble is really a data frame with “perks”. See this explanation from the tibble 1.0 package release\n\nThere are two main differences in the usage of a data frame vs a tibble: printing, and subsetting.\n\n\nTibbles have a refined print method that shows only the first 10 rows, and all the columns that fit on screen. This makes it much easier to work with large data. In addition to its name, each column reports its type, a nice feature borrowed from str():\n\n\nlibrary(tidyverse)\n\nclass(mtcars)\n\n[1] \"data.frame\"\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\nmtcars_tib &lt;- as_tibble(mtcars)\nclass(mtcars_tib)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nmtcars_tib\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nAnother interesting difference is that tibbles don’t have row names, but a lot of built in data.frames in R do. But rownames are hard to get out. So, when you make a tibble of a data.frame you can tell the function to use the rownames as a column:\n\nmtcars_tib &lt;- as_tibble(mtcars, rownames = \"car_name\")\nmtcars_tib\n\n# A tibble: 32 × 12\n   car_name      mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\n\nTibbles also clearly delineate [ and [[: [ always returns another tibble, [[ always returns a vector. No more drop = FALSE!\n\nIf we ask for the first column using the [] notation, we receive a numeric vector from a data frame, and a tibble/data.frame from the tibble.\nWe have not learned the [[]] yet because we have not talked about lists in R, but we will soon. The code below returns the first column as a vector for both a data frame and a tibble.\n\nmtcars[,1]\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\nmtcars_tib[,1]\n\n# A tibble: 32 × 1\n   car_name         \n   &lt;chr&gt;            \n 1 Mazda RX4        \n 2 Mazda RX4 Wag    \n 3 Datsun 710       \n 4 Hornet 4 Drive   \n 5 Hornet Sportabout\n 6 Valiant          \n 7 Duster 360       \n 8 Merc 240D        \n 9 Merc 230         \n10 Merc 280         \n# ℹ 22 more rows\n\nmtcars[[1]]\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\nmtcars_tib[[1]]\n\n [1] \"Mazda RX4\"           \"Mazda RX4 Wag\"       \"Datsun 710\"         \n [4] \"Hornet 4 Drive\"      \"Hornet Sportabout\"   \"Valiant\"            \n [7] \"Duster 360\"          \"Merc 240D\"           \"Merc 230\"           \n[10] \"Merc 280\"            \"Merc 280C\"           \"Merc 450SE\"         \n[13] \"Merc 450SL\"          \"Merc 450SLC\"         \"Cadillac Fleetwood\" \n[16] \"Lincoln Continental\" \"Chrysler Imperial\"   \"Fiat 128\"           \n[19] \"Honda Civic\"         \"Toyota Corolla\"      \"Toyota Corona\"      \n[22] \"Dodge Challenger\"    \"AMC Javelin\"         \"Camaro Z28\"         \n[25] \"Pontiac Firebird\"    \"Fiat X1-9\"           \"Porsche 914-2\"      \n[28] \"Lotus Europa\"        \"Ford Pantera L\"      \"Ferrari Dino\"       \n[31] \"Maserati Bora\"       \"Volvo 142E\"         \n\nclass(mtcars[,1])\n\n[1] \"numeric\"\n\nclass(mtcars_tib[,1])\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nclass(mtcars_tib[[1]])\n\n[1] \"character\"\n\n\nAs I was mentioning in class, there are some (older) functions that don’t like tibbles, but all you need to do is just make its primary class a data.frame as such:\n\nA handful of functions are don’t work with tibbles because they expect df[, 1] to return a vector, not a data frame. If you encounter one of these functions, use as.data.frame() to turn a tibble back to a data frame:\n\n\nmtcars_df &lt;- as.data.frame(mtcars_tib)\nclass(mtcars_df)\n\n[1] \"data.frame\"\n\n\nBack to muddy quotes:\n\npath files and knowing if you’re in a project or just an RMD\n\n\nR markdown vs R projects\n\nI hope to spend more time talking about this in class 4.\n\nggplot stuff was the most muddy, but I also haven’t done a lot of ggplot stuff before\n\nYes this was definitely expected for a brief intro, ggplot takes a while to get the hang of! We will use ggplot every class now, so we will go through it in bite sized pieces.\n\nUsing na=“NA” to pull in data and how to know that it’s needed.\n\nI will show more examples of this. Rule number one of importing data in any software is to look at your data, and figure out if what you see in the software is what you expect. Always look at your data! The read_excel(filename, na=\"NA\") is a strange case that isn’t actually very common to code data as “NA” directly, but I wanted to show you how it looks different when it does happen. Usually, missing data is just a blank space, which is automatically read in as the special NA data type in R.\n\n# If you did not include `na=NA` it would have been read in like this\ndf1 &lt;- tibble(a = c(\"NA\",\"C\",\"D\"), b= 1:3,  c = c(1,3,\"NA\"))\n# If you did include `na = NA` it would have been read in like this\ndf2 &lt;- tibble(a = c(NA,\"C\",\"D\"), b= 1:3, c = c(1,3,NA))\n\n# note the character types of the two DFs, and the way NA is printed\ndf1\n\n# A tibble: 3 × 3\n  a         b c    \n  &lt;chr&gt; &lt;int&gt; &lt;chr&gt;\n1 NA        1 1    \n2 C         2 3    \n3 D         3 NA   \n\ndf2\n\n# A tibble: 3 × 3\n  a         b     c\n  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 &lt;NA&gt;      1     1\n2 C         2     3\n3 D         3    NA\n\n\n\nI saw a lot of code with the two colons (“::”) in the middle. It is unclear to me if this is an alternative way to write some commands or if there is a certain context in which it is used.\n\nGood question, what this does is pulls a function from a package, so it works whether you have loaded the package (using library() or p_load()) or not. I mainly use it as a clue to you to where the function is coming from. Otherwise, you may not know you need to load that package to use it! For instance:\n\n# does not work, haven't loaded the package janitor\nmtcars %&gt;% tabyl(am, cyl)\n\n\n# does work\nmtcars %&gt;% janitor::tabyl(am, cyl)\n\n am 4 6  8\n  0 3 4 12\n  1 8 3  2\n\n\n\n# also works\nlibrary(janitor)\nmtcars %&gt;% tabyl(am, cyl)\n\n am 4 6  8\n  0 3 4 12\n  1 8 3  2\n\n\n\n\nClearest Points\n\nskim\n\n\nloading our excel to R studio\n\n\nLoading in the data and selecting the sheets that are most relevant to what we are looking to do was very clear and a nice foundation for future projects. I found that showing different ways of importing the data was helpful.\n\nI’m glad, the import tool in Rstudio is very nice, just remember to save the code in your Rmd.\n\nfunctionality of ggplot\n\n\ntidying the data\n\n\nFound out what eval=TRUE and eval=FALSE mean!\n\nGreat and I’ll show that again for anyone who was confused! (“still a little bit confused about the {r, EVAL} code”)\n\n\nOther messages\nSome people had trouble getting the fig.path= to work in the knitr options. I’m not sure what could be causing that but feel free to ask me during break.\nHere’s a good reference for all the code chunk options, if you want to read about it.\n\nlink to the course website that is in the overview tab in SAKAI links to last years materials.\n\nOops thank you great catch, fixed!\n\nSpeed is going great. I’m just worried as we progress through the course, it’ll be more difficult. Overall, really enjoying this class.\n\nI understand the concern, some things will get more difficult (I’m thinking across() in class 4, writing functions, and purrr), but we will also circle back to some things that might be familiar or maybe less complicated to start (stats models, making tables). Definitely keep asking questions and I will slow down as needed!",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-3-1",
    "href": "survey_feedback_previous_years.html#week-3-1",
    "title": "Survey Feedback",
    "section": "Week 3",
    "text": "Week 3\n\nMuddiest points\n\nthemes in ggplot\n\nCheck out this reference about ggplot themes first.\nHere’s a couple examples using this one plot, so you can see how the theme changes the look of the figure, when you use built in themes from the ggplot2 package (yes it only works in ggplot figures, for the person who asked about that)\n\nlibrary(tidyverse)\n\np &lt;- ggplot(mtcars, aes(x = mpg, y = carb, color = factor(cyl))) +\n  geom_point() +\n  labs(title = \"My scatterplot\")\np\n\n\n\n\n\n\n\n\nHere are some built in themes:\n\np + theme_bw()\n\n\n\n\n\n\n\n\n\np + theme_minimal()\n\n\n\n\n\n\n\n\n\np + theme_classic()\n\n\n\n\n\n\n\n\nHowever you can make more customized themes or plot changes where you use the theme() function to add in a lot of other elements. You can use this add on function to choose specific parts of the plot that you want to change, like this example from the above reference. Anything specified here will override the built in theme selected first. There are many options, and looking at specific examples will help. I am always, always googling how to change parts of the theme/plot like this, because there are just so many options it’s too hard to remember them all.\n\np + theme_classic() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 12),\n    legend.background = element_rect(fill = \"white\", size = 4, colour = \"white\"),\n    legend.justification = c(0, 1),\n    legend.position = c(0, 1),\n    axis.ticks = element_line(colour = \"grey70\", size = 0.2),\n    panel.grid.major = element_line(colour = \"grey70\", size = 0.2),\n    panel.grid.minor = element_blank()\n  )\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\n\nHere’s a simpler example just changing the title (from the above reference):\n\np + theme(plot.title = element_text(size = 16))\n\n\n\n\n\n\n\np + theme(plot.title = element_text(face = \"bold\", colour = \"red\"))\n\n\n\n\n\n\n\np + theme(plot.title = element_text(hjust = 1))\n\n\n\n\n\n\n\n\n\nhere()\n\nAgreed, it’s very confusing, more in class 4!\n\nCould you please clarify about the use of select(one_of) and the count command that was mentioned in dplyr cheatsheet?\n\nThese are very different, if you are talking about select() vs count(). One thing to note is that since I recorded that class, one_of() has been superseded/replaced by any_of() and all_of().\nFirst, select() is a function to subset columns.\n\nlibrary(palmerpenguins)\n\nHere we specify the columns we want in the order we want:\n\npenguins %&gt;% select(bill_length_mm, island, species, year)\n\n# A tibble: 344 × 4\n   bill_length_mm island    species  year\n            &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;int&gt;\n 1           39.1 Torgersen Adelie   2007\n 2           39.5 Torgersen Adelie   2007\n 3           40.3 Torgersen Adelie   2007\n 4           NA   Torgersen Adelie   2007\n 5           36.7 Torgersen Adelie   2007\n 6           39.3 Torgersen Adelie   2007\n 7           38.9 Torgersen Adelie   2007\n 8           39.2 Torgersen Adelie   2007\n 9           34.1 Torgersen Adelie   2007\n10           42   Torgersen Adelie   2007\n# ℹ 334 more rows\n\n\nHere, we pass a vector of character names, both of which work:\n\npenguins %&gt;% select(c(\"bill_length_mm\",\"island\",\"species\",\"year\"))\n\n# A tibble: 344 × 4\n   bill_length_mm island    species  year\n            &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;int&gt;\n 1           39.1 Torgersen Adelie   2007\n 2           39.5 Torgersen Adelie   2007\n 3           40.3 Torgersen Adelie   2007\n 4           NA   Torgersen Adelie   2007\n 5           36.7 Torgersen Adelie   2007\n 6           39.3 Torgersen Adelie   2007\n 7           38.9 Torgersen Adelie   2007\n 8           39.2 Torgersen Adelie   2007\n 9           34.1 Torgersen Adelie   2007\n10           42   Torgersen Adelie   2007\n# ℹ 334 more rows\n\npenguins %&gt;% select(any_of(c(\"bill_length_mm\",\"island\",\"species\",\"year\")))\n\n# A tibble: 344 × 4\n   bill_length_mm island    species  year\n            &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;int&gt;\n 1           39.1 Torgersen Adelie   2007\n 2           39.5 Torgersen Adelie   2007\n 3           40.3 Torgersen Adelie   2007\n 4           NA   Torgersen Adelie   2007\n 5           36.7 Torgersen Adelie   2007\n 6           39.3 Torgersen Adelie   2007\n 7           38.9 Torgersen Adelie   2007\n 8           39.2 Torgersen Adelie   2007\n 9           34.1 Torgersen Adelie   2007\n10           42   Torgersen Adelie   2007\n# ℹ 334 more rows\n\n\nThis might be useful if we have that character vector already saved from some other data work we are doing:\n\ncolnames_needed &lt;- c(\"bill_length_mm\",\"island\",\"species\",\"year\")\npenguins %&gt;% select(colnames_needed)\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(colnames_needed)\n\n  # Now:\n  data %&gt;% select(all_of(colnames_needed))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\n# A tibble: 344 × 4\n   bill_length_mm island    species  year\n            &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;int&gt;\n 1           39.1 Torgersen Adelie   2007\n 2           39.5 Torgersen Adelie   2007\n 3           40.3 Torgersen Adelie   2007\n 4           NA   Torgersen Adelie   2007\n 5           36.7 Torgersen Adelie   2007\n 6           39.3 Torgersen Adelie   2007\n 7           38.9 Torgersen Adelie   2007\n 8           39.2 Torgersen Adelie   2007\n 9           34.1 Torgersen Adelie   2007\n10           42   Torgersen Adelie   2007\n# ℹ 334 more rows\n\n\nBut the key about any_of and all_of is what it allows. any_of() allows column names that don’t exist! Using no tidyselect helper or all_of() does not allow this. Which you use depends on what you want to allow to happen.\n\ncolnames_needed &lt;- c(\"bill_length_mm\",\"island\",\"species\",\"year\",\"MISSING\")\n# penguins %&gt;% select((colnames_needed)) # does not work\npenguins %&gt;% select(any_of(colnames_needed)) # works!\n\n# A tibble: 344 × 4\n   bill_length_mm island    species  year\n            &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;int&gt;\n 1           39.1 Torgersen Adelie   2007\n 2           39.5 Torgersen Adelie   2007\n 3           40.3 Torgersen Adelie   2007\n 4           NA   Torgersen Adelie   2007\n 5           36.7 Torgersen Adelie   2007\n 6           39.3 Torgersen Adelie   2007\n 7           38.9 Torgersen Adelie   2007\n 8           39.2 Torgersen Adelie   2007\n 9           34.1 Torgersen Adelie   2007\n10           42   Torgersen Adelie   2007\n# ℹ 334 more rows\n\n# penguins %&gt;% select(all_of(colnames_needed)) # does not work\n\nany_of() is an example of a tidyselect helper, which we will see a lot more of when we start using across() with mutate() and summarize() in class 4. See this long list of useful tidyselect functions for more.\nOn the other hand, count() is mainly to count the number of unique values in a column/vector:\n\npenguins %&gt;% count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nThis created a new tibble, that summarizes the species column by counting the number of each type of species. This works for any type of vector but is most useful with character and factor columns. You can also use multiple columns here to see all possible combinations:\n\npenguins %&gt;% count(species, year)\n\n# A tibble: 9 × 3\n  species    year     n\n  &lt;fct&gt;     &lt;int&gt; &lt;int&gt;\n1 Adelie     2007    50\n2 Adelie     2008    50\n3 Adelie     2009    52\n4 Chinstrap  2007    26\n5 Chinstrap  2008    18\n6 Chinstrap  2009    24\n7 Gentoo     2007    34\n8 Gentoo     2008    46\n9 Gentoo     2009    44\n\n\n\n\nClearest Points\n\nfilter, select, arrange, pipes\n\nSuper! I want to take the time to mention (and hopefully not confuse everyone) that the pipe has recently (2021) been integrated into “base R”, that is, it’s loaded without loading the tidyverse package. HOWEVER it is this symbol |&gt; and does not behave exactly like the tidyverse pipe %&gt;% (actually from the magrittr package within the tidyverse package). For all the usual uses it works the same, so it could be used interchangeably in this class. Just know that if you see that type of pipe being used, assume it’s doing basically the same thing. Even R for Data Science is likely moving to use the native/base pipe, see this explanation. Probably next year’s class I will switch everything over to use this, though I still just use %&gt;% in my own work as it’s slightly more flexible for more “advanced” usage.\n\npenguins |&gt; count(species, year)\n\n# A tibble: 9 × 3\n  species    year     n\n  &lt;fct&gt;     &lt;int&gt; &lt;int&gt;\n1 Adelie     2007    50\n2 Adelie     2008    50\n3 Adelie     2009    52\n4 Chinstrap  2007    26\n5 Chinstrap  2008    18\n6 Chinstrap  2009    24\n7 Gentoo     2007    34\n8 Gentoo     2008    46\n9 Gentoo     2009    44\n\n\n\n\nOther messages\n\nDensity ridges are cool!\n\nI agree!",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "function_week0.html",
    "href": "function_week0.html",
    "title": "Functions of the Week",
    "section": "",
    "text": "Either open the Functions of the week webpage in a new browser window or view the webpage embedded below"
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-4-1",
    "href": "survey_feedback_previous_years.html#week-4-1",
    "title": "Survey Feedback",
    "section": "Week 4",
    "text": "Week 4\n\nMuddiest points\nI’ve noticed some confusion about what I call “saving your work”, so we’ll go over these slides.\n\nusing factors, what you’re doing and the benefit of turning things into factors in mutate\n\nI usually turn something into a factor for plotting (especially if I have a categorial numeric variable), and we’ll see more examples of that. We also later will see how it matters in statistical modeling/regression. It also is often easier to manage levels/categories this way, as we will see when we talk about the forcats package again in class 6.\n\ncase_when is not easy\n\nCorrect! Also some other comments on wanting more practice with case_when(). We will continue to see examples with this as we finish part5 and in other classes. It’s a very handy function so I use it a lot! See also the video above about factors with another explanation.\n\nThe function for converting a vector back from factor to character - I thought I had it, but I didn’t.\n\nOh, I didn’t show this!\n\n# make a character vector\nmyvec &lt;- c(\"medium\", \"low\", \"high\", \"low\")\nmyvec_fac &lt;- factor(myvec)\nmyvec_fac\n\n[1] medium low    high   low   \nLevels: high low medium\n\nclass(myvec_fac)\n\n[1] \"factor\"\n\n# get the levels out\nlevels(myvec_fac)\n\n[1] \"high\"   \"low\"    \"medium\"\n\n# Note we can \"test\" the classes of something like so:\nis.factor(myvec_fac)\n\n[1] TRUE\n\nis.character(myvec_fac)\n\n[1] FALSE\n\n# Now we can change it back\nmyvec2 &lt;- as.character(myvec_fac)\nmyvec2\n\n[1] \"medium\" \"low\"    \"high\"   \"low\"   \n\nclass(myvec2)\n\n[1] \"character\"\n\nlevels(myvec2) # no levels, because it's not a factor\n\nNULL\n\n# we could also change to numeric, how do you think it picks which number is which?\nmyvec3 &lt;- as.numeric(myvec_fac)\nmyvec3\n\n[1] 3 2 1 2\n\n# levels in order is assigned 1, 2, 3\ntable(myvec_fac, myvec3)\n\n         myvec3\nmyvec_fac 1 2 3\n   high   1 0 0\n   low    0 2 0\n   medium 0 0 1\n\n# change the level order\nmyvec_fac2 &lt;- factor(myvec, levels = c(\"low\", \"medium\", \"high\"))\nlevels(myvec_fac2)\n\n[1] \"low\"    \"medium\" \"high\"  \n\nmyvec4 &lt;- as.numeric(myvec_fac2)\nmyvec4\n\n[1] 2 1 3 1\n\ntable(myvec_fac2, myvec4)\n\n          myvec4\nmyvec_fac2 1 2 3\n    low    2 0 0\n    medium 0 1 0\n    high   0 0 1\n\n\n\nfactor vs as.factor\n\nEssentially the same. From the help documentation ?factor: “as.factor coerces its argument to a factor. It is an abbreviated (sometimes faster) form of factor.”\n\nI would like to know when you recommend that we save a new data set once we create new covariates. Also, it is unclear to me how you add the variable to the existing data.\n\nIf I want to use that column/covariate again, I save it (so almost always, as I don’t often make a column without using it later). I usually save it back into the original data set I’m working with, that is, overwrite that object to be updated with the new column. As long as I keep track of my changes this is definitely ok. It can get confusing having too many versions of a data set floating around. If something is broken, the worst that happens is that you’ll just need to start from the beginning and reload your data (the data file will remain untouched) and re-run the code.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n# does not save the new column, just prints result\npenguins %&gt;% \n  mutate(newvec = bill_length_mm/bill_depth_mm)\n\n# A tibble: 344 × 13\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 7 more variables: sex &lt;fct&gt;, year &lt;int&gt;, long_bill1 &lt;chr&gt;,\n#   long_bill2 &lt;chr&gt;, long_bill3 &lt;chr&gt;, long_bill4 &lt;chr&gt;, newvec &lt;dbl&gt;\n\n# saves new column in a data frame that is called penguins2\npenguins2 &lt;- penguins %&gt;% \n  mutate(newvec = bill_length_mm/bill_depth_mm)\nglimpse(penguins2)\n\nRows: 344\nColumns: 13\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ long_bill1        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill2        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill3        &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"shor…\n$ long_bill4        &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\", \"s…\n$ newvec            &lt;dbl&gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907767…\n\nglimpse(penguins) # has not been changed\n\nRows: 344\nColumns: 12\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ long_bill1        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill2        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill3        &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"shor…\n$ long_bill4        &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\", \"s…\n\n# saves new column in a data frame in the original data frame penguins\n# *overwrites penguins*\npenguins &lt;- penguins %&gt;% \n  mutate(newvec = bill_length_mm/bill_depth_mm)\nglimpse(penguins)\n\nRows: 344\nColumns: 13\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ long_bill1        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill2        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill3        &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"shor…\n$ long_bill4        &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\", \"s…\n$ newvec            &lt;dbl&gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907767…\n\n\n\narrange vs filter\n\narrange orders or sorts your data and does not remove or add anything, while filter removes rows.\n\n\nClearest points\n\nworking directory, here reordering factors mutate tibble vs data frame factors filtering\n\nGlad to hear we’re making progress!\n\n\nOther points\n\nIs there a list somewhere of all potential colors?\n\nA couple answers:\n\nSee this page for a list of “named” colors in R., or the ggplot2 cookbook for a smaller list\nWe will talk more about palettes when we finish part4 but there are many, many. I suggest finding a package or two that has the palettes you like and working with those. See a bunch listed here (scroll down in the readme).. My favorites are ggthemes and colorBlindness.\n\n\nI’m curious what the best practice is for stringing things together versus breaking them into pieces. For example, if I was trying to make a binary variable where all values were classified as larger or greater than the mean, I could use mean() inside several other functions like mutate(). Alternately I could calculate mean() [meanxx &lt;- mean(xxx)] and save it as an object, and then use the other functions on that value. I’m curious because it seems like if you did too many functions at once and were getting errors, it would be hard to tell what was wrong. But if you did it in a more stepwise fashion, you could see (for example) that mean() wasn’t working because there were NAs in your dataset. More importantly, I think if you were getting an erroneous answer (not an error, but a wrong answer, like if you calculated the mean of a variable but your NA’s were marked with “-88” and so R considered these actual observations) you might not know if you joined too many functions together and didn’t “see” what was happening under the hood. I’m curious how to deal with that.\n\nI copied over this whole question because I think it is an excellent one, and well said (hope you don’t mind)! I think this is something that evolves as you become more experienced in coding and debugging, and as you find your own style of coding. I will talk some about debugging later, but what you are saying about breaking things up into pieces absolutely helps with that.\nThe one thing to make sure of is that if you are saving intermediate steps, such as meanxx &lt;- mean(mydata$xx) and using it later, but then you update the data set (filter, replace NAs, fix an incorrect data entry, whatever), you need to make sure to update/re-calculate that mean object as it no longer matches your newer data set! So there is more to keep track of, in that case.\nI will say that if you are keeping track of all the steps well, then functionally it does not matter too much, so if it makes things easier to break it up, do that! If you like to chain everything together (often I do) you can run each piece by highlighting the code and running just that part to see what is going on, and this is something I do often.\nYour example is something I would probably do, though, as using the mean inside mutate does make me a bit nervous. For example, let’s use median because it’s easier to check my work at the end:\n\nlibrary(janitor) # for tabyl()\n\n# there are NAs in here:\nmedian(penguins$body_mass_g)\n\n[1] NA\n\n# let's save the median as a vector of length 1, remove NAs\ntmpmedian &lt;- median(penguins$body_mass_g, na.rm = TRUE)\ntmpmedian\n\n[1] 4050\n\npenguins &lt;- penguins %&gt;%\n  mutate(\n    large_mass = case_when(\n      body_mass_g &gt;= tmpmedian ~ \"yes\",\n      body_mass_g &lt; tmpmedian ~ \"no\" # this allows NAs to remain NA\n    ))\n\npenguins %&gt;% tabyl(large_mass)\n\n large_mass   n     percent valid_percent\n         no 170 0.494186047      0.497076\n        yes 172 0.500000000      0.502924\n       &lt;NA&gt;   2 0.005813953            NA\n\n# if I had just used median without checking for NAs, they all are NA:\npenguins %&gt;%\n  mutate(large_mass = 1*(body_mass_g &gt;= median(body_mass_g))) %&gt;%\n  tabyl(large_mass)\n\n large_mass   n percent valid_percent\n         NA 344       1            NA\n\n# Note if I just want females, this no longer makes sense:\npenguins %&gt;%\n  filter(sex==\"female\") %&gt;%\n  mutate(\n    large_mass = case_when(\n      body_mass_g &gt;= tmpmedian ~ \"yes\",\n      body_mass_g &lt; tmpmedian ~ \"no\" # this allows NAs to remain NA\n    )) %&gt;%\n  tabyl(large_mass)\n\n large_mass   n   percent\n         no 107 0.6484848\n        yes  58 0.3515152\n\n# but this would:\npenguins %&gt;%\n  filter(sex==\"female\") %&gt;%\n  mutate(\n    large_mass = case_when(\n      body_mass_g &gt;= median(body_mass_g, na.rm = TRUE) ~ \"yes\",\n      body_mass_g &lt; median(body_mass_g, na.rm = TRUE) ~ \"no\" \n    )) %&gt;%\n  tabyl(large_mass)\n\n large_mass  n   percent\n         no 80 0.4848485\n        yes 85 0.5151515",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-5-1",
    "href": "survey_feedback_previous_years.html#week-5-1",
    "title": "Survey Feedback",
    "section": "Week 5",
    "text": "Week 5\n\nMuddiest points\n\nI wasn’t super unclear about it, but just want to be more comfortable using summarize() and across and group_by functions. It looks like these will be really useful for future data projects, so that’s exciting! across function was a bit hazy because screen kept freezing\n\nSorry the zoom malfunctioned during this rather important and confusing section!\nWe will have more practice with across in other sections but the main points I want to get across (ha) are:\n\ngroup_by() is used to “group the data” (a.k.a “split”) by a categorical variable, and then all kinds of computations can be done within groups including summarize() but also slice() (such as slice_sample()) and later we will see this with nest() etc.\nsummarize() can be used with or without group_by() to collapse a big data set into a summarized table/data frame/tibble. This is still data, it’s just summarized data. Be careful when you are saving it, don’t overwrite your original data.\nacross() can be used inside mutate() and summarize() to “select” the columns we want to transform/mutate or summarize\nacross() uses what we call “tidyselect” syntax. For explanation and examples you can type ?dplyr_tidy_select or go to this website.\n\n\nthe syntax of .x ~\n\nWe use this when we are creating our own function inside of mutate. Think of algebra, where if we want to add something we might say:\ny = x + 3\ny = x/10\ny = log(x)\ny = exp(x)^3 - x/10\nThis is the same idea, except it’s just written with the special syntax/variable name that R knows how to interpret, where we use .x instead of x:\ny = .x + 3\ny = .x/10\ny = log(.x)\ny = exp(.x)^3 - .x/10\nBut we also need to use ~ to tell R, here’s a function! and we use the argument name and equal sign .fns = to say, here we are inputting the custom function as the argument input. If you look at the help ?across we see this is called “A purrr-style lambda” because we use it in the purrr package functions as well (we will see this later):\n\n# think of this as input to the argument of across()\n# typical argument syntax arg = _____\n.fns = ~ .x+3\n.fns = ~ .x/10\n.fns = ~ log(.x)\n.fns = ~ exp(.x)^3 - .x/10\n\nAnd this needs to go inside the nested functions mutate(across()) as an argument: mutate(across(.cols = ----, .fns = ----)):\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\npenguins %&gt;% mutate(\n  across(.cols = c(bill_length_mm, body_mass_g),\n         .fns = ~ exp(.x)^3 - .x/10))\n\n# A tibble: 344 × 14\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;dbl&gt;\n 1 Adelie  Torgersen        8.76e50          18.7               181         Inf\n 2 Adelie  Torgersen        2.91e51          17.4               186         Inf\n 3 Adelie  Torgersen        3.21e52          18                 195         Inf\n 4 Adelie  Torgersen       NA                NA                  NA          NA\n 5 Adelie  Torgersen        6.54e47          19.3               193         Inf\n 6 Adelie  Torgersen        1.60e51          20.6               190         Inf\n 7 Adelie  Torgersen        4.81e50          17.8               181         Inf\n 8 Adelie  Torgersen        1.18e51          19.6               195         Inf\n 9 Adelie  Torgersen        2.68e44          18.1               193         Inf\n10 Adelie  Torgersen        5.26e54          20.2               190         Inf\n# ℹ 334 more rows\n# ℹ 8 more variables: sex &lt;fct&gt;, year &lt;int&gt;, long_bill1 &lt;chr&gt;,\n#   long_bill2 &lt;chr&gt;, long_bill3 &lt;chr&gt;, long_bill4 &lt;chr&gt;, newvec &lt;dbl&gt;,\n#   large_mass &lt;chr&gt;\n\n\nWe can also apply multiple functions by putting them inside a list() and we can give them names:\n\n# here we have 3 functions\npenguins %&gt;% mutate(\n  across(.cols = c(bill_length_mm, body_mass_g),\n         .fns = list(\n           ~ .x/3,\n           log, # just using the named function, don't need .x\n           ~ exp(.x)^3 - .x/10))) %&gt;%\n  glimpse()\n\nRows: 344\nColumns: 20\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ long_bill1        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill2        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill3        &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"shor…\n$ long_bill4        &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\", \"s…\n$ newvec            &lt;dbl&gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907767…\n$ large_mass        &lt;chr&gt; \"no\", \"no\", \"no\", NA, \"no\", \"no\", \"no\", \"yes\", \"no\",…\n$ bill_length_mm_1  &lt;dbl&gt; 13.03333, 13.16667, 13.43333, NA, 12.23333, 13.10000…\n$ bill_length_mm_2  &lt;dbl&gt; 3.666122, 3.676301, 3.696351, NA, 3.602777, 3.671225…\n$ bill_length_mm_3  &lt;dbl&gt; 8.764814e+50, 2.910021e+51, 3.207767e+52, NA, 6.5436…\n$ body_mass_g_1     &lt;dbl&gt; 1250.000, 1266.667, 1083.333, NA, 1150.000, 1216.667…\n$ body_mass_g_2     &lt;dbl&gt; 8.229511, 8.242756, 8.086410, NA, 8.146130, 8.202482…\n$ body_mass_g_3     &lt;dbl&gt; Inf, Inf, Inf, NA, Inf, Inf, Inf, Inf, Inf, Inf, Inf…\n\n# here we have the same 3 functions but with names\npenguins %&gt;% mutate(\n  across(.cols = c(bill_length_mm, body_mass_g),\n         .fns = list(\n           fn1 = ~ .x/3,\n           log = log,\n           fn2 = ~ exp(.x)^3 - .x/10))) %&gt;%\n  glimpse()\n\nRows: 344\nColumns: 20\n$ species            &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ade…\n$ island             &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgers…\n$ bill_length_mm     &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1,…\n$ bill_depth_mm      &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1,…\n$ flipper_length_mm  &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 18…\n$ body_mass_g        &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475,…\n$ sex                &lt;fct&gt; male, female, female, NA, female, male, female, mal…\n$ year               &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 200…\n$ long_bill1         &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\",…\n$ long_bill2         &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\",…\n$ long_bill3         &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"sho…\n$ long_bill4         &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\", \"…\n$ newvec             &lt;dbl&gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.90776…\n$ large_mass         &lt;chr&gt; \"no\", \"no\", \"no\", NA, \"no\", \"no\", \"no\", \"yes\", \"no\"…\n$ bill_length_mm_fn1 &lt;dbl&gt; 13.03333, 13.16667, 13.43333, NA, 12.23333, 13.1000…\n$ bill_length_mm_log &lt;dbl&gt; 3.666122, 3.676301, 3.696351, NA, 3.602777, 3.67122…\n$ bill_length_mm_fn2 &lt;dbl&gt; 8.764814e+50, 2.910021e+51, 3.207767e+52, NA, 6.543…\n$ body_mass_g_fn1    &lt;dbl&gt; 1250.000, 1266.667, 1083.333, NA, 1150.000, 1216.66…\n$ body_mass_g_log    &lt;dbl&gt; 8.229511, 8.242756, 8.086410, NA, 8.146130, 8.20248…\n$ body_mass_g_fn2    &lt;dbl&gt; Inf, Inf, Inf, NA, Inf, Inf, Inf, Inf, Inf, Inf, In…\n\n\n\nhow do we change the names when using across() inside mutate()\n\nI skipped this for the sake of time and to avoid confusion last class and showed you how to do this using rename() instead, but let’s go over it now a little bit.\nThe .names argument inside across() uses a function called glue() inside the package glue. We haven’t covered glue package syntax yet (it’s in part9) but think of it as a string concatenating (“gluing”) method where we write out what we want to be in the text string inside quotes, but use variable names and code functions inside of the quotes in a special way. The important part to know right now is that the stuff inside {} is code, and everything else is just text. Here when we use .col inside the glue code that is the stand-in for the column name, so \"{.col}\" is literally just the column name, and \"{.col}_fun\" is the column name with “_fun” appended to it.\nHere are some simple glue examples:\n\nlibrary(glue)\nglue(\"hello\")\n\nhello\n\nmyname &lt;- \"jessica\"\n\nglue(\"hello {myname}\")\n\nhello jessica\n\nglue(\"hello {myname}, how are you?\")\n\nhello jessica, how are you?\n\nfirstname &lt;- \"jane\"\nlastname &lt;- \"doe\"\nglue(\"{firstname}_{lastname}\")\n\njane_doe\n\n\nLook at ?across and the .names argument for some info and the defaults.\n\n# Does not change names of transformed columns\n# no longer accruate since not mm\npenguins %&gt;%\n  mutate(\n    across(.cols = ends_with(\"mm\"), .fns = ~ .x/10)) %&gt;%\n  glimpse()\n\nRows: 344\nColumns: 14\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 3.91, 3.95, 4.03, NA, 3.67, 3.93, 3.89, 3.92, 3.41, …\n$ bill_depth_mm     &lt;dbl&gt; 1.87, 1.74, 1.80, NA, 1.93, 2.06, 1.78, 1.96, 1.81, …\n$ flipper_length_mm &lt;dbl&gt; 18.1, 18.6, 19.5, NA, 19.3, 19.0, 18.1, 19.5, 19.3, …\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ long_bill1        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill2        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill3        &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"shor…\n$ long_bill4        &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\", \"s…\n$ newvec            &lt;dbl&gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907767…\n$ large_mass        &lt;chr&gt; \"no\", \"no\", \"no\", NA, \"no\", \"no\", \"no\", \"yes\", \"no\",…\n\n# adds cm to end of column names, but still has mm, confusing\npenguins %&gt;%\n  mutate(\n    across(.cols = ends_with(\"mm\"),\n           .fns = ~ .x/10,\n           .names = \"{.col}_cm\")) %&gt;%\n  glimpse()\n\nRows: 344\nColumns: 17\n$ species              &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, A…\n$ island               &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torge…\n$ bill_length_mm       &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.…\n$ bill_depth_mm        &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.…\n$ flipper_length_mm    &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, …\n$ body_mass_g          &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 347…\n$ sex                  &lt;fct&gt; male, female, female, NA, female, male, female, m…\n$ year                 &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2…\n$ long_bill1           &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long…\n$ long_bill2           &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long…\n$ long_bill3           &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"s…\n$ long_bill4           &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\",…\n$ newvec               &lt;dbl&gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907…\n$ large_mass           &lt;chr&gt; \"no\", \"no\", \"no\", NA, \"no\", \"no\", \"no\", \"yes\", \"n…\n$ bill_length_mm_cm    &lt;dbl&gt; 3.91, 3.95, 4.03, NA, 3.67, 3.93, 3.89, 3.92, 3.4…\n$ bill_depth_mm_cm     &lt;dbl&gt; 1.87, 1.74, 1.80, NA, 1.93, 2.06, 1.78, 1.96, 1.8…\n$ flipper_length_mm_cm &lt;dbl&gt; 18.1, 18.6, 19.5, NA, 19.3, 19.0, 18.1, 19.5, 19.…\n\n# code inside the {} is evaluated, \n# so we can use stringr::str_remove() to remove what we don't want there\n# str_remove_all() also works\n# note now we have kept the original columns as well\n# note we need single quotes for the glue code because we are wrapping it in\n# double quotes already\npenguins %&gt;%\n  mutate(\n    across(.cols = ends_with(\"mm\"),\n           .fns = ~ .x/10,\n           .names = \"{str_remove(.col,'_mm')}_cm\")) %&gt;%\n  glimpse()\n\nRows: 344\nColumns: 17\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ long_bill1        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill2        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill3        &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"shor…\n$ long_bill4        &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\", \"s…\n$ newvec            &lt;dbl&gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907767…\n$ large_mass        &lt;chr&gt; \"no\", \"no\", \"no\", NA, \"no\", \"no\", \"no\", \"yes\", \"no\",…\n$ bill_length_cm    &lt;dbl&gt; 3.91, 3.95, 4.03, NA, 3.67, 3.93, 3.89, 3.92, 3.41, …\n$ bill_depth_cm     &lt;dbl&gt; 1.87, 1.74, 1.80, NA, 1.93, 2.06, 1.78, 1.96, 1.81, …\n$ flipper_length_cm &lt;dbl&gt; 18.1, 18.6, 19.5, NA, 19.3, 19.0, 18.1, 19.5, 19.3, …\n\n# alternative that works here is using str_replace()\npenguins %&gt;%\n  mutate(\n    across(.cols = ends_with(\"mm\"),\n           .fns = ~ .x/10,\n           .names = \"{str_replace(.col,'_mm', '_cm')}\")) %&gt;%\n  glimpse()\n\nRows: 344\nColumns: 17\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ long_bill1        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill2        &lt;chr&gt; \"not long\", \"not long\", \"not long\", NA, \"not long\", …\n$ long_bill3        &lt;chr&gt; \"short\", \"short\", \"medium\", \"medium\", \"short\", \"shor…\n$ long_bill4        &lt;chr&gt; \"short\", \"short\", \"medium\", NA, \"short\", \"short\", \"s…\n$ newvec            &lt;dbl&gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907767…\n$ large_mass        &lt;chr&gt; \"no\", \"no\", \"no\", NA, \"no\", \"no\", \"no\", \"yes\", \"no\",…\n$ bill_length_cm    &lt;dbl&gt; 3.91, 3.95, 4.03, NA, 3.67, 3.93, 3.89, 3.92, 3.41, …\n$ bill_depth_cm     &lt;dbl&gt; 1.87, 1.74, 1.80, NA, 1.93, 2.06, 1.78, 1.96, 1.81, …\n$ flipper_length_cm &lt;dbl&gt; 18.1, 18.6, 19.5, NA, 19.3, 19.0, 18.1, 19.5, 19.3, …\n\n\n\nIt’s unclear to me if there is distinction between using ‘str_remove_all’ and ‘separate()’ when we talked about removing “years old” from the column “age”. Are there particular circumstances where one is preferred over the other?\n\nIn R and in programming in general, there are always multiple ways to do the same thing. Often many, many ways! There is no preferred way just which makes the most sense to you/which you are most comfortable with.\nFor me, I like to use the stringr functions to remove stuff from columns that I don’t want, because it is the most “clear” to me and also probably to anyone reading my code.\nThe separate() way is more of a clever trick, an “out of the box” way to use an existing function that works for our needs in this case. There are a lot of things like that, and it’s perfectly ok to use them if you understand what they are doing and why.\n\narrange with two variables\n\nHere’s a simple example so we can see how arrange() works with two categories (this is analogous to sorting by two variables in excel)\n\nmydata &lt;- tibble(\n  id = 1:4,\n  animal = c(\"cat\",\"mouse\",\"dog\",\"cat\"),\n  weight = c(10, 1, 20, 8),\n  age = c(15, 3, 3, 20))\n\nmydata\n\n# A tibble: 4 × 4\n     id animal weight   age\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     1 cat        10    15\n2     2 mouse       1     3\n3     3 dog        20     3\n4     4 cat         8    20\n\nmydata %&gt;% arrange(weight)\n\n# A tibble: 4 × 4\n     id animal weight   age\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     2 mouse       1     3\n2     4 cat         8    20\n3     1 cat        10    15\n4     3 dog        20     3\n\nmydata %&gt;% arrange(animal)\n\n# A tibble: 4 × 4\n     id animal weight   age\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     1 cat        10    15\n2     4 cat         8    20\n3     3 dog        20     3\n4     2 mouse       1     3\n\n# arrange by animal first, then weight within animal categories\nmydata %&gt;% arrange(animal, weight)\n\n# A tibble: 4 × 4\n     id animal weight   age\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     4 cat         8    20\n2     1 cat        10    15\n3     3 dog        20     3\n4     2 mouse       1     3\n\n# does not do anything in this case, but would arrange by age if there were ties in the weight column within the animal category\nmydata %&gt;% arrange(animal, weight, age)\n\n# A tibble: 4 × 4\n     id animal weight   age\n  &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     4 cat         8    20\n2     1 cat        10    15\n3     3 dog        20     3\n4     2 mouse       1     3\n\n\n\nstringr::str_to_title()\n\nJust a clarification:\nRemember to read help documentation and look at examples if still not clear!\n\nstr_to_title(\"hello\")\n\n[1] \"Hello\"\n\nstr_to_title(\"hello my name is jessica\")\n\n[1] \"Hello My Name Is Jessica\"\n\nstr_to_title(\"HELLO MY name is jessica\")\n\n[1] \"Hello My Name Is Jessica\"\n\n\nThere are other similar “case conversion” functions as well:\n\nstr_to_upper(\"HELLO MY name is jessica\")\n\n[1] \"HELLO MY NAME IS JESSICA\"\n\nstr_to_lower(\"HELLO MY name is jessica\")\n\n[1] \"hello my name is jessica\"\n\nstr_to_sentence(\"HELLO MY name is jessica\")\n\n[1] \"Hello my name is jessica\"\n\n\n\nstringing together multiple commands in a pipe, which comes first and which functions are safe to put inside other functions- and if so- how do you know what order to put them in.\n\nYou’ll want to put them in the order that you want the operations to be performed.\nFor instance, if you want to summarize a data set after filtering, then put filter() first then summarize(). When in doubt, don’t string them together just do them one at a time!\nRegarding which functions are safe to put inside other functions I am not sure exactly what you mean, but perhaps it’s the summarize(across()) type situation that is causing confusion. In this case, the result of across() becomes an argument input for summarize(). We also use functions as arguments inside across().\nThis part will require just more experience seeing what functions go where and getting used to all the syntax. I’ll try to point out specific examples where it makes sense to put functions inside other functions, but in general the tidyverse “verbs” such as mutate(), select(), filter(), summarize(), separate(), rename() are done in some kind of order that makes sense for how you want to transform your data, and they are chained together by pipes or done one at a time.\n\n# mutate first\npenguins &lt;- penguins %&gt;% mutate(bill_length_cm = bill_length_mm/10)\n\n# create a filtered data sest of just female penguins\npenguins_f &lt;- penguins %&gt;% filter(sex==\"female\")\n\n# we could have mutated *after* filtering in this case, it doesn't matter if we only care about the female penguins\n\n# summarize that female penguin data set, don't save as anything\n# just print it out\npenguins_f %&gt;% summarize(across( # across goes inside summarize\n  .cols = where(is.numeric), # where() is a function inside across()\n  .fns = mean, na.rm = TRUE))\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `across(.cols = where(is.numeric), .fns = mean, na.rm = TRUE)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 1 × 7\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year newvec\n           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1           42.1          16.4              197.       3862. 2008.   2.61\n# ℹ 1 more variable: bill_length_cm &lt;dbl&gt;\n\n\n\nImporting files from other statistical programs, such as SAS and Stata joining tables joining two tables seems scary!\n\nWe will cover these in class 6! We haven’t talked about joining yet, just “stacking” tables with bind_rows(). Hopefully talking about join will make the difference more clear.\n\nzoom issues, try restarting R?\n\nGood idea I’ll try that next time! Hope there isn’t a next time…\nWhoever had the brilliant idea of “raising hand” during zoom class, definitely do that if you want to get my attention because I can see that but not the chat while teaching, and sometimes the audio in the room forces my computer to go on mute even when I unmute it.\n\n\nClearest points\n\npalettes mutate() case_when() here group_by() and summarize ggplots\n\nGreat, we are getting there!\n\nThe section on color palettes was clearest. It is nice to be given so many options and resources.\n\nOh good, I was worried that I spent too much time on this, so glad you find it helpful.\n\n\nOther\n\nWhen we encounter many categories (eg. 100+) in a variable, how do we plot the top 5% or 10% of the data using ggplot?\n\nHmm this is a pretty open ended question and could mean a lot of different things, but initial thought is you mean something like: “we have a lot of categories, we want to only plot a summary (i.e. boxplot) of the 5% most common categories.” It’s a very specific kind of question but I’ll show it in class as an excuse to show more forcats functions with factors.\n\nlibrary(gapminder)\nlibrary(janitor)\nset.seed(500) # set my random seed so the sampling is always the same\n\n# create a data that has uneven number of obs for each country\nmydata &lt;- gapminder %&gt;% slice_sample(prop=.2) \n\n# we can see some countries have more observations than others\nmydata %&gt;%\n  tabyl(country) %&gt;%\n  arrange(desc(n))\n\n                  country n     percent\n             Burkina Faso 6 0.017647059\n                  Senegal 6 0.017647059\n            Guinea-Bissau 5 0.014705882\n                     Mali 5 0.014705882\n                Nicaragua 5 0.014705882\n    Sao Tome and Principe 5 0.014705882\n             Saudi Arabia 5 0.014705882\n                   Serbia 5 0.014705882\n              Switzerland 5 0.014705882\n                  Bolivia 4 0.011764706\n                 Botswana 4 0.011764706\n                 Cambodia 4 0.011764706\n              Congo, Rep. 4 0.011764706\n                  Ecuador 4 0.011764706\n        Equatorial Guinea 4 0.011764706\n                   France 4 0.011764706\n                     Iraq 4 0.011764706\n              Korea, Rep. 4 0.011764706\n                 Mongolia 4 0.011764706\n               Montenegro 4 0.011764706\n                  Namibia 4 0.011764706\n                 Pakistan 4 0.011764706\n                 Slovenia 4 0.011764706\n             South Africa 4 0.011764706\n                   Taiwan 4 0.011764706\n      Trinidad and Tobago 4 0.011764706\n                  Tunisia 4 0.011764706\n                   Turkey 4 0.011764706\n       West Bank and Gaza 4 0.011764706\n               Bangladesh 3 0.008823529\n Central African Republic 3 0.008823529\n                  Comoros 3 0.008823529\n            Cote d'Ivoire 3 0.008823529\n           Czech Republic 3 0.008823529\n       Dominican Republic 3 0.008823529\n              El Salvador 3 0.008823529\n                 Ethiopia 3 0.008823529\n                  Germany 3 0.008823529\n                  Iceland 3 0.008823529\n                    India 3 0.008823529\n                Indonesia 3 0.008823529\n                    Italy 3 0.008823529\n                    Japan 3 0.008823529\n                    Kenya 3 0.008823529\n                   Kuwait 3 0.008823529\n                  Lebanon 3 0.008823529\n                  Lesotho 3 0.008823529\n               Madagascar 3 0.008823529\n                   Malawi 3 0.008823529\n               Mauritania 3 0.008823529\n               Mozambique 3 0.008823529\n                  Myanmar 3 0.008823529\n                    Nepal 3 0.008823529\n                    Niger 3 0.008823529\n                     Oman 3 0.008823529\n                 Paraguay 3 0.008823529\n                   Rwanda 3 0.008823529\n             Sierra Leone 3 0.008823529\n                  Somalia 3 0.008823529\n                Sri Lanka 3 0.008823529\n                 Thailand 3 0.008823529\n                     Togo 3 0.008823529\n                   Uganda 3 0.008823529\n                  Vietnam 3 0.008823529\n                 Zimbabwe 3 0.008823529\n                   Angola 2 0.005882353\n                Argentina 2 0.005882353\n                  Austria 2 0.005882353\n                  Bahrain 2 0.005882353\n                 Bulgaria 2 0.005882353\n                  Burundi 2 0.005882353\n                 Cameroon 2 0.005882353\n                    Chile 2 0.005882353\n                    China 2 0.005882353\n                 Colombia 2 0.005882353\n         Congo, Dem. Rep. 2 0.005882353\n                  Denmark 2 0.005882353\n                 Djibouti 2 0.005882353\n                    Egypt 2 0.005882353\n                  Finland 2 0.005882353\n                    Ghana 2 0.005882353\n                   Guinea 2 0.005882353\n                    Haiti 2 0.005882353\n                  Hungary 2 0.005882353\n                  Jamaica 2 0.005882353\n                   Jordan 2 0.005882353\n         Korea, Dem. Rep. 2 0.005882353\n                  Liberia 2 0.005882353\n                    Libya 2 0.005882353\n                   Mexico 2 0.005882353\n                   Norway 2 0.005882353\n                     Peru 2 0.005882353\n              Philippines 2 0.005882353\n              Puerto Rico 2 0.005882353\n                  Reunion 2 0.005882353\n                Singapore 2 0.005882353\n          Slovak Republic 2 0.005882353\n                    Spain 2 0.005882353\n                    Sudan 2 0.005882353\n                   Sweden 2 0.005882353\n                    Syria 2 0.005882353\n                 Tanzania 2 0.005882353\n                  Uruguay 2 0.005882353\n                Venezuela 2 0.005882353\n              Afghanistan 1 0.002941176\n                  Belgium 1 0.002941176\n                    Benin 1 0.002941176\n   Bosnia and Herzegovina 1 0.002941176\n                   Canada 1 0.002941176\n                     Chad 1 0.002941176\n               Costa Rica 1 0.002941176\n                  Croatia 1 0.002941176\n                     Cuba 1 0.002941176\n                    Gabon 1 0.002941176\n                   Gambia 1 0.002941176\n                   Greece 1 0.002941176\n                Guatemala 1 0.002941176\n                 Honduras 1 0.002941176\n                     Iran 1 0.002941176\n                  Ireland 1 0.002941176\n                   Israel 1 0.002941176\n                Mauritius 1 0.002941176\n                  Morocco 1 0.002941176\n              Netherlands 1 0.002941176\n              New Zealand 1 0.002941176\n                   Poland 1 0.002941176\n                 Portugal 1 0.002941176\n                  Romania 1 0.002941176\n                Swaziland 1 0.002941176\n           United Kingdom 1 0.002941176\n              Yemen, Rep. 1 0.002941176\n                  Albania 0 0.000000000\n                  Algeria 0 0.000000000\n                Australia 0 0.000000000\n                   Brazil 0 0.000000000\n                  Eritrea 0 0.000000000\n         Hong Kong, China 0 0.000000000\n                 Malaysia 0 0.000000000\n                  Nigeria 0 0.000000000\n                   Panama 0 0.000000000\n            United States 0 0.000000000\n                   Zambia 0 0.000000000\n\n# note country is a factor\nglimpse(mydata)\n\nRows: 340\nColumns: 6\n$ country   &lt;fct&gt; \"Slovenia\", \"Denmark\", \"Djibouti\", \"Paraguay\", \"Japan\", \"Pue…\n$ continent &lt;fct&gt; Europe, Europe, Africa, Americas, Asia, Americas, Asia, Euro…\n$ year      &lt;int&gt; 1962, 1962, 2002, 1972, 1982, 2007, 1962, 1977, 1977, 1977, …\n$ lifeExp   &lt;dbl&gt; 69.150, 72.350, 53.373, 65.815, 77.110, 78.746, 39.393, 59.5…\n$ pop       &lt;int&gt; 1582962, 4646899, 447416, 2614104, 118454974, 3942491, 10332…\n$ gdpPercap &lt;dbl&gt; 7402.3034, 13583.3135, 1908.2609, 2523.3380, 19384.1057, 193…\n\n\n\n# If we only want the categories with at least 5 levels, for example, we could lump everything else into an \"other\" category:\n\nmydata &lt;- mydata %&gt;% mutate(country_lump = fct_lump_min(country, min=5))\nmydata %&gt;% tabyl(country_lump)\n\n          country_lump   n    percent\n          Burkina Faso   6 0.01764706\n         Guinea-Bissau   5 0.01470588\n                  Mali   5 0.01470588\n             Nicaragua   5 0.01470588\n Sao Tome and Principe   5 0.01470588\n          Saudi Arabia   5 0.01470588\n               Senegal   6 0.01764706\n                Serbia   5 0.01470588\n           Switzerland   5 0.01470588\n                 Other 293 0.86176471\n\n# plot all countries\nggplot(mydata, aes(x=country, y=lifeExp, color = year)) +\n  geom_point() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\n\n\n# plot just the most common ones\nggplot(mydata, aes(x=country_lump, y=lifeExp, color = year)) +\n  geom_point() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\n\n\n# remove the other category\nggplot(mydata %&gt;% filter(country_lump!=\"Other\"), \n       aes(x=country_lump, y=lifeExp, color = year)) +\n  geom_point() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\n\n\n# plot in order of number of observations\nlevels(mydata$country_lump)\n\n [1] \"Burkina Faso\"          \"Guinea-Bissau\"         \"Mali\"                 \n [4] \"Nicaragua\"             \"Sao Tome and Principe\" \"Saudi Arabia\"         \n [7] \"Senegal\"               \"Serbia\"                \"Switzerland\"          \n[10] \"Other\"                \n\n# this relevels the factor in order of frequency:\nmydata &lt;- mydata %&gt;% \n  mutate(country_lump = fct_infreq(country_lump))\nlevels(mydata$country_lump)\n\n [1] \"Other\"                 \"Burkina Faso\"          \"Senegal\"              \n [4] \"Guinea-Bissau\"         \"Mali\"                  \"Nicaragua\"            \n [7] \"Sao Tome and Principe\" \"Saudi Arabia\"          \"Serbia\"               \n[10] \"Switzerland\"          \n\n# now plotting order has changed\nggplot(mydata, aes(x=country_lump, y=lifeExp, color = year)) +\n  geom_point() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-6",
    "href": "survey_feedback_previous_years.html#week-6",
    "title": "Survey Feedback",
    "section": "Week 6",
    "text": "Week 6\n\nMuddiest Points\nSomewhat equal numbers said that pivot/joining were clear or were muddy! I think that sounds about right, though, these concepts are tricky and will take a lot of practice. Today’s class will use these methods again and I hope that will help solidify what you’ve learned.\nI really do recommend watching the short video that I recommended last class if you’re still having trouble with grasping pivoting.\nDr. Kelly Bodwin’s Reshaping Data Video\nFor a short version, watch the pivot_longer excerpt about “working backwards” from a plot. Then watch the pivot_wider excerpt\nAlso read this join cheatsheet for some good explanations/examples about which join to use when!\nThe rstudio cheatsheet is also good.\nDefinitely do the readings in the R for Data Science in the appropriate chapters as well! joining, pivoting\nFor the different join types, here are some visuals I find helpful.\nWhen we use bind_rows() we stack cases on top of each other like so:\n\nFor joins, we put columns next to each other based on matching keys. The “intersection” of keys is shown in these diagrams for each type of join, with the blue denoting which keys/rows we keep from which table:\n\nA more data oriented visual is shown below. The lines denote the keys that match:\n\nThis is from the part5 Rmd:\n\nWhen do we use which join?\nSee this two-table verbs vignette and this cheatsheet for some extra explanations.\nThese joins are created to match SQL joins for databases.\n\ninner_join = You only want data that is in both tables\nleft_join = You only want data that is in one table.\n\nOften the right table is a subset of the left table, so it’s easy to use this to keep everything in the bigger table, and join on the smaller table\nIf the left table contains a cohort of interest, i.e. everyone that has been given a specific treatment, and you want to get their lab values from another table, use left_join() to add those lab values in the cohort defined by the left table\n\nright_join = maybe never\n\nright_join does the same thing as left_join but backwards, I find left join easier to think about (personal preference)\n\nfull_join = does not remove any rows, you might want to use this as your default and filter later\nanti_join and semi_join = filtering joins, probably use rarely, use right table as an exclusion criteria and find unmatched keys between two tables (anti_join), or filter left table based on keys in right table (semi_join), and keep only columns from left table\n\n\n\nseparate example\n\nseparate(), needed a few more minutes to get it figured out\n\nLet’s do another short example!\n\nlibrary(tidyverse)\n\nmydata &lt;- tibble(\n  name = c(\"Doe, Jane\", \"Smith, M\", \"Lee, Dave\"),\n  rx = c(\"Advil; 4.5 mg\", \"Tylenol; 300mg\", \"Advil; 2.5 mg\")\n)\n\n# obviously the dosage makes no sense, but, for sake of example\nmydata\n\n# A tibble: 3 × 2\n  name      rx            \n  &lt;chr&gt;     &lt;chr&gt;         \n1 Doe, Jane Advil; 4.5 mg \n2 Smith, M  Tylenol; 300mg\n3 Lee, Dave Advil; 2.5 mg \n\n# prints a little prettier in html\nknitr::kable(mydata)\n\n\n\n\nname\nrx\n\n\n\n\nDoe, Jane\nAdvil; 4.5 mg\n\n\nSmith, M\nTylenol; 300mg\n\n\nLee, Dave\nAdvil; 2.5 mg\n\n\n\n\n\n\n# by default, separates using most special/non-alphanumeric characters\nmydata %&gt;%\n  separate(name, into = c(\"last_name\", \"first_name\"))\n\n# A tibble: 3 × 3\n  last_name first_name rx            \n  &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;         \n1 Doe       Jane       Advil; 4.5 mg \n2 Smith     M          Tylenol; 300mg\n3 Lee       Dave       Advil; 2.5 mg \n\n# since there are special characters in rx, will need to be more specific\n# note it tried to split on the . since we only have 2 columns named, it removed the rest\nmydata %&gt;%\n  separate(rx, into = c(\"rx_name\", \"rx_dose\"))\n\nWarning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 3].\n\n\n# A tibble: 3 × 3\n  name      rx_name rx_dose\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;  \n1 Doe, Jane Advil   4      \n2 Smith, M  Tylenol 300mg  \n3 Lee, Dave Advil   2      \n\n# if we add in some more columns, we can see it's splitting based on ; . and space!\nmydata %&gt;%\n  separate(rx, into = c(\"rx_name\", \"rx_dose\", \"a\", \"b\", \"c\"))\n\nWarning: Expected 5 pieces. Missing pieces filled with `NA` in 3 rows [1, 2,\n3].\n\n\n# A tibble: 3 × 6\n  name      rx_name rx_dose a     b     c    \n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Doe, Jane Advil   4       5     mg    &lt;NA&gt; \n2 Smith, M  Tylenol 300mg   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 Lee, Dave Advil   2       5     mg    &lt;NA&gt; \n\n# still have a space\nmydata %&gt;%\n  separate(rx, into = c(\"rx_name\", \"rx_dose\"), sep=\";\")\n\n# A tibble: 3 × 3\n  name      rx_name rx_dose  \n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;    \n1 Doe, Jane Advil   \" 4.5 mg\"\n2 Smith, M  Tylenol \" 300mg\" \n3 Lee, Dave Advil   \" 2.5 mg\"\n\n# removed the space\nmydata %&gt;%\n  separate(rx, into = c(\"rx_name\", \"rx_dose\"), sep=\"; \")\n\n# A tibble: 3 × 3\n  name      rx_name rx_dose\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;  \n1 Doe, Jane Advil   4.5 mg \n2 Smith, M  Tylenol 300mg  \n3 Lee, Dave Advil   2.5 mg \n\n# removed the space, let's also remove the mg\nmydata %&gt;%\n  separate(rx, into = c(\"rx_name\", \"rx_dose_mg\"), sep=\"; \") %&gt;%\n  mutate(rx_dose_mg = str_remove_all(rx_dose_mg, \"mg\"),\n         rx_dose_mg = as.numeric(rx_dose_mg))\n\n# A tibble: 3 × 3\n  name      rx_name rx_dose_mg\n  &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n1 Doe, Jane Advil          4.5\n2 Smith, M  Tylenol      300  \n3 Lee, Dave Advil          2.5\n\n# all together, and also leave the name column in\nmydata %&gt;%\n  separate(name, into = c(\"last_name\", \"first_name\"), remove = FALSE) %&gt;%\n  separate(rx, into = c(\"rx_name\", \"rx_dose_mg\"), sep=\"; \") %&gt;%\n  mutate(rx_dose_mg = str_remove_all(rx_dose_mg, \"mg\"),\n         rx_dose_mg = as.numeric(rx_dose_mg))\n\n# A tibble: 3 × 5\n  name      last_name first_name rx_name rx_dose_mg\n  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;\n1 Doe, Jane Doe       Jane       Advil          4.5\n2 Smith, M  Smith     M          Tylenol      300  \n3 Lee, Dave Lee       Dave       Advil          2.5\n\n\n\n\n\nOther: piping troubles\n\nI have issues with my pipes where I think I’m putting things in the wrong order and nothing happens- I don’t get errors I can google, it just doesn’t work. Most often it’s when I end a pipe with %&gt;% tabyl(variable), maybe that is a no-no? But I’ve found I end up having to break pipes into multiple pieces because I can’t string them together the right way.\n\n\nI have a hard time understanding when to pipe things together or knowing when to nest a function as well. I’m glad you’ve reassured us in class that it’s ok that we put our functions into pieces. I think that eases the stress with learning as I feel like trying to make everything happen in one command can be very overwhelming.\n\nYes, yes! Please separate out your pipes/commands if it makes things more clear or makes it work better for you!\nI’m not sure what’s happening with the no-errors-broken situation. I will say that I often separate the taybl(variable) code when I’m doing analysis work, just because I am saving intermediate data sets after data cleaning or sub-setting and don’t want to save that tabyl. Something like this:\n\nlibrary(janitor)\nmtcars6 &lt;- mtcars %&gt;% filter(cyl==6)\n# check that it worked\nmtcars6 %&gt;% tabyl(cyl)\n\n cyl n percent\n   6 7       1\n\n\nAs a beginner I definitely think doing each step individually and seeing the result and (saving it/assigning it appropriately!) is the way to learn what each function does. I tend to string things together because I am used to doing that, but I’ll try not to do that so much if it’s adding confusion.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-7",
    "href": "survey_feedback_previous_years.html#week-7",
    "title": "Survey Feedback",
    "section": "Week 7",
    "text": "Week 7\n\nMuddiest Parts\nStill some pain points related to pivot_-ing. I get it, it took me a long time to get comfortable with this (and I’ve gone through multiple function and argument transformations from melt() to gather() to pivot_longer() etc, all those transitions were hard!). We might not see many more examples with this because we have so much more to cover, but keep practicing, and ask for help when you need it! Relatedly:\n\npivot_longer is so versatile for data manipulation but sometimes it’s contains many arguments\n\n\nWhen ever I use pivot_longer and pivot_wider I get the columns that are being switched wrong.Is there a way you think about it that helps you sort out which is which? The Stata manual uses this ‘i’ and ‘j’ notation that’s helping when I’m working in Stata, but I haven’t found an easy way to work with those functions in R.\n\nThe argument names have changed a lot since I started pivoting with the tidyverse, but now they are using names_to= because the authors think this makes more sense, and I tend to agree. This argument name helps me figure out what to do more than old versions. I think of this argument as “column names turn into one column called = X” or send the “names” of these columns “to” this new column. Therefore, I need to specify which cols= are the column names going into names_to=\nThen, when we go to pivot_wider() we get names_from= which is asking, where are the column names coming from? Also, values_from= which is asking, where are the actual values coming from? Pivot wider to me is easier because we don’t need to specify any other information than those two pieces (you can optionally specify id_cols= but the default is just to use all the other columns that you’re not pivoting). Pivot wider is tricky, however, in that you do need just one value for each combination of id columns.\nIf you’re still having trouble, you’re not alone, look at this article on how to create a code snippet that pops up to tell you exactly what to do, every time: (and there’s more about what “snippets” are in that article).\nsnippet plonger\n    pivot_longer(${1:mydf},\n                 cols = ${2:columns to pivot long},\n                 names_to = \"${3:desired name for category column}\",\n                 values_to = \"${4:desired name for value column}\"\n    )\n\nI struggled with the pivoting of tables on assignment #5, and still have some trouble wrapping my head around it– especially when we pivoted the long table back to wide but with different column names.\n\nOne difficult thing to grasp about pivoting is the idea of pivoting long, and then even longer (doubly long?), and then back again to wide but in a different way, with different information in the columns. This takes a lot of practice to get there without a lot of struggle. After you have done this many times you’ll be better able to see what you need out of the data frame and how to get it there. I wish we had more time to just pivot things in all sorts of ways, because it’s a powerful form of data manipulation!\n\nFaceting in ggplot I need to play with setting plot scales to actual values with “free_x/free_y”\n\nThis is something I think you’ll need to “play around with” to just, try some things and see how it affects the plot. The homework faceting is similar to the example plot we did in class last week, but, there’s a lot more you can do with faceting and it’s a very powerful way to display data. The ggplot2 book’s Faceting chapter is a nice review of this.\nI’ve also been meaning to mention that the ggplot2 package website has useful FAQs on lots of tricky subjects. Here’s the faceting one.\n\nReading the vignette for summarize and list. Can you explain how to read this vignette.\n\nSorry I couldn’t figure out which vignette you were talking about here, could you send me the link? Or maybe you are looking for a link… Usually if I mention a vignette in class I have the link the Rmd/html file. Otherwise, the best way to find package vignettes is by going to the package website. Most of the tidyverse packages have a website, and the vignettes will often be in the “Articles” drop down. For instance, here’s dplyr’s website and list of articles/vignettes, but I don’t see one on summarize/lists! You can also see vignettes in the CRAN package’s website usually, for instance here’s dplyr\n\nCan we go over how to create a summary table with percentages using summary and across?\n\nThis depends on exactly what you want to do. I might use one of the fancier functions like gtsummary::tbl_summary() or table1::table1 for a true “summary table” of all my categorical variables, but we can see how this would work with summarize() “by hand”. We are going to see in part6 some examples with tabyl, as well.\nHere’s an example just with summarize:\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(palmerpenguins)\n\n# First with tabyl, using adorn_ (which we will see in part6 today)\npenguins %&gt;%\n  tabyl(species, sex) %&gt;%\n  adorn_percentages() %&gt;%\n  adorn_pct_formatting()\n\n   species female  male  NA_\n    Adelie  48.0% 48.0% 3.9%\n Chinstrap  50.0% 50.0% 0.0%\n    Gentoo  46.8% 49.2% 4.0%\n\n# try to get the same information with summarize:\npenguins %&gt;%\n  group_by(species) %&gt;%\n  summarize(pct_male = sum(sex==\"male\", na.rm = TRUE)/length(sex),\n            pct_female = sum(sex==\"female\", na.rm = TRUE)/length(sex),\n            pct_NA = sum(is.na(sex), na.rm = TRUE)/length(sex)) %&gt;%\n  mutate(across(where(is.numeric), ~.x*100))\n\n# A tibble: 3 × 4\n  species   pct_male pct_female pct_NA\n  &lt;fct&gt;        &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie        48.0       48.0   3.95\n2 Chinstrap     50         50     0   \n3 Gentoo        49.2       46.8   4.03\n\n# mean also works:\npenguins %&gt;%\n  group_by(species) %&gt;%\n  summarize(pct_male = mean(sex==\"male\", na.rm = TRUE),\n            pct_female = mean(sex==\"female\", na.rm = TRUE),\n            pct_NA = mean(is.na(sex), na.rm = TRUE)) %&gt;%\n  mutate(across(where(is.numeric), ~.x*100))\n\n# A tibble: 3 × 4\n  species   pct_male pct_female pct_NA\n  &lt;fct&gt;        &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie        50         50     3.95\n2 Chinstrap     50         50     0   \n3 Gentoo        51.3       48.7   4.03\n\n\nBut it’s hard to generalize that specific summarize to other columns with across(), because nothing else has the category “male”, “female”. You’d need your data to be in quite a particular format, so I think this not something you’ll commonly do. You could calculate proportion missing, though, which is a similar idea:\n\npenguins %&gt;% group_by(species) %&gt;%\n  summarize(across(everything(), .fns= ~ mean(is.na(.x))))\n\n# A tibble: 3 × 15\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;      &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie         0        0.00658       0.00658           0.00658     0.00658\n2 Chinstrap      0        0             0                 0           0      \n3 Gentoo         0        0.00806       0.00806           0.00806     0.00806\n# ℹ 9 more variables: sex &lt;dbl&gt;, year &lt;dbl&gt;, long_bill1 &lt;dbl&gt;,\n#   long_bill2 &lt;dbl&gt;, long_bill3 &lt;dbl&gt;, long_bill4 &lt;dbl&gt;, newvec &lt;dbl&gt;,\n#   large_mass &lt;dbl&gt;, bill_length_cm &lt;dbl&gt;\n\n\n\n\nClearest Points\nLots of joining and binding, great!\n\nOutlining the steps you took and what you are looking for in the data was really helpful.\n\n\nI really liked the flow of explanation on data management yesterday, thank you!\n\nThat’s great to hear, I almost completely got rid of part6 because I wasn’t sure if it would be that helpful. Hopefully it provided some useful practice with messier data!\n\n\nOther\n\nWe followed an example where we had a graph to strive for, but is there an example or just advice you can provide when we don’t have that? How do you know to leave the demographic information aside and only join the other data first?\n\nI don’t think there’s good one size fits all advice here. For that particular question, I could have joined the demographic data with each piece of the other data, that is also an option. That also would have avoided the need for bind_rows(), so that’s a good point. I do tend to create separate data sets by “type” so for instance in that example I wanted all of the biomarker/outcome data together, just so I knew where it was. That’s my main reason for binding those data together first.\n\nWorking with messy data seems very scary!!!\n\n\nIt’s so useful to learn how to work with super messy data because unfortunately that’s often how people have their data set up!\n\nMessy data is scary, I agree!\n\nWhy do you use here::here sometimes and other times it’s just here without the here:: preceding it?\n\nUsually pckgname::functioname() is not necessary but used for clarification where that function is coming from. I sometimes do that in case I haven’t loaded the package first. Since I often use the here package at the beginning of my script when loading in data for an analysis, I’m not used to loading like other packages, but instead just call that function by using here::here(), so it’s somewhat due to habit!",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-8",
    "href": "survey_feedback_previous_years.html#week-8",
    "title": "Survey Feedback",
    "section": "Week 8",
    "text": "Week 8\n\nMuddiest Points\nDefinitely functions, several comments like this:\n\ncreating our own functions still seems pretty daunting. the error check in particular I am still very confused about how to write a function. I probably should practice more. Making custom function seems to be so useful, but I need to be more familiar with this.\n\nYes this will definitely take practice! If you’re doing the assigned readings, you’ll have read the R for Data Science chapter on functions which I find to be a good intro to this concept, but also the suggested reading on this topic is very good too, and I recommend it if you are still confused: Harvard Chan Bioinformatics Core’s lesson on “Functions in R”. The Software Carpentry’s lesson on functions in R is also good, with some info on error handling.\nHopefully doing the homework provided some good practice with functions. My tip to you is to really think about what is your input (argument) and what is your output (return).\nI also would not worry about error handling (using stop(), and if() etc) until you are really a pro at making the functions work without all that extra stuff.\n\nThings with periods (.namerepair, .x, .fns) and just the general flow of what you can and can’t string together in a function\n\nNote that things with periods are just an alternate way of naming arguments. I don’t do that for my custom functions because I’m not making complicated functions generally, but a lot of tidyverse functions do. There is a reason for this, which is explained in the Tidyverse design guide Dot prefix chapter.\nThis has to do with the ... argument which I briefly mentioned in one class. When you see this as an argument to a function it means that arguments supplied there are passed on to other functions. For instance, look at the simple base R function plot documentation (?plot). The explanation for the ... is this:\n\n… Arguments to be passed to methods, such as graphical parameters (see par). Many methods will accept the following arguments:\n\nSo any arguments specified after x and y inside plot() such as title = \"My Plot\" will be passed to be arguments of the function par().\nThe dot prefix chapter therefore says:\n\nWhen using … to create a data structure, or when passing … to a user-supplied function, add a . prefix to all named arguments. This reduces (but does not eliminate) the chances of matching an argument at the wrong level. Additionally, you should always provide some mechanism that allows you to escape and use that name if needed.\n\nIf you look therefore at the help for ?purrr::map you can see that the argument names start with a dot (.x and .f and .progress) and then everything else is passed to the function specified in .f.\nObviously this is next level stuff, things to think about when designing your own packages, not just simple functions only you will use/see. So don’t worry about it other than to know that some arguments start with a dot and some don’t, they are used the same way!\n\n\nClearest points\n\nList’ was unfamiliar for me, but the concept was clear.\n\nCool, more with lists today!\n\nIt was great to learn functions in R Using gt() to make the table was really nice and clear to me.\n\nGreat!\n\n\nOther\n\ngt() always seems to make my RStudio slow and glitchy. When I try to scroll past a gt() table, R Studio will freeze for a moment. Is that normal? Is there anything I can do?\n\nI have this same problem with some gtsummary() functions that use gt(), I think it depends on how much memory your computer has free, at least that is my guess. I think these do take a little bit to render and your computer may freeze because it’s doing a lot of “thinking”. If you google this issue and look on the gt package issues page on github you can see it isn’t a new or rare problem. If it really is troublesome, I’d make sure you closed all your other windows/software on your computer, or maybe just switch to kable and kableExtra packages.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "survey_feedback_previous_years.html#week-9",
    "href": "survey_feedback_previous_years.html#week-9",
    "title": "Survey Feedback",
    "section": "Week 9",
    "text": "Week 9\n\nMuddiest Points\nA lot of things were difficult including “this whole class” as one person said, and yeah, I get it, it’s hard stuff! The reason I teach these harder topics like for loops, functions, map, etc, as opposed to just going over more of the same kind of data cleaning tasks with various examples, is because it’s a lot harder to be motivated to learn the hard stuff if you’ve never been exposed to it. It will probably seem too daunting (I know this because it took me a long time to force myself to learn ggplot, or purrr::map, or even across and the new pivot_longer because I already had other ways of doing that).\nYou have the tools by now to learn how to do other data cleaning tasks related to what we’ve learned (i.e. more factor and string manipulation, even working with dates will not be that hard to figure out).\nAlso, part of the reason R is so powerful and useful is that it’s a “real” programming language (more similar to C, python, java, etc than SPSS or even SAS or STATA). This part of it will take a lot of practice to feel comfortable if you haven’t had any programming experience. If you have had programming experience, seeing how it’s done in R will get you started in the right direction to using the R-specific programming tools like purrr::map that are truly so useful when automating data tasks.\n\nfor loop was a bit confusing when making empty vector\n\nIt really is, and is why I recommend not using for loops but embracing map()! We could get even more technical and talk about how it’s actually better (faster/efficient) to specify the length or dimension of the empty vector (or data frame, or list, or whatever, this is called pre-allocation) because of how memory is allocated in R, but, no, I refuse to go down that rabbit hole and just say, use map()!\nSide note: If you’re working with data with millions of records, you’ll have plenty of speed issues to worry about, and you need an even more advanced R programming class focused on big data.\n\nI think the whole creation of the function is still quite a bit hazy for me. I believe it’s something that just takes some more practice. Hoping we can fit some more practice challenges to help really build this understanding.\n\nWe will start class with another function example, but please ask questions about anything confusing about it during class, too!\n\nI am still struggling with functions! In the reading on functions, I got confused about the difference between the && || operators and the & | operators.. The reading said “beware of floating point numbers” and I’m not sure what that is.\n\nAs we saw in class, the & “and” operator and | “or” operator are logic operators used to string one condition to another, such as:\n\nthing &lt;- 3\nis.na(thing) | thing == 3\n\n[1] TRUE\n\nis.na(thing) & thing == 3\n\n[1] FALSE\n\n\nBut remember we talked about how most functions in R are vectorized, which means they work seamlessly over a vector. This is true for | and & as well. However, if you didn’t want that vectorized behavior and only wanted to check the first elements of a vector you’d use the double && and ||. This becomes useful for if statements, but, you likely don’t need to worry about it, and you probably want the single & |.\n\nthing &lt;- 1:3\nis.na(thing) | thing == 3\n\n[1] FALSE FALSE  TRUE\n\nis.na(thing) & thing == 3\n\n[1] FALSE FALSE FALSE\n\n# no longer works\n# is.na(thing) || (thing == 3)\n# is.na(thing) && (thing == 3)\n\nAnother very specific situation mentioned in that reading is that floating point numbers (numeric values with lots of numbers after the decimal point) sometimes due to computational rounding/storage will not be exactly equal to each other so you just need to be wary of using == there. The example from the reading sums it up well:\n\nthing &lt;- sqrt(2)^2 # should be 2, right?\n2==thing # huh\n\n[1] FALSE\n\nidentical(2,thing) # weird\n\n[1] FALSE\n\n2 - thing # extremely small value\n\n[1] -4.440892e-16\n\n# I used to check for \"equality\" this way...before I knew about dplyr::near()\n(2-thing) &lt; 1e-16\n\n[1] TRUE\n\ndplyr::near(2,thing)\n\n[1] TRUE\n\n\n\nStill struggling with the difference between [[]] and [] and unclear on whether that distinction is actually important functionally.\n\nIt is very important functionally, if you think back to your homework question where you got different data types depending on which you use. Sometimes you want a list, sometimes you don’t want a list. Usually you only want a list ( i.e. list[1:2]) if you are asking for multiple elements of a list, otherwise you’re wanting to pull out what’s inside that “slot” and use list[[1]].\nNote that a lot of newer packages make dealing with complex lists less common than it used to be. The example I gave was the broom package tidy() function. In the past, we all learned how to pull out parts of regression output by accessing parts of the list using [[]] and $, just like I showed in class. Probably a lot of your biostats classes still do it this way because that is how your professor learned it. But, now we just need to use broom::tidy() to get a data frame of coefficients, confidence intervals, and p-values.\n\nIf pluck and pull do the same thing, is there any advantage to using one over the other?\n\nAs I mentioned last class, pluck and pull are similar in that they “pull out” elements from lists but they are used differently so there can not be any “advantage”. pluck is for lists and pull is for data frames (which are also lists, but you can’t use pull on a non-df list! you need to use pluck in that case).\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n# try this on your own\n# a list that is not a data frame\n# WHY is it not a data frame?\nmylist &lt;- list(\"a\"=1:3, \"b\" = 2) \n# mylist %&gt;% pull(\"a\")\n# Error in UseMethod(\"pull\") : \n#  no applicable method for 'pull' applied to an object of class \"list\"\n\nSide note, see the difference here:\n\nas.data.frame(mylist)\n\n  a b\n1 1 2\n2 2 2\n3 3 2\n\nmylist &lt;- list(\"a\"=1:3, \"b\"=2:4)\nmylist\n\n$a\n[1] 1 2 3\n\n$b\n[1] 2 3 4\n\nas.data.frame(mylist)\n\n  a b\n1 1 2\n2 2 3\n3 3 4\n\n\nIf we do have a data frame/tibble and want to “pull out” a column as a vector (not as a data frame), we are also pulling out an element from a list because a data frame is also a list!\nHere is how we would use pull and pluck to do the “same thing” on a data frame:\n\n# remember a tibble is a special kind of data frame, which is a special kind of list\nstr(penguins)\n\ntibble [344 × 15] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n $ long_bill1       : chr [1:344] \"not long\" \"not long\" \"not long\" NA ...\n $ long_bill2       : chr [1:344] \"not long\" \"not long\" \"not long\" NA ...\n $ long_bill3       : chr [1:344] \"short\" \"short\" \"medium\" \"medium\" ...\n $ long_bill4       : chr [1:344] \"short\" \"short\" \"medium\" NA ...\n $ newvec           : num [1:344] 2.09 2.27 2.24 NA 1.9 ...\n $ large_mass       : chr [1:344] \"no\" \"no\" \"no\" NA ...\n $ bill_length_cm   : num [1:344] 3.91 3.95 4.03 NA 3.67 3.93 3.89 3.92 3.41 4.2 ...\n\nclass(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\ntypeof(penguins)\n\n[1] \"list\"\n\n\n\ns = penguins %&gt;% pull(species)\nstr(s)\n\n Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n# does not work because you need quotes for a list element names\n# s2 = penguins %&gt;% pluck(species)\n# Error in list2(...) : object 'species' not found\n\ns2 = penguins %&gt;% pluck(\"species\")\nstr(s2)\n\n Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n# are they the same?\nidentical(s, s2)\n\n[1] TRUE\n\n\nI am not in the habit of using pluck yet, because I am used to [[]] and use it when I need it. I do use pull all the time to get a vector, though, for example:\n\npenguins %&gt;% \n  group_by(species) %&gt;%\n  summarize(m = mean(bill_length_mm, na.rm = TRUE)) %&gt;%\n  pull(m)\n\n[1] 38.79139 48.83382 47.50488\n\n\nOr let’s say I want a list of patient (penguin) ids of a subset:\n\nmypenguins &lt;- penguins %&gt;%\n  mutate(id = row_number(), .before = \"species\")\n\nmypenguins %&gt;% \n  filter(bill_length_mm &lt; 35)\n\n# A tibble: 9 × 16\n     id species island    bill_length_mm bill_depth_mm flipper_length_mm\n  &lt;int&gt; &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n1     9 Adelie  Torgersen           34.1          18.1               193\n2    15 Adelie  Torgersen           34.6          21.1               198\n3    19 Adelie  Torgersen           34.4          18.4               184\n4    55 Adelie  Biscoe              34.5          18.1               187\n5    71 Adelie  Torgersen           33.5          19                 190\n6    81 Adelie  Torgersen           34.6          17.2               189\n7    93 Adelie  Dream               34            17.1               185\n8    99 Adelie  Dream               33.1          16.1               178\n9   143 Adelie  Dream               32.1          15.5               188\n# ℹ 10 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;int&gt;,\n#   long_bill1 &lt;chr&gt;, long_bill2 &lt;chr&gt;, long_bill3 &lt;chr&gt;, long_bill4 &lt;chr&gt;,\n#   newvec &lt;dbl&gt;, large_mass &lt;chr&gt;, bill_length_cm &lt;dbl&gt;\n\nids_short_bill &lt;- mypenguins %&gt;% \n  filter(bill_length_mm &lt; 35) %&gt;% \n  pull(id)\n\nNow I have a vector of IDs that satisfy my bill length requirements.\n\nids_short_bill\n\n[1]   9  15  19  55  71  81  93  99 143\n\n\n\nI just want to check my understanding is correct. The map() is for list and it can be used as itself, but the across() function is only for data frame or tibble and can be used inside the mutate() function. Is that correct? Then, can we use any function inside those map(), and mutate() ?\n\nI really like this distinction and clarification! Yes to this part\n\nmap() can be used by itself like, list %&gt;% map(.f = length), applied to a list or vector\nacross() can only be used as a helper function inside mutate or summarize applied to a data frame/tibble\n\nAlso:\n\ninside across() we need to use very specific syntax which is called tidyselect.\nThink of across() and select() as friends, because they use the same language to select columns.\n\nBut across() is used more like map() in that it takes a “what” argument (.cols = tidy select columns for across, .x = a list or vector for map) and “function” argument (.fns= for across because multiple functions can be supplied, .f= for map because only one function can be applied)\n\nlibrary(palmerpenguins)\n\npenguins %&gt;% select(where(is.numeric))\n\n# A tibble: 344 × 7\n   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year newvec\n            &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n 1           39.1          18.7               181        3750  2007   2.09\n 2           39.5          17.4               186        3800  2007   2.27\n 3           40.3          18                 195        3250  2007   2.24\n 4           NA            NA                  NA          NA  2007  NA   \n 5           36.7          19.3               193        3450  2007   1.90\n 6           39.3          20.6               190        3650  2007   1.91\n 7           38.9          17.8               181        3625  2007   2.19\n 8           39.2          19.6               195        4675  2007   2   \n 9           34.1          18.1               193        3475  2007   1.88\n10           42            20.2               190        4250  2007   2.08\n# ℹ 334 more rows\n# ℹ 1 more variable: bill_length_cm &lt;dbl&gt;\n\n# penguins %&gt;% across(where(is.numeric))\n# Error in `across()`:\n# ! Must only be used inside data-masking verbs like `mutate()`,\n#   `filter()`, and `group_by()`.\n\n# mutate requires a function that returns a vector the same length as the original vector\npenguins %&gt;% mutate(across(.cols = where(is.numeric), .f = as.character))\n\n# A tibble: 344 × 15\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;     &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;             &lt;chr&gt;      \n 1 Adelie  Torgersen 39.1           18.7          181               3750       \n 2 Adelie  Torgersen 39.5           17.4          186               3800       \n 3 Adelie  Torgersen 40.3           18            195               3250       \n 4 Adelie  Torgersen &lt;NA&gt;           &lt;NA&gt;          &lt;NA&gt;              &lt;NA&gt;       \n 5 Adelie  Torgersen 36.7           19.3          193               3450       \n 6 Adelie  Torgersen 39.3           20.6          190               3650       \n 7 Adelie  Torgersen 38.9           17.8          181               3625       \n 8 Adelie  Torgersen 39.2           19.6          195               4675       \n 9 Adelie  Torgersen 34.1           18.1          193               3475       \n10 Adelie  Torgersen 42             20.2          190               4250       \n# ℹ 334 more rows\n# ℹ 9 more variables: sex &lt;fct&gt;, year &lt;chr&gt;, long_bill1 &lt;chr&gt;,\n#   long_bill2 &lt;chr&gt;, long_bill3 &lt;chr&gt;, long_bill4 &lt;chr&gt;, newvec &lt;chr&gt;,\n#   large_mass &lt;chr&gt;, bill_length_cm &lt;chr&gt;\n\n# this works but it shouldn't and is \"deprecated\" in dplyr 1.1.0\n# summarize SHOULD return a vector of length 1\npenguins %&gt;% summarize(across(.cols = where(is.numeric), .f = as.character))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n# A tibble: 344 × 7\n   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g year  newvec      \n   &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;       \n 1 39.1           18.7          181               3750        2007  2.090909090…\n 2 39.5           17.4          186               3800        2007  2.270114942…\n 3 40.3           18            195               3250        2007  2.238888888…\n 4 &lt;NA&gt;           &lt;NA&gt;          &lt;NA&gt;              &lt;NA&gt;        2007  &lt;NA&gt;        \n 5 36.7           19.3          193               3450        2007  1.901554404…\n 6 39.3           20.6          190               3650        2007  1.907766990…\n 7 38.9           17.8          181               3625        2007  2.185393258…\n 8 39.2           19.6          195               4675        2007  2           \n 9 34.1           18.1          193               3475        2007  1.883977900…\n10 42             20.2          190               4250        2007  2.079207920…\n# ℹ 334 more rows\n# ℹ 1 more variable: bill_length_cm &lt;chr&gt;\n\npenguins %&gt;% summarize(across(.cols = where(is.numeric), .f = length))\n\n# A tibble: 1 × 7\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year newvec\n           &lt;int&gt;         &lt;int&gt;             &lt;int&gt;       &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n1            344           344               344         344   344    344\n# ℹ 1 more variable: bill_length_cm &lt;int&gt;\n\nmylist &lt;- list(\"a\"=1:3, \"b\" = 2, c = penguins) \n\n# .x can be piped into map or used as an explicit argument\nmylist %&gt;% map(.f = length)\n\n$a\n[1] 3\n\n$b\n[1] 1\n\n$c\n[1] 15\n\nmap(.x = mylist, .f = length)\n\n$a\n[1] 3\n\n$b\n[1] 1\n\n$c\n[1] 15\n\n# this also works because penguins is a data frame which means it is also a list (columns are elements)\npenguins %&gt;% map(.f = length)\n\n$species\n[1] 344\n\n$island\n[1] 344\n\n$bill_length_mm\n[1] 344\n\n$bill_depth_mm\n[1] 344\n\n$flipper_length_mm\n[1] 344\n\n$body_mass_g\n[1] 344\n\n$sex\n[1] 344\n\n$year\n[1] 344\n\n$long_bill1\n[1] 344\n\n$long_bill2\n[1] 344\n\n$long_bill3\n[1] 344\n\n$long_bill4\n[1] 344\n\n$newvec\n[1] 344\n\n$large_mass\n[1] 344\n\n$bill_length_cm\n[1] 344\n\nmap(.x = penguins, .f = length)\n\n$species\n[1] 344\n\n$island\n[1] 344\n\n$bill_length_mm\n[1] 344\n\n$bill_depth_mm\n[1] 344\n\n$flipper_length_mm\n[1] 344\n\n$body_mass_g\n[1] 344\n\n$sex\n[1] 344\n\n$year\n[1] 344\n\n$long_bill1\n[1] 344\n\n$long_bill2\n[1] 344\n\n$long_bill3\n[1] 344\n\n$long_bill4\n[1] 344\n\n$newvec\n[1] 344\n\n$large_mass\n[1] 344\n\n$bill_length_cm\n[1] 344\n\n\nHowever, as we will see in class today, we also can use map() inside mutate() when we are using nested data frames, or when we need to “vectorize” a non-vectorized function. In this case, map() is being applied to a list of data that is inside a column of a data frame….it’s complicated, and we’ll see more today.\n\n\nClearest points\nFor every topic in the muddy list it was also in the clear list, so at least it’s not all lost. I think more practice will help.",
    "crumbs": [
      "Home",
      "Survey Feedback"
    ]
  },
  {
    "objectID": "readings/07-reading.html#required",
    "href": "readings/07-reading.html#required",
    "title": "Week 7 Readings",
    "section": "Required",
    "text": "Required\n\nIntroduction to Functions and Arguments\nIntroduction to Lists in R\nFunctions in R for Data Science"
  },
  {
    "objectID": "readings/07-reading.html#suggested",
    "href": "readings/07-reading.html#suggested",
    "title": "Week 7 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nVectors and Lists - Jenny Bryan\nWould also recommend reading week 8’s readings in advance!"
  },
  {
    "objectID": "readings/09-reading.html#required",
    "href": "readings/09-reading.html#required",
    "title": "Week 9 Readings",
    "section": "Required",
    "text": "Required\n\nIteration in R for Data Science\nLearn to purrr"
  },
  {
    "objectID": "readings/09-reading.html#suggested",
    "href": "readings/09-reading.html#suggested",
    "title": "Week 9 Readings",
    "section": "Suggested",
    "text": "Suggested\n\nIntroduction to map() - Jenny Bryan\nSoftware Carpentry’s lesson on functions in R"
  },
  {
    "objectID": "function_week/presentation_example.html",
    "href": "function_week/presentation_example.html",
    "title": "dplyr::slice",
    "section": "",
    "text": "In this document, I will introduce the slice() function and show what it’s for.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(penguins)\n\n\n\nSay you want the first 7 rows of a table. Well, slice() is an easy way to do that. The slice() function accepts two arguments: The first is the dataset, and the second is the range of values you want to extract.\n\nslice(penguins, 1:7)\n\n# A tibble: 7 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n7 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nslice() is much more helpful in a tidy workflow, so you can see the first few rows of the data when you’re processing. This is really helpful when you’re building up a pipeline and need to show intermediate output without showing the entire table.\n\npenguins %&gt;%\n  slice(1:7)\n\n# A tibble: 7 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n7 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\nYes, when you need to just show part of a table as an example, slice() can come in handy. I don’t use it everyday, but it can come in handy."
  },
  {
    "objectID": "function_week/presentation_example.html#what-is-it-for",
    "href": "function_week/presentation_example.html#what-is-it-for",
    "title": "dplyr::slice",
    "section": "",
    "text": "Say you want the first 7 rows of a table. Well, slice() is an easy way to do that. The slice() function accepts two arguments: The first is the dataset, and the second is the range of values you want to extract.\n\nslice(penguins, 1:7)\n\n# A tibble: 7 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n7 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nslice() is much more helpful in a tidy workflow, so you can see the first few rows of the data when you’re processing. This is really helpful when you’re building up a pipeline and need to show intermediate output without showing the entire table.\n\npenguins %&gt;%\n  slice(1:7)\n\n# A tibble: 7 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n7 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "function_week/presentation_example.html#is-it-helpful",
    "href": "function_week/presentation_example.html#is-it-helpful",
    "title": "dplyr::slice",
    "section": "",
    "text": "Yes, when you need to just show part of a table as an example, slice() can come in handy. I don’t use it everyday, but it can come in handy."
  },
  {
    "objectID": "function_week/Bovenkamp_fotw.html",
    "href": "function_week/Bovenkamp_fotw.html",
    "title": "forcats::fct_collapse",
    "section": "",
    "text": "In this document, I will introduce the fct_collapse function that allows you to collapse factor levels into manually defined groups.\n\n\nThe fct_collapse function accepts a factor or character vector and multiple named character levels. ‘fct_collapse’ consolidates several factor levels into fewer groups. Let’s look at tumor_stage:\n\n#mutating tumor_stage into a factor\n\nsmoke_complete2 &lt;- smoke_complete %&gt;% \n    mutate(stage_factor = \n               factor(tumor_stage,\n                      levels = c(\"not reported\", \n                                 \"stage i\", \n                                 \"stage ia\", \n                                 \"stage ib\", \n                                 \"stage ii\", \n                                 \"stage iia\", \n                                 \"stage iib\", \n                                 \"stage iii\", \n                                 \"stage iiia\", \n                                 \"stage iiib\", \n                                 \"stage iv\")))\n\n\nsmoke_complete2 %&gt;% \n  select(stage_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,1521\n    \n  \n  \n    stage_factor\n\n        not reported\n99 (8.6%)\n        stage i\n7 (0.6%)\n        stage ia\n146 (13%)\n        stage ib\n266 (23%)\n        stage ii\n65 (5.6%)\n        stage iia\n112 (9.7%)\n        stage iib\n148 (13%)\n        stage iii\n86 (7.5%)\n        stage iiia\n102 (8.9%)\n        stage iiib\n30 (2.6%)\n        stage iv\n91 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nThat’s a lot of levels right? Here are visual examples of the tumor_stage variable before any manipulation:\n\n#boxplot\nggplot(smoke_complete2) +\n  aes(x = tumor_stage, y = cigarettes_per_day) +\n  geom_boxplot() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\") +\n  ylim(c(0,15))\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n#bar graph\nggplot(smoke_complete2) +\n  aes(x = tumor_stage, y = cigarettes_per_day) +\n  geom_col() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\")\n\n\n\n\nHaving a large amount of categories can be overwhelming in some graphics. There are distinguishable categories that these levels could be reduced to using ‘fct_collapse’.\n\nsmoke_complete3 &lt;- smoke_complete2 %&gt;% \n  mutate(stage_collapsed = fct_collapse(\n    stage_factor,\n    not_reported = c(\"not reported\"),\n    stage_i = c(\"stage i\", \"stage ia\", \"stage ib\"),\n    stage_ii = c(\"stage ii\", \"stage iia\", \"stage iib\"),\n    stage_iii = c(\"stage iii\", \"stage iiia\", \"stage iiib\"),\n    stage_iv = c(\"stage iv\"))) %&gt;% \n  glimpse()\n\nRows: 1,152\nColumns: 22\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;chr&gt; \"371\", \"136\", \"2304\", \"NA\", \"NA\", \"345\", \"…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24477, -26615, -28171, -27154, -23370, -1…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;chr&gt; \"NA\", \"NA\", \"2099\", \"3747\", \"3576\", \"NA\", …\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;chr&gt; \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", …\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;chr&gt; \"1936\", \"1931\", \"1927\", \"1930\", \"1942\", \"1…\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;chr&gt; \"2004\", \"2003\", \"NA\", \"NA\", \"NA\", \"2005\", …\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n$ stage_factor                &lt;fct&gt; stage ia, stage ib, stage ib, stage ia, st…\n$ stage_collapsed             &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n\n\nYou can also use the ‘other_level’ argument to set any category levels you’d like to ‘NA’.\n\nsmoke_complete4 &lt;- smoke_complete3 %&gt;% \n  mutate(stage_collapsed_na = fct_collapse(\n    stage_factor,\n    not_reported = c(\"not reported\"),\n    stage_i = c(\"stage i\", \"stage ia\", \"stage ib\"),\n    stage_ii = c(\"stage ii\", \"stage iia\", \"stage iib\"),\n    stage_iii = c(\"stage iii\", \"stage iiia\", \"stage iiib\"),\n    other_level = NA)) %&gt;% \n  glimpse()\n\nRows: 1,152\nColumns: 23\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;chr&gt; \"371\", \"136\", \"2304\", \"NA\", \"NA\", \"345\", \"…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24477, -26615, -28171, -27154, -23370, -1…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;chr&gt; \"NA\", \"NA\", \"2099\", \"3747\", \"3576\", \"NA\", …\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;chr&gt; \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", …\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;chr&gt; \"1936\", \"1931\", \"1927\", \"1930\", \"1942\", \"1…\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;chr&gt; \"2004\", \"2003\", \"NA\", \"NA\", \"NA\", \"2005\", …\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n$ stage_factor                &lt;fct&gt; stage ia, stage ib, stage ib, stage ia, st…\n$ stage_collapsed             &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n$ stage_collapsed_na          &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n\n\nNow there are 5 factor levels instead of 11.\n\nsmoke_complete3 %&gt;% \n  select(stage_collapsed) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,1521\n    \n  \n  \n    stage_collapsed\n\n        not_reported\n99 (8.6%)\n        stage_i\n419 (36%)\n        stage_ii\n325 (28%)\n        stage_iii\n218 (19%)\n        stage_iv\n91 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\nggplot(smoke_complete3) +\n  aes(x = stage_collapsed, y = cigarettes_per_day) +\n  geom_boxplot() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\") +\n  ylim(c(0,15))\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n#bar graph\nggplot(smoke_complete3) +\n  aes(x = stage_collapsed, y = cigarettes_per_day) +\n  geom_col() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\")\n\n\n\n\n\n\n\nCollapsing factor levels could be done in general when variables have broader classifications that many levels could be reduced under. ‘fct_collapse’ can help with data visualization and comparing groups together. This function is very useful when working with large data sets or a data set like ‘smoke_complete’ where there are variables with ordered categories and subcategories. Many other ‘fct_ …’ functions can be used in conjunction with ‘fct_collapse’ to further manipulate factor levels."
  },
  {
    "objectID": "function_week/Bovenkamp_fotw.html#what-is-it-for",
    "href": "function_week/Bovenkamp_fotw.html#what-is-it-for",
    "title": "forcats::fct_collapse",
    "section": "",
    "text": "The fct_collapse function accepts a factor or character vector and multiple named character levels. ‘fct_collapse’ consolidates several factor levels into fewer groups. Let’s look at tumor_stage:\n\n#mutating tumor_stage into a factor\n\nsmoke_complete2 &lt;- smoke_complete %&gt;% \n    mutate(stage_factor = \n               factor(tumor_stage,\n                      levels = c(\"not reported\", \n                                 \"stage i\", \n                                 \"stage ia\", \n                                 \"stage ib\", \n                                 \"stage ii\", \n                                 \"stage iia\", \n                                 \"stage iib\", \n                                 \"stage iii\", \n                                 \"stage iiia\", \n                                 \"stage iiib\", \n                                 \"stage iv\")))\n\n\nsmoke_complete2 %&gt;% \n  select(stage_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,1521\n    \n  \n  \n    stage_factor\n\n        not reported\n99 (8.6%)\n        stage i\n7 (0.6%)\n        stage ia\n146 (13%)\n        stage ib\n266 (23%)\n        stage ii\n65 (5.6%)\n        stage iia\n112 (9.7%)\n        stage iib\n148 (13%)\n        stage iii\n86 (7.5%)\n        stage iiia\n102 (8.9%)\n        stage iiib\n30 (2.6%)\n        stage iv\n91 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nThat’s a lot of levels right? Here are visual examples of the tumor_stage variable before any manipulation:\n\n#boxplot\nggplot(smoke_complete2) +\n  aes(x = tumor_stage, y = cigarettes_per_day) +\n  geom_boxplot() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\") +\n  ylim(c(0,15))\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n#bar graph\nggplot(smoke_complete2) +\n  aes(x = tumor_stage, y = cigarettes_per_day) +\n  geom_col() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\")\n\n\n\n\nHaving a large amount of categories can be overwhelming in some graphics. There are distinguishable categories that these levels could be reduced to using ‘fct_collapse’.\n\nsmoke_complete3 &lt;- smoke_complete2 %&gt;% \n  mutate(stage_collapsed = fct_collapse(\n    stage_factor,\n    not_reported = c(\"not reported\"),\n    stage_i = c(\"stage i\", \"stage ia\", \"stage ib\"),\n    stage_ii = c(\"stage ii\", \"stage iia\", \"stage iib\"),\n    stage_iii = c(\"stage iii\", \"stage iiia\", \"stage iiib\"),\n    stage_iv = c(\"stage iv\"))) %&gt;% \n  glimpse()\n\nRows: 1,152\nColumns: 22\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;chr&gt; \"371\", \"136\", \"2304\", \"NA\", \"NA\", \"345\", \"…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24477, -26615, -28171, -27154, -23370, -1…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;chr&gt; \"NA\", \"NA\", \"2099\", \"3747\", \"3576\", \"NA\", …\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;chr&gt; \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", …\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;chr&gt; \"1936\", \"1931\", \"1927\", \"1930\", \"1942\", \"1…\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;chr&gt; \"2004\", \"2003\", \"NA\", \"NA\", \"NA\", \"2005\", …\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n$ stage_factor                &lt;fct&gt; stage ia, stage ib, stage ib, stage ia, st…\n$ stage_collapsed             &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n\n\nYou can also use the ‘other_level’ argument to set any category levels you’d like to ‘NA’.\n\nsmoke_complete4 &lt;- smoke_complete3 %&gt;% \n  mutate(stage_collapsed_na = fct_collapse(\n    stage_factor,\n    not_reported = c(\"not reported\"),\n    stage_i = c(\"stage i\", \"stage ia\", \"stage ib\"),\n    stage_ii = c(\"stage ii\", \"stage iia\", \"stage iib\"),\n    stage_iii = c(\"stage iii\", \"stage iiia\", \"stage iiib\"),\n    other_level = NA)) %&gt;% \n  glimpse()\n\nRows: 1,152\nColumns: 23\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;chr&gt; \"371\", \"136\", \"2304\", \"NA\", \"NA\", \"345\", \"…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24477, -26615, -28171, -27154, -23370, -1…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;chr&gt; \"NA\", \"NA\", \"2099\", \"3747\", \"3576\", \"NA\", …\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;chr&gt; \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", …\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;chr&gt; \"1936\", \"1931\", \"1927\", \"1930\", \"1942\", \"1…\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;chr&gt; \"2004\", \"2003\", \"NA\", \"NA\", \"NA\", \"2005\", …\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n$ stage_factor                &lt;fct&gt; stage ia, stage ib, stage ib, stage ia, st…\n$ stage_collapsed             &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n$ stage_collapsed_na          &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n\n\nNow there are 5 factor levels instead of 11.\n\nsmoke_complete3 %&gt;% \n  select(stage_collapsed) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,1521\n    \n  \n  \n    stage_collapsed\n\n        not_reported\n99 (8.6%)\n        stage_i\n419 (36%)\n        stage_ii\n325 (28%)\n        stage_iii\n218 (19%)\n        stage_iv\n91 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\nggplot(smoke_complete3) +\n  aes(x = stage_collapsed, y = cigarettes_per_day) +\n  geom_boxplot() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\") +\n  ylim(c(0,15))\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n#bar graph\nggplot(smoke_complete3) +\n  aes(x = stage_collapsed, y = cigarettes_per_day) +\n  geom_col() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\")"
  },
  {
    "objectID": "function_week/Bovenkamp_fotw.html#is-it-helpful",
    "href": "function_week/Bovenkamp_fotw.html#is-it-helpful",
    "title": "forcats::fct_collapse",
    "section": "",
    "text": "Collapsing factor levels could be done in general when variables have broader classifications that many levels could be reduced under. ‘fct_collapse’ can help with data visualization and comparing groups together. This function is very useful when working with large data sets or a data set like ‘smoke_complete’ where there are variables with ordered categories and subcategories. Many other ‘fct_ …’ functions can be used in conjunction with ‘fct_collapse’ to further manipulate factor levels."
  },
  {
    "objectID": "function_week/Bovenkamp_fct_collapse.html",
    "href": "function_week/Bovenkamp_fct_collapse.html",
    "title": "forcats::fct_collapse",
    "section": "",
    "text": "In this document, I will introduce the fct_collapse function that allows you to collapse factor levels into manually defined groups.\n\n\nThe fct_collapse function accepts a factor or character vector and multiple named character levels. ‘fct_collapse’ consolidates several factor levels into fewer groups. Let’s look at tumor_stage:\n\n#mutating tumor_stage into a factor\n\nsmoke_complete2 &lt;- smoke_complete %&gt;% \n    mutate(stage_factor = \n               factor(tumor_stage,\n                      levels = c(\"not reported\", \n                                 \"stage i\", \n                                 \"stage ia\", \n                                 \"stage ib\", \n                                 \"stage ii\", \n                                 \"stage iia\", \n                                 \"stage iib\", \n                                 \"stage iii\", \n                                 \"stage iiia\", \n                                 \"stage iiib\", \n                                 \"stage iv\")))\n\n\nsmoke_complete2 %&gt;% \n  select(stage_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,1521\n    \n  \n  \n    stage_factor\n\n        not reported\n99 (8.6%)\n        stage i\n7 (0.6%)\n        stage ia\n146 (13%)\n        stage ib\n266 (23%)\n        stage ii\n65 (5.6%)\n        stage iia\n112 (9.7%)\n        stage iib\n148 (13%)\n        stage iii\n86 (7.5%)\n        stage iiia\n102 (8.9%)\n        stage iiib\n30 (2.6%)\n        stage iv\n91 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nThat’s a lot of levels right? Here are visual examples of the tumor_stage variable before any manipulation:\n\n#boxplot\nggplot(smoke_complete2) +\n  aes(x = tumor_stage, y = cigarettes_per_day) +\n  geom_boxplot() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\") +\n  ylim(c(0,15))\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n#bar graph\nggplot(smoke_complete2) +\n  aes(x = tumor_stage, y = cigarettes_per_day) +\n  geom_col() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\")\n\n\n\n\nHaving a large amount of categories can be overwhelming in some graphics. There are distinguishable categories that these levels could be reduced to using ‘fct_collapse’.\n\nsmoke_complete3 &lt;- smoke_complete2 %&gt;% \n  mutate(stage_collapsed = fct_collapse(\n    stage_factor,\n    not_reported = c(\"not reported\"),\n    stage_i = c(\"stage i\", \"stage ia\", \"stage ib\"),\n    stage_ii = c(\"stage ii\", \"stage iia\", \"stage iib\"),\n    stage_iii = c(\"stage iii\", \"stage iiia\", \"stage iiib\"),\n    stage_iv = c(\"stage iv\"))) %&gt;% \n  glimpse()\n\nRows: 1,152\nColumns: 22\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;chr&gt; \"371\", \"136\", \"2304\", \"NA\", \"NA\", \"345\", \"…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24477, -26615, -28171, -27154, -23370, -1…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;chr&gt; \"NA\", \"NA\", \"2099\", \"3747\", \"3576\", \"NA\", …\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;chr&gt; \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", …\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;chr&gt; \"1936\", \"1931\", \"1927\", \"1930\", \"1942\", \"1…\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;chr&gt; \"2004\", \"2003\", \"NA\", \"NA\", \"NA\", \"2005\", …\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n$ stage_factor                &lt;fct&gt; stage ia, stage ib, stage ib, stage ia, st…\n$ stage_collapsed             &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n\n\nYou can also use the ‘other_level’ argument to set any category levels you’d like to ‘NA’.\n\nsmoke_complete4 &lt;- smoke_complete3 %&gt;% \n  mutate(stage_collapsed_na = fct_collapse(\n    stage_factor,\n    not_reported = c(\"not reported\"),\n    stage_i = c(\"stage i\", \"stage ia\", \"stage ib\"),\n    stage_ii = c(\"stage ii\", \"stage iia\", \"stage iib\"),\n    stage_iii = c(\"stage iii\", \"stage iiia\", \"stage iiib\"),\n    other_level = NA)) %&gt;% \n  glimpse()\n\nRows: 1,152\nColumns: 23\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;chr&gt; \"371\", \"136\", \"2304\", \"NA\", \"NA\", \"345\", \"…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24477, -26615, -28171, -27154, -23370, -1…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;chr&gt; \"NA\", \"NA\", \"2099\", \"3747\", \"3576\", \"NA\", …\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;chr&gt; \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", …\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;chr&gt; \"1936\", \"1931\", \"1927\", \"1930\", \"1942\", \"1…\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;chr&gt; \"2004\", \"2003\", \"NA\", \"NA\", \"NA\", \"2005\", …\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n$ stage_factor                &lt;fct&gt; stage ia, stage ib, stage ib, stage ia, st…\n$ stage_collapsed             &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n$ stage_collapsed_na          &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n\n\nNow there are 5 factor levels instead of 11.\n\nsmoke_complete3 %&gt;% \n  select(stage_collapsed) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,1521\n    \n  \n  \n    stage_collapsed\n\n        not_reported\n99 (8.6%)\n        stage_i\n419 (36%)\n        stage_ii\n325 (28%)\n        stage_iii\n218 (19%)\n        stage_iv\n91 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\nggplot(smoke_complete3) +\n  aes(x = stage_collapsed, y = cigarettes_per_day) +\n  geom_boxplot() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\") +\n  ylim(c(0,15))\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n#bar graph\nggplot(smoke_complete3) +\n  aes(x = stage_collapsed, y = cigarettes_per_day) +\n  geom_col() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\")\n\n\n\n\n\n\n\nCollapsing factor levels could be done in general when variables have broader classifications that many levels could be reduced under. ‘fct_collapse’ can help with data visualization and comparing groups together. This function is very useful when working with large data sets or a data set like ‘smoke_complete’ where there are variables with ordered categories and subcategories. Many other ‘fct_ …’ functions can be used in conjunction with ‘fct_collapse’ to further manipulate factor levels."
  },
  {
    "objectID": "function_week/Bovenkamp_fct_collapse.html#what-is-it-for",
    "href": "function_week/Bovenkamp_fct_collapse.html#what-is-it-for",
    "title": "forcats::fct_collapse",
    "section": "",
    "text": "The fct_collapse function accepts a factor or character vector and multiple named character levels. ‘fct_collapse’ consolidates several factor levels into fewer groups. Let’s look at tumor_stage:\n\n#mutating tumor_stage into a factor\n\nsmoke_complete2 &lt;- smoke_complete %&gt;% \n    mutate(stage_factor = \n               factor(tumor_stage,\n                      levels = c(\"not reported\", \n                                 \"stage i\", \n                                 \"stage ia\", \n                                 \"stage ib\", \n                                 \"stage ii\", \n                                 \"stage iia\", \n                                 \"stage iib\", \n                                 \"stage iii\", \n                                 \"stage iiia\", \n                                 \"stage iiib\", \n                                 \"stage iv\")))\n\n\nsmoke_complete2 %&gt;% \n  select(stage_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,1521\n    \n  \n  \n    stage_factor\n\n        not reported\n99 (8.6%)\n        stage i\n7 (0.6%)\n        stage ia\n146 (13%)\n        stage ib\n266 (23%)\n        stage ii\n65 (5.6%)\n        stage iia\n112 (9.7%)\n        stage iib\n148 (13%)\n        stage iii\n86 (7.5%)\n        stage iiia\n102 (8.9%)\n        stage iiib\n30 (2.6%)\n        stage iv\n91 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nThat’s a lot of levels right? Here are visual examples of the tumor_stage variable before any manipulation:\n\n#boxplot\nggplot(smoke_complete2) +\n  aes(x = tumor_stage, y = cigarettes_per_day) +\n  geom_boxplot() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\") +\n  ylim(c(0,15))\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n#bar graph\nggplot(smoke_complete2) +\n  aes(x = tumor_stage, y = cigarettes_per_day) +\n  geom_col() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\")\n\n\n\n\nHaving a large amount of categories can be overwhelming in some graphics. There are distinguishable categories that these levels could be reduced to using ‘fct_collapse’.\n\nsmoke_complete3 &lt;- smoke_complete2 %&gt;% \n  mutate(stage_collapsed = fct_collapse(\n    stage_factor,\n    not_reported = c(\"not reported\"),\n    stage_i = c(\"stage i\", \"stage ia\", \"stage ib\"),\n    stage_ii = c(\"stage ii\", \"stage iia\", \"stage iib\"),\n    stage_iii = c(\"stage iii\", \"stage iiia\", \"stage iiib\"),\n    stage_iv = c(\"stage iv\"))) %&gt;% \n  glimpse()\n\nRows: 1,152\nColumns: 22\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;chr&gt; \"371\", \"136\", \"2304\", \"NA\", \"NA\", \"345\", \"…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24477, -26615, -28171, -27154, -23370, -1…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;chr&gt; \"NA\", \"NA\", \"2099\", \"3747\", \"3576\", \"NA\", …\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;chr&gt; \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", …\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;chr&gt; \"1936\", \"1931\", \"1927\", \"1930\", \"1942\", \"1…\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;chr&gt; \"2004\", \"2003\", \"NA\", \"NA\", \"NA\", \"2005\", …\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n$ stage_factor                &lt;fct&gt; stage ia, stage ib, stage ib, stage ia, st…\n$ stage_collapsed             &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n\n\nYou can also use the ‘other_level’ argument to set any category levels you’d like to ‘NA’.\n\nsmoke_complete4 &lt;- smoke_complete3 %&gt;% \n  mutate(stage_collapsed_na = fct_collapse(\n    stage_factor,\n    not_reported = c(\"not reported\"),\n    stage_i = c(\"stage i\", \"stage ia\", \"stage ib\"),\n    stage_ii = c(\"stage ii\", \"stage iia\", \"stage iib\"),\n    stage_iii = c(\"stage iii\", \"stage iiia\", \"stage iiib\"),\n    other_level = NA)) %&gt;% \n  glimpse()\n\nRows: 1,152\nColumns: 23\n$ primary_diagnosis           &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ tumor_stage                 &lt;chr&gt; \"stage ia\", \"stage ib\", \"stage ib\", \"stage…\n$ age_at_diagnosis            &lt;dbl&gt; 24477, 26615, 28171, 27154, 23370, 19025, …\n$ vital_status                &lt;chr&gt; \"dead\", \"dead\", \"dead\", \"alive\", \"alive\", …\n$ morphology                  &lt;chr&gt; \"8070/3\", \"8070/3\", \"8070/3\", \"8083/3\", \"8…\n$ days_to_death               &lt;chr&gt; \"371\", \"136\", \"2304\", \"NA\", \"NA\", \"345\", \"…\n$ state                       &lt;chr&gt; \"live\", \"live\", \"live\", \"live\", \"live\", \"l…\n$ tissue_or_organ_of_origin   &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_birth               &lt;dbl&gt; -24477, -26615, -28171, -27154, -23370, -1…\n$ site_of_resection_or_biopsy &lt;chr&gt; \"C34.1\", \"C34.1\", \"C34.3\", \"C34.1\", \"C34.1…\n$ days_to_last_follow_up      &lt;chr&gt; \"NA\", \"NA\", \"2099\", \"3747\", \"3576\", \"NA\", …\n$ cigarettes_per_day          &lt;dbl&gt; 10.9589041, 2.1917808, 1.6438356, 1.095890…\n$ years_smoked                &lt;chr&gt; \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", …\n$ gender                      &lt;chr&gt; \"male\", \"male\", \"female\", \"male\", \"female\"…\n$ year_of_birth               &lt;chr&gt; \"1936\", \"1931\", \"1927\", \"1930\", \"1942\", \"1…\n$ race                        &lt;chr&gt; \"white\", \"asian\", \"white\", \"white\", \"not r…\n$ ethnicity                   &lt;chr&gt; \"not hispanic or latino\", \"not hispanic or…\n$ year_of_death               &lt;chr&gt; \"2004\", \"2003\", \"NA\", \"NA\", \"NA\", \"2005\", …\n$ bcr_patient_barcode         &lt;chr&gt; \"TCGA-18-3406\", \"TCGA-18-3407\", \"TCGA-18-3…\n$ disease                     &lt;chr&gt; \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"LUSC\", \"L…\n$ stage_factor                &lt;fct&gt; stage ia, stage ib, stage ib, stage ia, st…\n$ stage_collapsed             &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n$ stage_collapsed_na          &lt;fct&gt; stage_i, stage_i, stage_i, stage_i, stage_…\n\n\nNow there are 5 factor levels instead of 11.\n\nsmoke_complete3 %&gt;% \n  select(stage_collapsed) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,1521\n    \n  \n  \n    stage_collapsed\n\n        not_reported\n99 (8.6%)\n        stage_i\n419 (36%)\n        stage_ii\n325 (28%)\n        stage_iii\n218 (19%)\n        stage_iv\n91 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\nggplot(smoke_complete3) +\n  aes(x = stage_collapsed, y = cigarettes_per_day) +\n  geom_boxplot() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\") +\n  ylim(c(0,15))\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n#bar graph\nggplot(smoke_complete3) +\n  aes(x = stage_collapsed, y = cigarettes_per_day) +\n  geom_col() +\n  labs(x=\"Tumor Stage\", y=\"Cigarettes Per Day\")"
  },
  {
    "objectID": "function_week/Bovenkamp_fct_collapse.html#is-it-helpful",
    "href": "function_week/Bovenkamp_fct_collapse.html#is-it-helpful",
    "title": "forcats::fct_collapse",
    "section": "",
    "text": "Collapsing factor levels could be done in general when variables have broader classifications that many levels could be reduced under. ‘fct_collapse’ can help with data visualization and comparing groups together. This function is very useful when working with large data sets or a data set like ‘smoke_complete’ where there are variables with ordered categories and subcategories. Many other ‘fct_ …’ functions can be used in conjunction with ‘fct_collapse’ to further manipulate factor levels."
  },
  {
    "objectID": "function_week/Coonfield_na_if.html",
    "href": "function_week/Coonfield_na_if.html",
    "title": "dplyr::na_if",
    "section": "",
    "text": "In this document, I will introduce the dplyr na_if() function and show what it’s for.\n\n#load tidyverse up\nknitr::opts_chunk$set(echo = TRUE)\npacman::p_load(\n  tidyverse,\n  readxl,\n  here,         \n  janitor,\n  gt\n  )\n\n#load example dataset\nclinical_data &lt;- read_excel(here(\"function_week\", \"data\", \"tcga_clinical_data.xlsx\"), \n                             sheet = 2,\n                             na = \"NA\")"
  },
  {
    "objectID": "function_week/Coonfield_na_if.html#function-of-interest-dplyr---na_ifxy",
    "href": "function_week/Coonfield_na_if.html#function-of-interest-dplyr---na_ifxy",
    "title": "dplyr::na_if",
    "section": "",
    "text": "In this document, I will introduce the dplyr na_if() function and show what it’s for.\n\n#load tidyverse up\nknitr::opts_chunk$set(echo = TRUE)\npacman::p_load(\n  tidyverse,\n  readxl,\n  here,         \n  janitor,\n  gt\n  )\n\n#load example dataset\nclinical_data &lt;- read_excel(here(\"function_week\", \"data\", \"tcga_clinical_data.xlsx\"), \n                             sheet = 2,\n                             na = \"NA\")"
  },
  {
    "objectID": "function_week/Coonfield_na_if.html#what-is-it-for",
    "href": "function_week/Coonfield_na_if.html#what-is-it-for",
    "title": "dplyr::na_if",
    "section": "2 What is it for?",
    "text": "2 What is it for?\nThis function is used to replace annoying values with NA. It allows you to replace NaN with NA, even though NaN == NaN returns NA.\n\n2.1 Example 1: The Basics\n\n# Example 1: The basics\n# na_if functions as `na_if(x, y)`; where x is the vector to modify and y is the value to replace with NA.\n\nx &lt;- c(1, 25, -5, 0, 10)\n\nx_inf &lt;- 100/x\n# This enters us an infinite value, which has downstream effects on common data analysis.\nx_inf\n\n[1] 100   4 -20 Inf  10\n\nmean(x_inf, na.rm = T)\n\n[1] Inf\n\n# We see that we are not given a proper mean.\n\nx_na_if &lt;- 100/ na_if(x, 0)\nx_na_if\n\n[1] 100   4 -20  NA  10\n\nmean(x_na_if, na.rm = T)\n\n[1] 23.5\n\n# Success! What a meaningful change!\n\nThe previous example we adapted from Rdocumentation.org.\n\n\n2.2 Lets Set The Table: Data Clean Up\nNow that we have glimpsed the power of na_if, lets see how to utilize it in an actual data set.\n\n# First, lets clean up column names to aid data viewing.\n\nclinical_clean &lt;- clinical_data %&gt;%\n  rename(tumor_class = classification_of_tumor,\n         last_status = last_known_disease_status,\n         vital = vital_status,\n         morph = morphology,\n         diagnosis = primary_diagnosis,\n         stage = tumor_stage,\n         last_diseasestat = days_to_last_known_disease_status,\n         datetime = created_datetime,\n         recurrence = days_to_recurrence,\n         origin = tissue_or_organ_of_origin,\n         progression = progression_or_recurrence,\n         biopsy_site = site_of_resection_or_biopsy,\n         last_follow_up = days_to_last_follow_up,\n         intent_type = treatment_intent_type,\n         treatment = treatment_or_therapy) %&gt;%\n  select(c(-updated_datetime))\n\n\n\n2.3 Putting It All On The Table\n\nclinical_table &lt;- clinical_clean %&gt;%\n  head(2)\n\ngt(clinical_table)\n\n\n\n\n\n  \n    \n      submitter_id\n      tumor_class\n      last_status\n      diagnosis\n      stage\n      age_at_diagnosis\n      vital\n      morph\n      days_to_death\n      last_diseasestat\n      datetime\n      state\n      recurrence\n      diagnosis_id\n      tumor_grade\n      origin\n      days_to_birth\n      progression\n      prior_malignancy\n      biopsy_site\n      last_follow_up\n      cigarettes_per_day\n      weight\n      alcohol_history\n      alcohol_intensity\n      bmi\n      years_smoked\n      exposure_id\n      height\n      gender\n      year_of_birth\n      race\n      demographic_id\n      ethnicity\n      year_of_death\n      treatment_id\n      therapeutic_agents\n      intent_type\n      treatment\n      bcr_patient_barcode\n      disease\n    \n  \n  \n    TCGA-2W-A8YY\nnot reported\nnot reported\nC53.9\nnot reported\n18886\nalive\n8560/3\nNA\nNA\nNA\nlive\nNA\n908ee155-bfca-5240-b78b-6b82f565aedd\nnot reported\nC53.9\n-18886\nnot reported\nnot reported\nC53.9\n533\nNA\n42\nNA\nNA\n16.40625\nNA\n67aa3949-ad62-5f81-ad08-e8e295f84cfb\n160\nfemale\n1962\nwhite\nb89e4409-f7c6-53f2-a85f-31448e2ae1f6\nnot hispanic or latino\nNA\n026fa545-ac02-5915-ac23-5984d67a75f8\nNA\nNA\nNA\nTCGA-2W-A8YY\nCESC\n    TCGA-4J-AA1J\nnot reported\nnot reported\nC53.9\nnot reported\n11611\nalive\n8070/3\nNA\nNA\nNA\nlive\nNA\n20b61f8a-5efb-5bcc-aaad-5f79cd8ff313\nnot reported\nC53.9\n-11611\nnot reported\nnot reported\nC53.9\n542\nNA\n48\nNA\nNA\n17.63085\nNA\n93ddbaf1-67b9-59a9-8a04-ef00db42fd54\n165\nfemale\n1982\nwhite\n1c2c712d-0a6c-5b52-a4b0-8e1d61256f6c\nnot hispanic or latino\nNA\nf68ae36d-85e6-558c-91a7-f5b69b9dde19\nNA\nNA\nNA\nTCGA-4J-AA1J\nCESC\n  \n  \n  \n\n\n\n# As you can see there are many entries that use the phrase \"not reported\". This phrase did not get caught when we loaded that data into R.\n\n\n\n2.4 Example 2: Are You Tired of Data Being not reported?\n\n# Now if we want all the not reported inputs to be catergorzed as \"NA\" we will use the na_if function.\n\nclinical_na_if &lt;- clinical_clean %&gt;%\n  mutate(tumor_class = na_if(tumor_class, \"not reported\"),\n         last_status = na_if(last_status, \"not reported\"),\n         stage = na_if(stage, \"not reported\"),\n         tumor_grade = na_if(tumor_grade, \"not reported\"))\n\ngt(head(clinical_na_if, 2))\n\n\n\n\n\n  \n    \n      submitter_id\n      tumor_class\n      last_status\n      diagnosis\n      stage\n      age_at_diagnosis\n      vital\n      morph\n      days_to_death\n      last_diseasestat\n      datetime\n      state\n      recurrence\n      diagnosis_id\n      tumor_grade\n      origin\n      days_to_birth\n      progression\n      prior_malignancy\n      biopsy_site\n      last_follow_up\n      cigarettes_per_day\n      weight\n      alcohol_history\n      alcohol_intensity\n      bmi\n      years_smoked\n      exposure_id\n      height\n      gender\n      year_of_birth\n      race\n      demographic_id\n      ethnicity\n      year_of_death\n      treatment_id\n      therapeutic_agents\n      intent_type\n      treatment\n      bcr_patient_barcode\n      disease\n    \n  \n  \n    TCGA-2W-A8YY\nNA\nNA\nC53.9\nNA\n18886\nalive\n8560/3\nNA\nNA\nNA\nlive\nNA\n908ee155-bfca-5240-b78b-6b82f565aedd\nNA\nC53.9\n-18886\nnot reported\nnot reported\nC53.9\n533\nNA\n42\nNA\nNA\n16.40625\nNA\n67aa3949-ad62-5f81-ad08-e8e295f84cfb\n160\nfemale\n1962\nwhite\nb89e4409-f7c6-53f2-a85f-31448e2ae1f6\nnot hispanic or latino\nNA\n026fa545-ac02-5915-ac23-5984d67a75f8\nNA\nNA\nNA\nTCGA-2W-A8YY\nCESC\n    TCGA-4J-AA1J\nNA\nNA\nC53.9\nNA\n11611\nalive\n8070/3\nNA\nNA\nNA\nlive\nNA\n20b61f8a-5efb-5bcc-aaad-5f79cd8ff313\nNA\nC53.9\n-11611\nnot reported\nnot reported\nC53.9\n542\nNA\n48\nNA\nNA\n17.63085\nNA\n93ddbaf1-67b9-59a9-8a04-ef00db42fd54\n165\nfemale\n1982\nwhite\n1c2c712d-0a6c-5b52-a4b0-8e1d61256f6c\nnot hispanic or latino\nNA\nf68ae36d-85e6-558c-91a7-f5b69b9dde19\nNA\nNA\nNA\nTCGA-4J-AA1J\nCESC\n  \n  \n  \n\n\n\n\nAs you can see editing one column is very accessible, but once you get past three columns writing the na_if function gets tedious. There has got to be a better way! Akin to any late night infomercial, there is a better way by using our good old friend across function.\n\n\n2.5 Example 3: Have No Fear na_if Is Here!\n\n## Example 3: Multiple columns\n\nclinical_across &lt;- clinical_clean %&gt;%\n  mutate(across(where(is.character), \n                ~na_if(., \"not reported\")))\n\ngt(head(clinical_across, 2))\n\n\n\n\n\n  \n    \n      submitter_id\n      tumor_class\n      last_status\n      diagnosis\n      stage\n      age_at_diagnosis\n      vital\n      morph\n      days_to_death\n      last_diseasestat\n      datetime\n      state\n      recurrence\n      diagnosis_id\n      tumor_grade\n      origin\n      days_to_birth\n      progression\n      prior_malignancy\n      biopsy_site\n      last_follow_up\n      cigarettes_per_day\n      weight\n      alcohol_history\n      alcohol_intensity\n      bmi\n      years_smoked\n      exposure_id\n      height\n      gender\n      year_of_birth\n      race\n      demographic_id\n      ethnicity\n      year_of_death\n      treatment_id\n      therapeutic_agents\n      intent_type\n      treatment\n      bcr_patient_barcode\n      disease\n    \n  \n  \n    TCGA-2W-A8YY\nNA\nNA\nC53.9\nNA\n18886\nalive\n8560/3\nNA\nNA\nNA\nlive\nNA\n908ee155-bfca-5240-b78b-6b82f565aedd\nNA\nC53.9\n-18886\nNA\nNA\nC53.9\n533\nNA\n42\nNA\nNA\n16.40625\nNA\n67aa3949-ad62-5f81-ad08-e8e295f84cfb\n160\nfemale\n1962\nwhite\nb89e4409-f7c6-53f2-a85f-31448e2ae1f6\nnot hispanic or latino\nNA\n026fa545-ac02-5915-ac23-5984d67a75f8\nNA\nNA\nNA\nTCGA-2W-A8YY\nCESC\n    TCGA-4J-AA1J\nNA\nNA\nC53.9\nNA\n11611\nalive\n8070/3\nNA\nNA\nNA\nlive\nNA\n20b61f8a-5efb-5bcc-aaad-5f79cd8ff313\nNA\nC53.9\n-11611\nNA\nNA\nC53.9\n542\nNA\n48\nNA\nNA\n17.63085\nNA\n93ddbaf1-67b9-59a9-8a04-ef00db42fd54\n165\nfemale\n1982\nwhite\n1c2c712d-0a6c-5b52-a4b0-8e1d61256f6c\nnot hispanic or latino\nNA\nf68ae36d-85e6-558c-91a7-f5b69b9dde19\nNA\nNA\nNA\nTCGA-4J-AA1J\nCESC"
  },
  {
    "objectID": "function_week/Coonfield_na_if.html#is-it-helpful",
    "href": "function_week/Coonfield_na_if.html#is-it-helpful",
    "title": "dplyr::na_if",
    "section": "3 Is it helpful?",
    "text": "3 Is it helpful?\nThis function would be particularly useful is you wanted to change any NaN inputs to NA, or if you had very cluttered data with lots of “unknowns” or “not reported” or any other unusual entry for NA. This is also useful because when loading excel data you cannot have two different NA arguments.\nWhat is particularly useful about this function is when nesting it in the mutate and across function because you can make large edits to several vectors."
  },
  {
    "objectID": "function_week/Hand_coord_cartesian.html",
    "href": "function_week/Hand_coord_cartesian.html",
    "title": "ggplot2::coord_cartesian",
    "section": "",
    "text": "In this document, I will introduce the coord_cartesian() function and show what it’s for.\n\n\ncoord_cartesian( xlim = NULL, ylim = NULL, expand = TRUE, default = FALSE, clip = “on” )\nxlim/ylim: The values you would like to set for the x and y axes.\nexpand: True by default, adds a small buffer to limits to ensure data and axes do not overlap.\ndefault: False by default, adds warning message to user to alert that coordinate system is being replaced.\nclip: “on” by default, should remain on unless for very specific cases, when turned off data points can be anywhere on the plot including in the margins. This is the setting that removes the points outside of the set limits.\n\n\n\nThis function allows you to view a smaller section of a plot without changing the underlying data.\nFirst lets look at our unchanged penguin data.\n\n#making a ggplot of penguin flipper length\n\nggplot(penguins, aes(x = species, \n                   y = flipper_length_mm, \n                   color = species)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2, \n              show.legend = FALSE) +     # removed legend since not needed\n  labs(x = \"Species\", \n       y = \"Flipper lengths (mm)\",\n       title = \"Flipper lengths by penguin species\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nNow lets test what the standard zoom using scale_y_continuous looks like.\n\nggplot(penguins, aes(x = species, \n                   y = flipper_length_mm, \n                   color = species)) +\n  scale_y_continuous(limits = c(170, 190)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2, \n              show.legend = FALSE) +     # removed legend since not needed\n  labs(x = \"Species\", \n       y = \"Flipper lengths (mm)\",\n       title = \"Flipper lengths by penguin species\")\n\nWarning: Removed 257 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nAs you can see the shape of the data changes here, this is because this sort of scaling sets anything outside of the set limits to NA and re-scales the data based on what is inside of the range.\nNext lets look at the same range of data using the new function coord_cartesian()\n\nggplot(penguins, aes(x = species, \n                   y = flipper_length_mm, \n                   color = species)) +\n  coord_cartesian(ylim = c(170, 190)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2, \n              show.legend = FALSE) +     # removed legend since not needed\n  labs(x = \"Species\", \n       y = \"Flipper lengths (mm)\",\n       title = \"Flipper lengths by penguin species\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nHere we can see the shape of the data remains the same as from the main graph, we are simply zooming in on the set limits.\nUsing the penguin data the effect is there but it can be hard to see, lets look at some other data.\nThis data is from the R dataset called mtcars.\n\nplot &lt;- ggplot(mtcars, aes(qsec, hp)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x=\"Gross Horsepower\", y=\"1/4 mile time (sec)\", title=\"1/4 Mile Time by Horsepower\" )\nplot\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\nplot + scale_x_continuous(limits = c(16, 18))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 18 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\nplot + coord_cartesian(xlim = c(16, 18))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nHere we can more clearly see the difference in the two scaling methods.\n\n\n\nThis function is useful especially when doing any sort of modeling. Using a loess curve and zooming in using the standard method would ignore your other data points and can change the shape of your modeled line. By instead using coord_cartesian() you can ensure that the zoomed in plot is only magnifying the original section of data and not changing the relationship between the data points in any way.\nPresentation adapted from the webpage: https://ggplot2.tidyverse.org/reference/coord_cartesian.html"
  },
  {
    "objectID": "function_week/Hand_coord_cartesian.html#the-function-and-its-parts",
    "href": "function_week/Hand_coord_cartesian.html#the-function-and-its-parts",
    "title": "ggplot2::coord_cartesian",
    "section": "",
    "text": "coord_cartesian( xlim = NULL, ylim = NULL, expand = TRUE, default = FALSE, clip = “on” )\nxlim/ylim: The values you would like to set for the x and y axes.\nexpand: True by default, adds a small buffer to limits to ensure data and axes do not overlap.\ndefault: False by default, adds warning message to user to alert that coordinate system is being replaced.\nclip: “on” by default, should remain on unless for very specific cases, when turned off data points can be anywhere on the plot including in the margins. This is the setting that removes the points outside of the set limits."
  },
  {
    "objectID": "function_week/Hand_coord_cartesian.html#what-is-it-for",
    "href": "function_week/Hand_coord_cartesian.html#what-is-it-for",
    "title": "ggplot2::coord_cartesian",
    "section": "",
    "text": "This function allows you to view a smaller section of a plot without changing the underlying data.\nFirst lets look at our unchanged penguin data.\n\n#making a ggplot of penguin flipper length\n\nggplot(penguins, aes(x = species, \n                   y = flipper_length_mm, \n                   color = species)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2, \n              show.legend = FALSE) +     # removed legend since not needed\n  labs(x = \"Species\", \n       y = \"Flipper lengths (mm)\",\n       title = \"Flipper lengths by penguin species\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nNow lets test what the standard zoom using scale_y_continuous looks like.\n\nggplot(penguins, aes(x = species, \n                   y = flipper_length_mm, \n                   color = species)) +\n  scale_y_continuous(limits = c(170, 190)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2, \n              show.legend = FALSE) +     # removed legend since not needed\n  labs(x = \"Species\", \n       y = \"Flipper lengths (mm)\",\n       title = \"Flipper lengths by penguin species\")\n\nWarning: Removed 257 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nAs you can see the shape of the data changes here, this is because this sort of scaling sets anything outside of the set limits to NA and re-scales the data based on what is inside of the range.\nNext lets look at the same range of data using the new function coord_cartesian()\n\nggplot(penguins, aes(x = species, \n                   y = flipper_length_mm, \n                   color = species)) +\n  coord_cartesian(ylim = c(170, 190)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2, \n              show.legend = FALSE) +     # removed legend since not needed\n  labs(x = \"Species\", \n       y = \"Flipper lengths (mm)\",\n       title = \"Flipper lengths by penguin species\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nHere we can see the shape of the data remains the same as from the main graph, we are simply zooming in on the set limits.\nUsing the penguin data the effect is there but it can be hard to see, lets look at some other data.\nThis data is from the R dataset called mtcars.\n\nplot &lt;- ggplot(mtcars, aes(qsec, hp)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x=\"Gross Horsepower\", y=\"1/4 mile time (sec)\", title=\"1/4 Mile Time by Horsepower\" )\nplot\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\nplot + scale_x_continuous(limits = c(16, 18))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 18 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\nplot + coord_cartesian(xlim = c(16, 18))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nHere we can more clearly see the difference in the two scaling methods."
  },
  {
    "objectID": "function_week/Hand_coord_cartesian.html#is-it-helpful",
    "href": "function_week/Hand_coord_cartesian.html#is-it-helpful",
    "title": "ggplot2::coord_cartesian",
    "section": "",
    "text": "This function is useful especially when doing any sort of modeling. Using a loess curve and zooming in using the standard method would ignore your other data points and can change the shape of your modeled line. By instead using coord_cartesian() you can ensure that the zoomed in plot is only magnifying the original section of data and not changing the relationship between the data points in any way.\nPresentation adapted from the webpage: https://ggplot2.tidyverse.org/reference/coord_cartesian.html"
  },
  {
    "objectID": "function_week/Hindley_geom_density_ridges.html",
    "href": "function_week/Hindley_geom_density_ridges.html",
    "title": "ggridges::geom_density_ridges",
    "section": "",
    "text": "In this document, I will introduce the geom_density_ridges() function and show what it’s for.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ndata(penguins)\n#install ggridges with install.packages(\"ggridges\")\nlibrary(ggridges)\n\n\n\nImagine you have some sort of continuous data that you can turn into a density plot. This could be blood pressure, height, or weight. Most of these variables are normally distributed when you have a big enough population.\nThe function geom_density_ridges() allows you to overlay and directly compare density plots for multiple subcategories. This could be gender, species, city, month, or year.\nSuch a direct comparison allows us to see where distributions overlap between subcategories and where they are distinct. If time is used, they can also show how distributions of continuous variables change or remain the same over time.\n\n\nggplot(dataset ) + aes() + geom_density_ridges()\n\nplot_basic &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm,\n      y = species) +\n  geom_density_ridges()\n\nplot_basic\n\nPicking joint bandwidth of 1.08\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nIf you want a line along the bottom you can add that by using geom_density_ridges2()\n\nplot_basic_2 &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm,\n      y = species) +\n  geom_density_ridges2()\n\nplot_basic_2\n\nPicking joint bandwidth of 1.08\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nThis divides the bill length into separate species of penguins, but we have other subgroups that we are curious about seeing. We can use arguments color and fill to incorporate those subgroups.\n\npenguins %&gt;%\n  drop_na(sex) %&gt;% #there were many na values in the sex category\n  ggplot() +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = sex) +\n  geom_density_ridges()\n\nPicking joint bandwidth of 0.831\n\n\n\n\n\nThis can get a little cluttered, matching the y axis to a color can help simplify it:\n\nmyplot &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = species) +\n  scale_color_manual(values = c(\"Biscoe\" = \"blue\", \"Dream\" = \"green\", \"Torgersen\" = \"red\")) + #I had to manually match the colors because they were mismatched. scale_color_manual() allows that.\n  geom_density_ridges()\nmyplot\n\nPicking joint bandwidth of 1.11\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nOther arguments:\nalpha() changes the transparency of the fill color.\njittered_points() allows us to see the individual points that form the distribution curve.\n\nmyplot &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = species) +\n  scale_color_manual(values = c(\"Biscoe\" = \"blue\", \"Dream\" = \"green\", \"Torgersen\" = \"red\")) +\n  geom_density_ridges(alpha = 0.5, jittered_points = TRUE)\nmyplot\n\nPicking joint bandwidth of 1.11\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nFinally, if the ridges are overlapping too much, you can change that with the scale() argument. A scale of 1 means the top of one graph will reach the bottom of the next one.\n\nmyplot &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = species) +\n  scale_color_manual(values = c(\"Biscoe\" = \"blue\", \"Dream\" = \"green\", \"Torgersen\" = \"red\")) +\n  geom_density_ridges(alpha = 0.5, jittered_points = TRUE, scale = 0.95)\nmyplot\n\nPicking joint bandwidth of 1.11\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nSometimes, having more overlap with transparency on can show areas where the distributions meet.\n\nmyplot &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = species) +\n  scale_color_manual(values = c(\"Biscoe\" = \"blue\", \"Dream\" = \"green\", \"Torgersen\" = \"red\")) +\n  geom_density_ridges(alpha = 0.5, jittered_points = TRUE, scale = 5)\nmyplot\n\nPicking joint bandwidth of 1.11\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\n\n\n\n\nThe ggridges package with the density ridges function would be helpful in observational studies that collect a large amount of data on a number of different variables with subgroups.\nAdditionally, an interesting graph that I saw using this function used it to compare data over time intervals, where the y axis included each month of a year and the x axis showed how temperatures varied for each of those months.\nI think it these graphs can be quite informative and helpful."
  },
  {
    "objectID": "function_week/Hindley_geom_density_ridges.html#what-is-it-for",
    "href": "function_week/Hindley_geom_density_ridges.html#what-is-it-for",
    "title": "ggridges::geom_density_ridges",
    "section": "",
    "text": "Imagine you have some sort of continuous data that you can turn into a density plot. This could be blood pressure, height, or weight. Most of these variables are normally distributed when you have a big enough population.\nThe function geom_density_ridges() allows you to overlay and directly compare density plots for multiple subcategories. This could be gender, species, city, month, or year.\nSuch a direct comparison allows us to see where distributions overlap between subcategories and where they are distinct. If time is used, they can also show how distributions of continuous variables change or remain the same over time.\n\n\nggplot(dataset ) + aes() + geom_density_ridges()\n\nplot_basic &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm,\n      y = species) +\n  geom_density_ridges()\n\nplot_basic\n\nPicking joint bandwidth of 1.08\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nIf you want a line along the bottom you can add that by using geom_density_ridges2()\n\nplot_basic_2 &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm,\n      y = species) +\n  geom_density_ridges2()\n\nplot_basic_2\n\nPicking joint bandwidth of 1.08\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nThis divides the bill length into separate species of penguins, but we have other subgroups that we are curious about seeing. We can use arguments color and fill to incorporate those subgroups.\n\npenguins %&gt;%\n  drop_na(sex) %&gt;% #there were many na values in the sex category\n  ggplot() +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = sex) +\n  geom_density_ridges()\n\nPicking joint bandwidth of 0.831\n\n\n\n\n\nThis can get a little cluttered, matching the y axis to a color can help simplify it:\n\nmyplot &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = species) +\n  scale_color_manual(values = c(\"Biscoe\" = \"blue\", \"Dream\" = \"green\", \"Torgersen\" = \"red\")) + #I had to manually match the colors because they were mismatched. scale_color_manual() allows that.\n  geom_density_ridges()\nmyplot\n\nPicking joint bandwidth of 1.11\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nOther arguments:\nalpha() changes the transparency of the fill color.\njittered_points() allows us to see the individual points that form the distribution curve.\n\nmyplot &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = species) +\n  scale_color_manual(values = c(\"Biscoe\" = \"blue\", \"Dream\" = \"green\", \"Torgersen\" = \"red\")) +\n  geom_density_ridges(alpha = 0.5, jittered_points = TRUE)\nmyplot\n\nPicking joint bandwidth of 1.11\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nFinally, if the ridges are overlapping too much, you can change that with the scale() argument. A scale of 1 means the top of one graph will reach the bottom of the next one.\n\nmyplot &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = species) +\n  scale_color_manual(values = c(\"Biscoe\" = \"blue\", \"Dream\" = \"green\", \"Torgersen\" = \"red\")) +\n  geom_density_ridges(alpha = 0.5, jittered_points = TRUE, scale = 0.95)\nmyplot\n\nPicking joint bandwidth of 1.11\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\nSometimes, having more overlap with transparency on can show areas where the distributions meet.\n\nmyplot &lt;- ggplot(penguins) +\n  aes(x = bill_length_mm, \n      y = species, \n      color = island, \n      fill = species) +\n  scale_color_manual(values = c(\"Biscoe\" = \"blue\", \"Dream\" = \"green\", \"Torgersen\" = \"red\")) +\n  geom_density_ridges(alpha = 0.5, jittered_points = TRUE, scale = 5)\nmyplot\n\nPicking joint bandwidth of 1.11\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density_ridges()`)."
  },
  {
    "objectID": "function_week/Hindley_geom_density_ridges.html#is-it-helpful",
    "href": "function_week/Hindley_geom_density_ridges.html#is-it-helpful",
    "title": "ggridges::geom_density_ridges",
    "section": "",
    "text": "The ggridges package with the density ridges function would be helpful in observational studies that collect a large amount of data on a number of different variables with subgroups.\nAdditionally, an interesting graph that I saw using this function used it to compare data over time intervals, where the y axis included each month of a year and the x axis showed how temperatures varied for each of those months.\nI think it these graphs can be quite informative and helpful."
  },
  {
    "objectID": "function_week/Mandalapu_FotW_.geom_errorbar.html",
    "href": "function_week/Mandalapu_FotW_.geom_errorbar.html",
    "title": "ggplot2::geom_errorbar()",
    "section": "",
    "text": "In this document, I will introduce the geom_errorbar() function and show what it’s for.\n\n# load packages\nlibrary(tidyverse)\n\n# load dataset\nlibrary(palmerpenguins)\ndata(penguins)\n\n\nThe tidyverse package automatically includes ggplot2\nThe Palmer penguins dataset contains data on 344 penguins from the Palmer Archipelago\n\n\n\n\nEstimates from a dataset often have some degree of uncertainty\nError bars are a graphical representation of this uncertainty or variability\n\nThey can show variability via standard deviation, standard error, or confidence intervals\n\ngeom_errorbar() is a function that lets us add error bars to existing plots to understand the level of variability around measurements\n\nCritical inputs into this function are the min and max values for the bars for each measurement (in our case, ymin and ymax)\n\n\n\n# make a summary table with aggregated stats\npenguins_summary &lt;- penguins %&gt;%\n  filter(!is.na(body_mass_g)) %&gt;% \n  group_by(species) %&gt;%\n  summarise(\n    mean_mass = mean(body_mass_g),\n    sd_mass = sd(body_mass_g),\n    se_mass = sd_mass / sqrt(n()),\n    ci_lower = mean_mass - qt(0.975, df = n() - 1) * se_mass,\n    ci_upper = mean_mass + qt(0.975, df = n() - 1) * se_mass\n  )\n\n\n\nConfidence intervals are good for inference and show us the range where the true population mean is likely to fall for a given group and give us an idea of the uncertainty in a measurement.\n\nggplot(penguins_summary, aes(x = species, y = mean_mass)) +\n  geom_col(fill = \"thistle\") +\n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),\n                width = 0.2) +\n  ggtitle(\"Mean Mass by Species\") +\n  labs(x = \"Species\", y=\"Mean Body Mass (g)\") +\n  theme_minimal()\n\n\n\n\nFrom the above, we can conclude that there is a statistically significant difference in body mass between Gentoo and Adelie/Chinstrap penguins, but not between Adelie and Chinstrap. We can additionally conduct a t-test to confirm this significance.\n\n\n\nWe can change the colors of the data as well as the error bars, along with the width of error bars.\n\nggplot(penguins_summary, aes(x = species, y = mean_mass)) +\n  geom_col(fill = \"beige\") +\n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),\n                width = 1, color = \"purple\") +\n  ggtitle(\"Mean Mass by Species\") +\n  labs(x = \"Species\", y=\"Mean Body Mass (g)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSize (thickness) of the error bars with the size = X argument\nType of line with the linetype = \"X\" argument (“solid”, “dashed”, “dotted”, etc.)\nTransparency (opacity) with the alpha = X argument\n\n\n\n\nThe inputs for min and max for error bars can be anything such as standard deviation:\n\nggplot(penguins_summary, aes(x = species, y = mean_mass)) +\n  geom_col(fill = \"thistle\") +\n  geom_errorbar(aes(ymin = mean_mass - sd_mass, ymax = mean_mass + sd_mass),\n                width = 0.2) +\n  ggtitle(\"Mean Mass by Species\") +\n  labs(x = \"Species\", y=\"Mean Body Mass (g)\") +\n  theme_minimal()\n\n\n\n\nStandard deviation doesn’t provide statistical significance, but we can see the spread of data within each species. For example, Gentoo penguins have the larger standard deviation (taller error bars) meaning more variation.\n\n\n\nWe can also add error bars for horizontal plots! Just change the function to be geom_errorbarh and the inputs are now xmin and xmax, and height instead of width.\n\nggplot(penguins_summary, aes(y = species, x = mean_mass)) +\n  geom_col(fill = \"thistle\") +\n  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper),\n                height = 0.2) +\n  ggtitle(\"Mean Mass by Species\") +\n  labs(x = \"Mean Body Mass (g)\", y=\"Species\") +\n  theme_minimal()\n\n\n\n\n\n\n\nIt doesn’t have to be just bar plots. We can add error bars most plot types!\n\n# econ summary table\necon_summary &lt;- economics %&gt;%\n  summarise(\n    mean_unemploy = mean(unemploy, na.rm = TRUE),\n    sd_unemploy = sd(unemploy, na.rm = TRUE),\n    se_unemploy = sd_unemploy / sqrt(n()),\n    ci_lower = unemploy - qt(0.975, df = n() - 1) * se_unemploy,\n    ci_upper = unemploy + qt(0.975, df = n() - 1) * se_unemploy\n  )\n\n# plot with 95% CI\nggplot(economics, aes(x = date, y = unemploy)) +\n  geom_line(color = \"red\") +  \n  geom_errorbar(aes(ymin = econ_summary$ci_lower, ymax = econ_summary$ci_upper),         width = 1) +\n  ggtitle(\"US Unemployment Over Time\") +\n  labs(x = \"Date\", y=\"# Unemployed (000s)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nYes! It’s a great addition to any data visualization and allows us to:\n\nUnderstand variability of measurements\nCompare differences between groups and assess their significance\nProvides context to raw data and shows uncertainty"
  },
  {
    "objectID": "function_week/Mandalapu_FotW_.geom_errorbar.html#what-is-it-for",
    "href": "function_week/Mandalapu_FotW_.geom_errorbar.html#what-is-it-for",
    "title": "ggplot2::geom_errorbar()",
    "section": "",
    "text": "Estimates from a dataset often have some degree of uncertainty\nError bars are a graphical representation of this uncertainty or variability\n\nThey can show variability via standard deviation, standard error, or confidence intervals\n\ngeom_errorbar() is a function that lets us add error bars to existing plots to understand the level of variability around measurements\n\nCritical inputs into this function are the min and max values for the bars for each measurement (in our case, ymin and ymax)\n\n\n\n# make a summary table with aggregated stats\npenguins_summary &lt;- penguins %&gt;%\n  filter(!is.na(body_mass_g)) %&gt;% \n  group_by(species) %&gt;%\n  summarise(\n    mean_mass = mean(body_mass_g),\n    sd_mass = sd(body_mass_g),\n    se_mass = sd_mass / sqrt(n()),\n    ci_lower = mean_mass - qt(0.975, df = n() - 1) * se_mass,\n    ci_upper = mean_mass + qt(0.975, df = n() - 1) * se_mass\n  )\n\n\n\nConfidence intervals are good for inference and show us the range where the true population mean is likely to fall for a given group and give us an idea of the uncertainty in a measurement.\n\nggplot(penguins_summary, aes(x = species, y = mean_mass)) +\n  geom_col(fill = \"thistle\") +\n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),\n                width = 0.2) +\n  ggtitle(\"Mean Mass by Species\") +\n  labs(x = \"Species\", y=\"Mean Body Mass (g)\") +\n  theme_minimal()\n\n\n\n\nFrom the above, we can conclude that there is a statistically significant difference in body mass between Gentoo and Adelie/Chinstrap penguins, but not between Adelie and Chinstrap. We can additionally conduct a t-test to confirm this significance.\n\n\n\nWe can change the colors of the data as well as the error bars, along with the width of error bars.\n\nggplot(penguins_summary, aes(x = species, y = mean_mass)) +\n  geom_col(fill = \"beige\") +\n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),\n                width = 1, color = \"purple\") +\n  ggtitle(\"Mean Mass by Species\") +\n  labs(x = \"Species\", y=\"Mean Body Mass (g)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSize (thickness) of the error bars with the size = X argument\nType of line with the linetype = \"X\" argument (“solid”, “dashed”, “dotted”, etc.)\nTransparency (opacity) with the alpha = X argument\n\n\n\n\nThe inputs for min and max for error bars can be anything such as standard deviation:\n\nggplot(penguins_summary, aes(x = species, y = mean_mass)) +\n  geom_col(fill = \"thistle\") +\n  geom_errorbar(aes(ymin = mean_mass - sd_mass, ymax = mean_mass + sd_mass),\n                width = 0.2) +\n  ggtitle(\"Mean Mass by Species\") +\n  labs(x = \"Species\", y=\"Mean Body Mass (g)\") +\n  theme_minimal()\n\n\n\n\nStandard deviation doesn’t provide statistical significance, but we can see the spread of data within each species. For example, Gentoo penguins have the larger standard deviation (taller error bars) meaning more variation.\n\n\n\nWe can also add error bars for horizontal plots! Just change the function to be geom_errorbarh and the inputs are now xmin and xmax, and height instead of width.\n\nggplot(penguins_summary, aes(y = species, x = mean_mass)) +\n  geom_col(fill = \"thistle\") +\n  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper),\n                height = 0.2) +\n  ggtitle(\"Mean Mass by Species\") +\n  labs(x = \"Mean Body Mass (g)\", y=\"Species\") +\n  theme_minimal()\n\n\n\n\n\n\n\nIt doesn’t have to be just bar plots. We can add error bars most plot types!\n\n# econ summary table\necon_summary &lt;- economics %&gt;%\n  summarise(\n    mean_unemploy = mean(unemploy, na.rm = TRUE),\n    sd_unemploy = sd(unemploy, na.rm = TRUE),\n    se_unemploy = sd_unemploy / sqrt(n()),\n    ci_lower = unemploy - qt(0.975, df = n() - 1) * se_unemploy,\n    ci_upper = unemploy + qt(0.975, df = n() - 1) * se_unemploy\n  )\n\n# plot with 95% CI\nggplot(economics, aes(x = date, y = unemploy)) +\n  geom_line(color = \"red\") +  \n  geom_errorbar(aes(ymin = econ_summary$ci_lower, ymax = econ_summary$ci_upper),         width = 1) +\n  ggtitle(\"US Unemployment Over Time\") +\n  labs(x = \"Date\", y=\"# Unemployed (000s)\") +\n  theme_minimal()"
  },
  {
    "objectID": "function_week/Mandalapu_FotW_.geom_errorbar.html#is-it-helpful",
    "href": "function_week/Mandalapu_FotW_.geom_errorbar.html#is-it-helpful",
    "title": "ggplot2::geom_errorbar()",
    "section": "",
    "text": "Yes! It’s a great addition to any data visualization and allows us to:\n\nUnderstand variability of measurements\nCompare differences between groups and assess their significance\nProvides context to raw data and shows uncertainty"
  },
  {
    "objectID": "function_week/Mann_between.html",
    "href": "function_week/Mann_between.html",
    "title": "dplyr::between()",
    "section": "",
    "text": "In this document, I will introduce the between( ) function and show what it can be used for.\n\nlibrary(tidyverse)\n\nlibrary(palmerpenguins)\ndata(penguins)\n\n\n\nThe between( ) function from the dplyr package makes it easier to find values within a specified range (inclusive of the lower and upper bounds).\n\n\n\n#1  getting info on penguin body mass \nsummary(penguins$body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n#2  Getting values that are between the 1st and 3rd quartiles using &gt;= , &lt;= \n\npenguins_filtered &lt;- penguins %&gt;%\n  filter(body_mass_g&gt;= 3550  & body_mass_g &lt;= 4750)\n\nhead(penguins_filtered)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           39.3          20.6               190        3650\n4 Adelie  Torgersen           38.9          17.8               181        3625\n5 Adelie  Torgersen           39.2          19.6               195        4675\n6 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n# Getting values that are between the 1st and 3rd quartiles using between()\n\npenguins_filtered_btwn&lt;- penguins %&gt;%\n  filter(between(body_mass_g, 3550, 4750))\n\nhead(penguins_filtered_btwn)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           39.3          20.6               190        3650\n4 Adelie  Torgersen           38.9          17.8               181        3625\n5 Adelie  Torgersen           39.2          19.6               195        4675\n6 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n#1  getting info on penguin bill length  \nsummary(penguins$bill_length_mm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  32.10   39.23   44.45   43.92   48.50   59.60       2 \n\n#2 creating dataset of penguins with shirt beaks \n\nPenguins_short_beaks &lt;- penguins%&gt;% \n  filter(between(bill_length_mm, 32.10, 39.23))\n\nhead(Penguins_short_beaks)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           36.7          19.3               193        3450\n3 Adelie  Torgersen           38.9          17.8               181        3625\n4 Adelie  Torgersen           39.2          19.6               195        4675\n5 Adelie  Torgersen           34.1          18.1               193        3475\n6 Adelie  Torgersen           37.8          17.1               186        3300\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n\nDiscuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\n\nYes, it works well with other functions such as mutate or filter, and also makes the readability of your code better. Readability of your code is important because it makes it easier for you to read and find errors, and makes it easier for others to work with your code."
  },
  {
    "objectID": "function_week/Mann_between.html#what-is-it-for",
    "href": "function_week/Mann_between.html#what-is-it-for",
    "title": "dplyr::between()",
    "section": "",
    "text": "The between( ) function from the dplyr package makes it easier to find values within a specified range (inclusive of the lower and upper bounds).\n\n\n\n#1  getting info on penguin body mass \nsummary(penguins$body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n#2  Getting values that are between the 1st and 3rd quartiles using &gt;= , &lt;= \n\npenguins_filtered &lt;- penguins %&gt;%\n  filter(body_mass_g&gt;= 3550  & body_mass_g &lt;= 4750)\n\nhead(penguins_filtered)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           39.3          20.6               190        3650\n4 Adelie  Torgersen           38.9          17.8               181        3625\n5 Adelie  Torgersen           39.2          19.6               195        4675\n6 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n# Getting values that are between the 1st and 3rd quartiles using between()\n\npenguins_filtered_btwn&lt;- penguins %&gt;%\n  filter(between(body_mass_g, 3550, 4750))\n\nhead(penguins_filtered_btwn)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           39.3          20.6               190        3650\n4 Adelie  Torgersen           38.9          17.8               181        3625\n5 Adelie  Torgersen           39.2          19.6               195        4675\n6 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n#1  getting info on penguin bill length  \nsummary(penguins$bill_length_mm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  32.10   39.23   44.45   43.92   48.50   59.60       2 \n\n#2 creating dataset of penguins with shirt beaks \n\nPenguins_short_beaks &lt;- penguins%&gt;% \n  filter(between(bill_length_mm, 32.10, 39.23))\n\nhead(Penguins_short_beaks)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           36.7          19.3               193        3450\n3 Adelie  Torgersen           38.9          17.8               181        3625\n4 Adelie  Torgersen           39.2          19.6               195        4675\n5 Adelie  Torgersen           34.1          18.1               193        3475\n6 Adelie  Torgersen           37.8          17.1               186        3300\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "function_week/Mann_between.html#is-it-helpful",
    "href": "function_week/Mann_between.html#is-it-helpful",
    "title": "dplyr::between()",
    "section": "",
    "text": "Discuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\n\nYes, it works well with other functions such as mutate or filter, and also makes the readability of your code better. Readability of your code is important because it makes it easier for you to read and find errors, and makes it easier for others to work with your code."
  },
  {
    "objectID": "function_week/McVeety_geom_rug.html",
    "href": "function_week/McVeety_geom_rug.html",
    "title": "ggplot2::geom_rug()",
    "section": "",
    "text": "In this document, I will introduce the geom_rug() function and show what it’s for.\n\n#load tidyverse up\nlibrary(tidyverse) #this will include the ggplot2 package, which we need!\n\n#example dataset\nlibrary(palmerpenguins)\ndata(penguins)\n\n\n\n\nDiscuss what the function does. Learn from the examples, but show how to use it using another dataset such as penguins. If you can provide two examples, even better!\n\nLike other geom_ family functions, geom_rug() creates a plot using ggplot() - in this case, a rug plot! A rug plot shows the distribution of a single numeric variable as marks on an axis, making it look like a rug or tufts of grass sticking up.\nThis can help us visualize the distribution of a single variable - it functions much like a histogram or a scatterplot with only one variable. For example, using the penguins dataset, we can look at the distribution of bill length with the following:\n\nggplot(data = penguins, \n       aes(x = bill_length_mm)) + \n  geom_rug()\n\n\n\n\nLet’s compare it to a histogram:\n\nggplot(data = penguins, \n       aes(x = bill_length_mm)) + \n  geom_rug() + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nYou can see the lines are more dense where the histogram is taller - both show that where data points are clustered (here, around 40 mm and 50 mm).\nOn its own, a rug plot isn’t very pretty or exciting. But it comes in handy when you want to display the distribution of a single variable in addition to multiple variables.\nLet’s say we have a scatterplot showing bill depth compared to bill length in penguins.\n\nggplot(data = penguins, \n       aes(x = bill_length_mm,\n           y = bill_depth_mm)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nWe can see where there are clusters in the 2D space, but it’s a little harder to see the distribution of each individual variable (bill depth and bill length) from this graph. Adding a rug plot can help.\n\nggplot(data = penguins, \n       aes(x = bill_length_mm,\n           y = bill_depth_mm)) + \n  geom_point() + \n  geom_rug()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nThis makes it easier to tell where bill length is more concentrated, and to see that bill depth appears to be very evenly distributed across the range of values - however, it’s unclear whether that uniformity is because of overlap in the lines, where points have the same bill depth value.\nWe can fix this by adding jitter! Let’s try it with the iris dataset.\n\nggplot(data = iris, \n       aes(x = Sepal.Length,\n           y = Petal.Length)) + \n  geom_point() + \n  geom_rug()\n\n\n\n\nIn this plot, sepal length (the x-axis) appears to have extremely uniform distribution. But by adding jitter, we can see that there are areas with actual higher density, which were hidden by observations having the exact same values.\n\nggplot(data = iris, \n       aes(x = Sepal.Length,\n           y = Petal.Length)) + \n  geom_point() + \n  geom_rug(position = \"jitter\")\n\n\n\n\n\n\nYou can control which variable(s) to display the rug plot for and where they go using the sides = argument.\n\nggplot(data = iris, \n       aes(x = Sepal.Length,\n           y = Petal.Length)) + \n  geom_point() + \n  geom_rug(position = \"jitter\", \n           sides = \"b\")\n\n\n\n\nChange the length of the lines using the length = argument, opacity with the alpha = argument, color with the color = argument, and the width of the lines with the linewidth = argument.\n\nggplot(data = iris, \n       aes(x = Sepal.Length,\n           y = Petal.Length)) + \n  geom_point() + \n  geom_rug(position = \"jitter\", \n           length = unit(0.06, \"npc\"),\n           alpha = 0.2, \n           color = 'red', \n           linewidth = 0.5)\n\n\n\n\n\n\n\n\n\nDiscuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\n\nRug plots are most helpful when you are comparing multiple numeric variables but still want to see the individual variable distribution(s), particularly in datasets where you have relatively few observations. Once there are a lot of points, it can be hard to see relative density in a rug plot. They’re also most effective when variables are truly continuous (e.g., not something like age in years), because otherwise we see a lot of overlap in the points (or you can use the ‘jitter’ option).\nOverall, this can be a helpful visualization for some types of data, but its use-case is specific enough that it’s unlikely to be relevant in a lot of cases."
  },
  {
    "objectID": "function_week/McVeety_geom_rug.html#dataset-instructions",
    "href": "function_week/McVeety_geom_rug.html#dataset-instructions",
    "title": "ggplot2::geom_rug()",
    "section": "",
    "text": "Please use a dataset that is publicly available. In particular, do not use a dataset with PHI that we cannot publicly share.\n\n\n\nIt is easiest to use a dataset that is a part of base R or a part of an R package. For example, below the penguins dataset from the palmerpenguins package is used.\nSome R packages that include datasets are:\n\nThe datasets in the package datasets are included with base R and “ready” to use without having to load them first. Learn more about the available datasets here and here.\n\npalmerpenguins package\nfivethirtyeight package\nA list of R packages and datasets included in them. This list is not comprehensive.\n\n\n\n\nIf you choose to load your own dataset (which could be one downloaded from the web somewhere), then\n\nInclude a description of the dataset and from where it was downloaded or how it was created. If these are data from a project you have worked on, make sure there are no identifying information and also alter the data so that they are not the original data.\nUpload the dataset on Sakai along with your .qmd and .html files so that we can render your .qmd file."
  },
  {
    "objectID": "function_week/McVeety_geom_rug.html#what-is-it-for",
    "href": "function_week/McVeety_geom_rug.html#what-is-it-for",
    "title": "ggplot2::geom_rug()",
    "section": "",
    "text": "Discuss what the function does. Learn from the examples, but show how to use it using another dataset such as penguins. If you can provide two examples, even better!\n\nLike other geom_ family functions, geom_rug() creates a plot using ggplot() - in this case, a rug plot! A rug plot shows the distribution of a single numeric variable as marks on an axis, making it look like a rug or tufts of grass sticking up.\nThis can help us visualize the distribution of a single variable - it functions much like a histogram or a scatterplot with only one variable. For example, using the penguins dataset, we can look at the distribution of bill length with the following:\n\nggplot(data = penguins, \n       aes(x = bill_length_mm)) + \n  geom_rug()\n\n\n\n\nLet’s compare it to a histogram:\n\nggplot(data = penguins, \n       aes(x = bill_length_mm)) + \n  geom_rug() + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nYou can see the lines are more dense where the histogram is taller - both show that where data points are clustered (here, around 40 mm and 50 mm).\nOn its own, a rug plot isn’t very pretty or exciting. But it comes in handy when you want to display the distribution of a single variable in addition to multiple variables.\nLet’s say we have a scatterplot showing bill depth compared to bill length in penguins.\n\nggplot(data = penguins, \n       aes(x = bill_length_mm,\n           y = bill_depth_mm)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nWe can see where there are clusters in the 2D space, but it’s a little harder to see the distribution of each individual variable (bill depth and bill length) from this graph. Adding a rug plot can help.\n\nggplot(data = penguins, \n       aes(x = bill_length_mm,\n           y = bill_depth_mm)) + \n  geom_point() + \n  geom_rug()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nThis makes it easier to tell where bill length is more concentrated, and to see that bill depth appears to be very evenly distributed across the range of values - however, it’s unclear whether that uniformity is because of overlap in the lines, where points have the same bill depth value.\nWe can fix this by adding jitter! Let’s try it with the iris dataset.\n\nggplot(data = iris, \n       aes(x = Sepal.Length,\n           y = Petal.Length)) + \n  geom_point() + \n  geom_rug()\n\n\n\n\nIn this plot, sepal length (the x-axis) appears to have extremely uniform distribution. But by adding jitter, we can see that there are areas with actual higher density, which were hidden by observations having the exact same values.\n\nggplot(data = iris, \n       aes(x = Sepal.Length,\n           y = Petal.Length)) + \n  geom_point() + \n  geom_rug(position = \"jitter\")\n\n\n\n\n\n\nYou can control which variable(s) to display the rug plot for and where they go using the sides = argument.\n\nggplot(data = iris, \n       aes(x = Sepal.Length,\n           y = Petal.Length)) + \n  geom_point() + \n  geom_rug(position = \"jitter\", \n           sides = \"b\")\n\n\n\n\nChange the length of the lines using the length = argument, opacity with the alpha = argument, color with the color = argument, and the width of the lines with the linewidth = argument.\n\nggplot(data = iris, \n       aes(x = Sepal.Length,\n           y = Petal.Length)) + \n  geom_point() + \n  geom_rug(position = \"jitter\", \n           length = unit(0.06, \"npc\"),\n           alpha = 0.2, \n           color = 'red', \n           linewidth = 0.5)"
  },
  {
    "objectID": "function_week/McVeety_geom_rug.html#is-it-helpful",
    "href": "function_week/McVeety_geom_rug.html#is-it-helpful",
    "title": "ggplot2::geom_rug()",
    "section": "",
    "text": "Discuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\n\nRug plots are most helpful when you are comparing multiple numeric variables but still want to see the individual variable distribution(s), particularly in datasets where you have relatively few observations. Once there are a lot of points, it can be hard to see relative density in a rug plot. They’re also most effective when variables are truly continuous (e.g., not something like age in years), because otherwise we see a lot of overlap in the points (or you can use the ‘jitter’ option).\nOverall, this can be a helpful visualization for some types of data, but its use-case is specific enough that it’s unlikely to be relevant in a lot of cases."
  },
  {
    "objectID": "function_week/Sonstroem_.html",
    "href": "function_week/Sonstroem_.html",
    "title": "dplyr::slice_max, slice_min",
    "section": "",
    "text": "Please sign up for a function here (Enter your name and the week you want to present): function_of_the_week_signup_2025\nFor this assignment, please submit both the .qmd and the .html files. I will add it to the website. Remove your name from the qmd if you do not wish it shared or let us know if it is okay to post in anonymously.\nPrevious years’ Functions of the Week can be found on the previous class websites:\n\nhttps://niederhausen.github.io/BSTA_526_W24/function_week.html/\nhttps://sph-r-programming-2023.netlify.app/functions/\nhttps://sph-r-programming-2022.netlify.app/functions/\nhttps://sph-r-programming.netlify.app/functions/ (2021)\n\nIf you select a function which was presented previously, please develop your own examples and content."
  },
  {
    "objectID": "function_week/Sonstroem_.html#what-is-it-for",
    "href": "function_week/Sonstroem_.html#what-is-it-for",
    "title": "dplyr::slice_max, slice_min",
    "section": "2.1 What is it for?",
    "text": "2.1 What is it for?\nslice_max() and slice_min() are two of several different slice functions, all of which allow you to select specific rows in order to view, delete, mutate, or otherwise interact with them. slice_max() selects the rows with the highest values of a particular variable, and slice_min() selects the rows with the lowest values.\n\n2.1.1 Syntax\nThe necessary arguments are your data frame and order_by, which specifies the variable to select the highest and lowest values from\nThe optional arguments include:\n\nn, which specifies the number of rows to select, or prop, which specifies a proportion of rows. The default value is n=1.\nwith_ties, which specifies whether or not to include ties. The default value is TRUE, which means that the function may return more rows than requested if there are ties.\n\n\n\n2.1.2 Examples\n\n2.1.2.1 View a subset of your data\nWhich are the 5 penguins with the longest beaks?\n\nslice_max(penguins, order_by=bill_length_mm, n=5)\n\n# A tibble: 5 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           59.6          17                 230        6050\n2 Chinstrap Dream            58            17.8               181        3700\n3 Gentoo    Biscoe           55.9          17                 228        5600\n4 Chinstrap Dream            55.8          19.8               207        4000\n5 Gentoo    Biscoe           55.1          16                 230        5850\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n2.1.2.2 Subsetting quantiles\nWhich penguins are in the lowest quartile of beak length?\n\npenguins %&gt;% slice_min(bill_length_mm, prop=0.25)\n\n# A tibble: 86 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Dream               32.1          15.5               188        3050\n 2 Adelie  Dream               33.1          16.1               178        2900\n 3 Adelie  Torgersen           33.5          19                 190        3600\n 4 Adelie  Dream               34            17.1               185        3400\n 5 Adelie  Torgersen           34.1          18.1               193        3475\n 6 Adelie  Torgersen           34.4          18.4               184        3325\n 7 Adelie  Biscoe              34.5          18.1               187        2900\n 8 Adelie  Torgersen           34.6          21.1               198        4400\n 9 Adelie  Torgersen           34.6          17.2               189        3200\n10 Adelie  Biscoe              35            17.9               190        3450\n# ℹ 76 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n2.1.2.3 Creating new data frames and variables\nWhat is the average beak length for the penguins in the lowest quartile of beak length?\n\nshortbeak &lt;- slice_min(penguins, order_by=bill_length_mm, prop=0.25)\nmean(shortbeak$bill_length_mm)\n\n[1] 36.9186\n\n\n\n\n\n2.1.3 Weird examples\n\n2.1.3.1 What happens if you try to use slice_max() or slice_min() with a non-numeric variable?\n\npenguins %&gt;% slice_min(species, n=5)\n\n# A tibble: 152 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 142 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThe values will be sorted alphabetically! This seems less useful than using the functions for numeric values, but it would allow you to do things like pull the first 5 people alphabetically from a list.\n\n\n2.1.3.2 What happens if you set ties to FALSE even though there are lots of ties?\nAs we saw with the species example above, I requested n=5 but got far more rows than that. If I’d set with_ties to false, I would have gotten…\n\npenguins %&gt;% slice_min(species, n=5, with_ties=FALSE)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n… the five Adelie penguins that happen to be listed first in the data frame.\n\n\n2.1.3.3 What happens if you set prop&gt;=1?\n\npenguins %&gt;% slice_min(bill_length_mm, prop=1.3)\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Dream               32.1          15.5               188        3050\n 2 Adelie  Dream               33.1          16.1               178        2900\n 3 Adelie  Torgersen           33.5          19                 190        3600\n 4 Adelie  Dream               34            17.1               185        3400\n 5 Adelie  Torgersen           34.1          18.1               193        3475\n 6 Adelie  Torgersen           34.4          18.4               184        3325\n 7 Adelie  Biscoe              34.5          18.1               187        2900\n 8 Adelie  Torgersen           34.6          21.1               198        4400\n 9 Adelie  Torgersen           34.6          17.2               189        3200\n10 Adelie  Biscoe              35            17.9               190        3450\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nSetting prop&gt;=1 will return all of the rows in the data frame, sorted by your relevant variable. This means that you can use slice_min() and slice_max() as substitutes for arrange() or order(), if you wanted to do that for some reason!"
  },
  {
    "objectID": "function_week/Sonstroem_.html#is-it-helpful",
    "href": "function_week/Sonstroem_.html#is-it-helpful",
    "title": "dplyr::slice_max, slice_min",
    "section": "2.2 Is it helpful?",
    "text": "2.2 Is it helpful?\nYes, I can think of at least three situations where these functions would be helpful:\n\nSubsetting your data into quantiles\nVerifying that a mutation worked correctly by double checking the highest and lowest values\nLooking quickly for apparent outlier values"
  },
  {
    "objectID": "function_week/Sonstroem_slice_max_slice_min.html",
    "href": "function_week/Sonstroem_slice_max_slice_min.html",
    "title": "dplyr::slice_max, slice_min",
    "section": "",
    "text": "In this document, I will introduce the slice_max and slice_min functions and show what they’re for.\n\n\nslice_max() and slice_min() are two of several different slice functions, all of which allow you to select specific rows in order to view, delete, mutate, or otherwise interact with them. slice_max() selects the rows with the highest values of a particular variable, and slice_min() selects the rows with the lowest values.\n\n\nThe necessary arguments are your data frame and order_by, which specifies the variable to select the highest and lowest values from\nThe optional arguments include:\n\nn, which specifies the number of rows to select, or prop, which specifies a proportion of rows. The default value is n=1.\nwith_ties, which specifies whether or not to include ties. The default value is TRUE, which means that the function may return more rows than requested if there are ties.\n\n\n\n\n\n\nWhich are the 5 penguins with the longest beaks?\n\nslice_max(penguins, order_by=bill_length_mm, n=5)\n\n# A tibble: 5 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           59.6          17                 230        6050\n2 Chinstrap Dream            58            17.8               181        3700\n3 Gentoo    Biscoe           55.9          17                 228        5600\n4 Chinstrap Dream            55.8          19.8               207        4000\n5 Gentoo    Biscoe           55.1          16                 230        5850\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\nWhich penguins are in the lowest quartile of beak length?\n\npenguins %&gt;% slice_min(bill_length_mm, prop=0.25)\n\n# A tibble: 86 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Dream               32.1          15.5               188        3050\n 2 Adelie  Dream               33.1          16.1               178        2900\n 3 Adelie  Torgersen           33.5          19                 190        3600\n 4 Adelie  Dream               34            17.1               185        3400\n 5 Adelie  Torgersen           34.1          18.1               193        3475\n 6 Adelie  Torgersen           34.4          18.4               184        3325\n 7 Adelie  Biscoe              34.5          18.1               187        2900\n 8 Adelie  Torgersen           34.6          21.1               198        4400\n 9 Adelie  Torgersen           34.6          17.2               189        3200\n10 Adelie  Biscoe              35            17.9               190        3450\n# ℹ 76 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\nWhat is the average beak length for the penguins in the lowest quartile of beak length?\n\nshortbeak &lt;- slice_min(penguins, order_by=bill_length_mm, prop=0.25)\nmean(shortbeak$bill_length_mm)\n\n[1] 36.9186\n\n\n\n\n\n\n\n\n\npenguins %&gt;% slice_min(species, n=5)\n\n# A tibble: 152 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 142 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThe values will be sorted alphabetically! This seems less useful than using the functions for numeric values, but it would allow you to do things like pull the first 5 people alphabetically from a list.\n\n\n\nAs we saw with the species example above, I requested n=5 but got far more rows than that. If I’d set with_ties to false, I would have gotten…\n\npenguins %&gt;% slice_min(species, n=5, with_ties=FALSE)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n… the five Adelie penguins that happen to be listed first in the data frame.\n\n\n\n\npenguins %&gt;% slice_min(bill_length_mm, prop=1.3)\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Dream               32.1          15.5               188        3050\n 2 Adelie  Dream               33.1          16.1               178        2900\n 3 Adelie  Torgersen           33.5          19                 190        3600\n 4 Adelie  Dream               34            17.1               185        3400\n 5 Adelie  Torgersen           34.1          18.1               193        3475\n 6 Adelie  Torgersen           34.4          18.4               184        3325\n 7 Adelie  Biscoe              34.5          18.1               187        2900\n 8 Adelie  Torgersen           34.6          21.1               198        4400\n 9 Adelie  Torgersen           34.6          17.2               189        3200\n10 Adelie  Biscoe              35            17.9               190        3450\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nSetting prop&gt;=1 will return all of the rows in the data frame, sorted by your relevant variable. This means that you can use slice_min() and slice_max() as substitutes for arrange() or order(), if you wanted to do that for some reason!\n\n\n\n\n\nYes, I can think of at least three situations where these functions would be helpful:\n\nSubsetting your data into quantiles\nVerifying that a mutation worked correctly by double checking the highest and lowest values\nLooking quickly for apparent outlier values"
  },
  {
    "objectID": "function_week/Sonstroem_slice_max_slice_min.html#what-is-it-for",
    "href": "function_week/Sonstroem_slice_max_slice_min.html#what-is-it-for",
    "title": "dplyr::slice_max, slice_min",
    "section": "",
    "text": "slice_max() and slice_min() are two of several different slice functions, all of which allow you to select specific rows in order to view, delete, mutate, or otherwise interact with them. slice_max() selects the rows with the highest values of a particular variable, and slice_min() selects the rows with the lowest values.\n\n\nThe necessary arguments are your data frame and order_by, which specifies the variable to select the highest and lowest values from\nThe optional arguments include:\n\nn, which specifies the number of rows to select, or prop, which specifies a proportion of rows. The default value is n=1.\nwith_ties, which specifies whether or not to include ties. The default value is TRUE, which means that the function may return more rows than requested if there are ties.\n\n\n\n\n\n\nWhich are the 5 penguins with the longest beaks?\n\nslice_max(penguins, order_by=bill_length_mm, n=5)\n\n# A tibble: 5 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           59.6          17                 230        6050\n2 Chinstrap Dream            58            17.8               181        3700\n3 Gentoo    Biscoe           55.9          17                 228        5600\n4 Chinstrap Dream            55.8          19.8               207        4000\n5 Gentoo    Biscoe           55.1          16                 230        5850\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\nWhich penguins are in the lowest quartile of beak length?\n\npenguins %&gt;% slice_min(bill_length_mm, prop=0.25)\n\n# A tibble: 86 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Dream               32.1          15.5               188        3050\n 2 Adelie  Dream               33.1          16.1               178        2900\n 3 Adelie  Torgersen           33.5          19                 190        3600\n 4 Adelie  Dream               34            17.1               185        3400\n 5 Adelie  Torgersen           34.1          18.1               193        3475\n 6 Adelie  Torgersen           34.4          18.4               184        3325\n 7 Adelie  Biscoe              34.5          18.1               187        2900\n 8 Adelie  Torgersen           34.6          21.1               198        4400\n 9 Adelie  Torgersen           34.6          17.2               189        3200\n10 Adelie  Biscoe              35            17.9               190        3450\n# ℹ 76 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\nWhat is the average beak length for the penguins in the lowest quartile of beak length?\n\nshortbeak &lt;- slice_min(penguins, order_by=bill_length_mm, prop=0.25)\nmean(shortbeak$bill_length_mm)\n\n[1] 36.9186\n\n\n\n\n\n\n\n\n\npenguins %&gt;% slice_min(species, n=5)\n\n# A tibble: 152 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 142 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThe values will be sorted alphabetically! This seems less useful than using the functions for numeric values, but it would allow you to do things like pull the first 5 people alphabetically from a list.\n\n\n\nAs we saw with the species example above, I requested n=5 but got far more rows than that. If I’d set with_ties to false, I would have gotten…\n\npenguins %&gt;% slice_min(species, n=5, with_ties=FALSE)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n… the five Adelie penguins that happen to be listed first in the data frame.\n\n\n\n\npenguins %&gt;% slice_min(bill_length_mm, prop=1.3)\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Dream               32.1          15.5               188        3050\n 2 Adelie  Dream               33.1          16.1               178        2900\n 3 Adelie  Torgersen           33.5          19                 190        3600\n 4 Adelie  Dream               34            17.1               185        3400\n 5 Adelie  Torgersen           34.1          18.1               193        3475\n 6 Adelie  Torgersen           34.4          18.4               184        3325\n 7 Adelie  Biscoe              34.5          18.1               187        2900\n 8 Adelie  Torgersen           34.6          21.1               198        4400\n 9 Adelie  Torgersen           34.6          17.2               189        3200\n10 Adelie  Biscoe              35            17.9               190        3450\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nSetting prop&gt;=1 will return all of the rows in the data frame, sorted by your relevant variable. This means that you can use slice_min() and slice_max() as substitutes for arrange() or order(), if you wanted to do that for some reason!"
  },
  {
    "objectID": "function_week/Sonstroem_slice_max_slice_min.html#is-it-helpful",
    "href": "function_week/Sonstroem_slice_max_slice_min.html#is-it-helpful",
    "title": "dplyr::slice_max, slice_min",
    "section": "",
    "text": "Yes, I can think of at least three situations where these functions would be helpful:\n\nSubsetting your data into quantiles\nVerifying that a mutation worked correctly by double checking the highest and lowest values\nLooking quickly for apparent outlier values"
  },
  {
    "objectID": "function_week/Surya_geom_tile.html",
    "href": "function_week/Surya_geom_tile.html",
    "title": "ggplot2::geom_tile",
    "section": "",
    "text": "In this document, I will introduce the geom_tile() function and show what it’s for.\n\n# Loading tidyverse and other libraries\npacman::p_load(\n  tidyverse,    \n  readxl,       \n  ggthemes,     \n  ggplot2,\n  here\n  )\n\n\n\n\nThis function comes from the ggplot2 library and is used for data visualization, specifically in the form of heatmaps or other tile plots.\nHeatmaps are a useful visual way to show the intensity of a numerical variable in the context of two categorical variables.\nIn the code below, I will show how geom_tile() can be used to create a heatmap looking at a data set of HIV Diagnoses and AIDS Deaths in Oregon from 2012 to 2022. We will be looking at the count of cases of these indicators.\nData Source: Retrieved from CDC.gov.\nTo get a CSV file, which I converted to an Excel file, I chose STI data in the form of a table and specified parameters: Indicators: AIDS Deaths, HIV Diagnoses, Age: 13+, Sex: Both, State: Oregon, Years: 2012-2022, All transmission categories, All races and ethnicities.\n\n\n# Load and view the STI Dataset\n# Skip the first 11 lines to reach the headers\nOR_STI &lt;- read_excel(here(\"function_week\", \"data\", \"data_SURYA.xlsx\"), sheet = 1, skip = 11, na = \"NA\")\nOR_STI\n\n# A tibble: 22 × 4\n   Indicator     Year                     Cases `Rate per 100000`\n   &lt;chr&gt;         &lt;chr&gt;                    &lt;dbl&gt;             &lt;dbl&gt;\n 1 AIDS deaths   2022                       140               3.8\n 2 HIV diagnoses 2022                       250               6.8\n 3 AIDS deaths   2021                       117               3.2\n 4 HIV diagnoses 2021                       201               5.5\n 5 AIDS deaths   2020 (COVID-19 Pandemic)   102               2.8\n 6 HIV diagnoses 2020 (COVID-19 Pandemic)   180               4.9\n 7 AIDS deaths   2019                       105               2.9\n 8 HIV diagnoses 2019                       198               5.5\n 9 HIV diagnoses 2018                       227               6.4\n10 AIDS deaths   2018                        88               2.5\n# ℹ 12 more rows\n\n\n\n\n# Create the heatmap\nmyplot &lt;- ggplot(OR_STI,\n       aes(x = Year,\n           y = Indicator,\n           fill = Cases)) +\n  geom_tile() +\n  scale_fill_viridis_c() +\n  theme_minimal() +\n  # Customize the angle and positions of x and y tick mark labels for better visualization (especially because the 2020 label has a much longer name)\n  theme(axis.text.y = element_text(angle = 90, size = 8, hjust = 0.5),\n        axis.text.x = element_text(angle = 25, hjust = 1, vjust = 1, size = 8)) +\n  # Add a graph title\n  labs(title = \"Count of Cases of HIV and AIDS Indicators in Oregon from 2012 to 2022\")\nmyplot\n\n\n\n\n\n\n\n\nHeatmaps are helpful to visualize categorical variables with a third numeric variable\nWhen there is a greater range of values, such as in this dataset, heatmaps can show intensity in an easy-to-digest visual way as opposed to other options where readers would need to read numeric scales on a graph.\nCan be helpful to visually stack and compare variables. In this data for instance, we can visually see that there have historically been a lot more HIV diagnoses than AIDS deaths, and HIV diagnoses fluctuate often with time. However, in recent years we can see a clear upward trend in counts of AIDS deaths since the color becomes lighter, indicating increasing cases."
  },
  {
    "objectID": "function_week/Surya_geom_tile.html#what-is-it-for",
    "href": "function_week/Surya_geom_tile.html#what-is-it-for",
    "title": "ggplot2::geom_tile",
    "section": "",
    "text": "This function comes from the ggplot2 library and is used for data visualization, specifically in the form of heatmaps or other tile plots.\nHeatmaps are a useful visual way to show the intensity of a numerical variable in the context of two categorical variables.\nIn the code below, I will show how geom_tile() can be used to create a heatmap looking at a data set of HIV Diagnoses and AIDS Deaths in Oregon from 2012 to 2022. We will be looking at the count of cases of these indicators.\nData Source: Retrieved from CDC.gov.\nTo get a CSV file, which I converted to an Excel file, I chose STI data in the form of a table and specified parameters: Indicators: AIDS Deaths, HIV Diagnoses, Age: 13+, Sex: Both, State: Oregon, Years: 2012-2022, All transmission categories, All races and ethnicities.\n\n\n# Load and view the STI Dataset\n# Skip the first 11 lines to reach the headers\nOR_STI &lt;- read_excel(here(\"function_week\", \"data\", \"data_SURYA.xlsx\"), sheet = 1, skip = 11, na = \"NA\")\nOR_STI\n\n# A tibble: 22 × 4\n   Indicator     Year                     Cases `Rate per 100000`\n   &lt;chr&gt;         &lt;chr&gt;                    &lt;dbl&gt;             &lt;dbl&gt;\n 1 AIDS deaths   2022                       140               3.8\n 2 HIV diagnoses 2022                       250               6.8\n 3 AIDS deaths   2021                       117               3.2\n 4 HIV diagnoses 2021                       201               5.5\n 5 AIDS deaths   2020 (COVID-19 Pandemic)   102               2.8\n 6 HIV diagnoses 2020 (COVID-19 Pandemic)   180               4.9\n 7 AIDS deaths   2019                       105               2.9\n 8 HIV diagnoses 2019                       198               5.5\n 9 HIV diagnoses 2018                       227               6.4\n10 AIDS deaths   2018                        88               2.5\n# ℹ 12 more rows\n\n\n\n\n# Create the heatmap\nmyplot &lt;- ggplot(OR_STI,\n       aes(x = Year,\n           y = Indicator,\n           fill = Cases)) +\n  geom_tile() +\n  scale_fill_viridis_c() +\n  theme_minimal() +\n  # Customize the angle and positions of x and y tick mark labels for better visualization (especially because the 2020 label has a much longer name)\n  theme(axis.text.y = element_text(angle = 90, size = 8, hjust = 0.5),\n        axis.text.x = element_text(angle = 25, hjust = 1, vjust = 1, size = 8)) +\n  # Add a graph title\n  labs(title = \"Count of Cases of HIV and AIDS Indicators in Oregon from 2012 to 2022\")\nmyplot"
  },
  {
    "objectID": "function_week/Surya_geom_tile.html#is-it-helpful",
    "href": "function_week/Surya_geom_tile.html#is-it-helpful",
    "title": "ggplot2::geom_tile",
    "section": "",
    "text": "Heatmaps are helpful to visualize categorical variables with a third numeric variable\nWhen there is a greater range of values, such as in this dataset, heatmaps can show intensity in an easy-to-digest visual way as opposed to other options where readers would need to read numeric scales on a graph.\nCan be helpful to visually stack and compare variables. In this data for instance, we can visually see that there have historically been a lot more HIV diagnoses than AIDS deaths, and HIV diagnoses fluctuate often with time. However, in recent years we can see a clear upward trend in counts of AIDS deaths since the color becomes lighter, indicating increasing cases."
  }
]